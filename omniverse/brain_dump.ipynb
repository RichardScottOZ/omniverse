{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Table of contents**<a id='toc0_'></a>    \n",
    "- [Playbook: What is Softmax and Derivatives](#toc1_)    \n",
    "- [Playbook: Sampling Methodologies in Large Language Models](#toc2_)    \n",
    "  - [Sampling Methodologies (Deep Learning: Foundations and Concepts)](#toc2_1_)    \n",
    "  - [Multinomial](#toc2_2_)    \n",
    "  - [Greedy vs Probabilistic sampling](#toc2_3_)    \n",
    "- [How to Derive Sigmoid and Softmax Functions from Exponential Family in Machine Learning Context](#toc3_)    \n",
    "  - [Bernoulli Distribution as an Exponential Family Member](#toc3_1_)    \n",
    "  - [Expressing Bernoulli in Exponential Family Form](#toc3_2_)    \n",
    "  - [Derivation of the Sigmoid Function](#toc3_3_)    \n",
    "\n",
    "<!-- vscode-jupyter-toc-config\n",
    "\tnumbering=false\n",
    "\tanchor=true\n",
    "\tflat=false\n",
    "\tminLevel=1\n",
    "\tmaxLevel=6\n",
    "\t/vscode-jupyter-toc-config -->\n",
    "<!-- THIS CELL WILL BE REPLACED ON TOC UPDATE. DO NOT WRITE YOUR TEXT IN THIS CELL -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='toc1_'></a>[Playbook: What is Softmax and Derivatives](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">tensor</span><span style=\"font-weight: bold\">([[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.3400</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0411</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0217</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.5727</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0246</span><span style=\"font-weight: bold\">]</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0656</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0864</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1489</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.2467</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.4524</span><span style=\"font-weight: bold\">]]</span>, <span style=\"color: #808000; text-decoration-color: #808000\">grad_fn</span>=<span style=\"font-weight: bold\">&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">SoftmaxBackward0</span><span style=\"font-weight: bold\">&gt;)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m0.3400\u001b[0m, \u001b[1;36m0.0411\u001b[0m, \u001b[1;36m0.0217\u001b[0m, \u001b[1;36m0.5727\u001b[0m, \u001b[1;36m0.0246\u001b[0m\u001b[1m]\u001b[0m,\n",
       "\u001b[2;32m│   │   \u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m0.0656\u001b[0m, \u001b[1;36m0.0864\u001b[0m, \u001b[1;36m0.1489\u001b[0m, \u001b[1;36m0.2467\u001b[0m, \u001b[1;36m0.4524\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m, \u001b[33mgrad_fn\u001b[0m=\u001b[1m<\u001b[0m\u001b[1;95mSoftmaxBackward0\u001b[0m\u001b[1m>\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">tensor</span><span style=\"font-weight: bold\">([[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.3400</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0411</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0217</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.5727</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0246</span><span style=\"font-weight: bold\">]</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0656</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0864</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1489</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.2467</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.4524</span><span style=\"font-weight: bold\">]]</span>, <span style=\"color: #808000; text-decoration-color: #808000\">grad_fn</span>=<span style=\"font-weight: bold\">&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">DivBackward0</span><span style=\"font-weight: bold\">&gt;)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m0.3400\u001b[0m, \u001b[1;36m0.0411\u001b[0m, \u001b[1;36m0.0217\u001b[0m, \u001b[1;36m0.5727\u001b[0m, \u001b[1;36m0.0246\u001b[0m\u001b[1m]\u001b[0m,\n",
       "\u001b[2;32m│   │   \u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m0.0656\u001b[0m, \u001b[1;36m0.0864\u001b[0m, \u001b[1;36m0.1489\u001b[0m, \u001b[1;36m0.2467\u001b[0m, \u001b[1;36m0.4524\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m, \u001b[33mgrad_fn\u001b[0m=\u001b[1m<\u001b[0m\u001b[1;95mDivBackward0\u001b[0m\u001b[1m>\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from __future__ import annotations\n",
    "from torch import nn\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from rich.pretty import pprint\n",
    "from typing import List, Dict, Any, Optional\n",
    "\n",
    "class Softmax:\n",
    "    \"\"\"\n",
    "    Softmax activation function.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, dim: int | None = None) -> None:\n",
    "        \"\"\"\n",
    "        Initialize the softmax function.\n",
    "        \"\"\"\n",
    "        self.dim = dim\n",
    "\n",
    "    def __call__(self, z: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Compute the softmax function for a given input.\n",
    "        \"\"\"\n",
    "        numerator = torch.exp(z)\n",
    "        denominator = torch.sum(numerator, dim=self.dim, keepdim=True)\n",
    "        g = numerator / denominator\n",
    "        return g\n",
    "\n",
    "\n",
    "    def gradient(self, z: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Compute the derivative of the softmax function with respect to its input.\n",
    "        \"\"\"\n",
    "        g = self.__call__(z)\n",
    "        g = g.unsqueeze(-1)  # add an extra dimension\n",
    "        eye = torch.eye(g.shape[1], device=z.device)[None, :]  # identity matrix\n",
    "        dg_dz = g * (eye - g)\n",
    "        return dg_dz.sum(dim=1)\n",
    "\n",
    "\n",
    "z = torch.randn((2, 5), requires_grad=True, dtype=torch.float32)\n",
    "pytorch_softmax = nn.Softmax(dim=1)\n",
    "pytorch_softmax_outputs = pytorch_softmax(z)\n",
    "pprint(pytorch_softmax_outputs)\n",
    "\n",
    "my_softmax = Softmax(dim=1)\n",
    "my_softmax_outputs = my_softmax(z)\n",
    "pprint(my_softmax_outputs)\n",
    "\n",
    "torch.testing.assert_close(\n",
    "    pytorch_softmax_outputs, my_softmax_outputs, rtol=1.3e-6, atol=1e-5, msg=\"Softmax function outputs do not match.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = torch.randn((2, 5), requires_grad=True)\n",
    "pytorch_softmax = nn.Softmax(dim=1)\n",
    "pytorch_softmax_outputs = pytorch_softmax(z)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradients via PyTorch's autograd:\n",
      "tensor([[-0.0172,  0.0806,  0.0072, -0.0803,  0.0096],\n",
      "        [ 0.0730,  0.0435, -0.0768, -0.0686,  0.0288]])\n",
      "\n",
      "Manual gradient computation currently doesn't integrate directly with autograd; needs adjustment.\n"
     ]
    }
   ],
   "source": [
    "# Use PyTorch's softmax and calculate gradients with respect to z\n",
    "output_torch = F.softmax(z, dim=1)\n",
    "loss_torch = output_torch.log().mean()  # Example loss for gradient calculation\n",
    "loss_torch.backward()\n",
    "\n",
    "# Gradients obtained via PyTorch\n",
    "gradients_torch = z.grad.data\n",
    "\n",
    "# Reset gradients in z for custom gradient computation\n",
    "z.grad = None\n",
    "\n",
    "# Compute softmax using custom function and calculate custom gradients\n",
    "softmax = Softmax()\n",
    "output_custom = softmax(z)\n",
    "# For custom gradient calculation, we need an illustrative \"loss\" since gradients are usually\n",
    "# calculated in the context of some scalar output. Here, we mimic a simple operation as a stand-in for loss.\n",
    "loss_custom = output_custom.log().mean()\n",
    "loss_custom.backward()\n",
    "\n",
    "# Assuming custom gradient computation inside the backward method of a custom autograd function,\n",
    "# here we manually compute it for comparison, which isn't directly applicable as is.\n",
    "# gradients_custom = softmax.gradient(z)  # This line was proposed, but doesn't fit directly into the autograd framework as is.\n",
    "\n",
    "# Print both gradients for comparison\n",
    "print(\"Gradients via PyTorch's autograd:\")\n",
    "print(gradients_torch)\n",
    "print(\"\\nManual gradient computation currently doesn't integrate directly with autograd; needs adjustment.\")\n",
    "# Print the manually computed gradients for educational purposes, if applicable\n",
    "# print(\"\\nCustom computed gradients (for illustration, not directly comparable):\")\n",
    "# print(gradients_custom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch Softmax Gradient: tensor([[-4.3086e-08, -5.9735e-09, -1.9813e-08, -2.2872e-08, -3.0181e-09,\n",
      "         -5.1731e-08, -3.5311e-08, -1.6718e-08, -3.0283e-08, -9.6135e-09],\n",
      "        [ 2.3789e-09,  8.6295e-09,  1.4517e-09,  1.9518e-08,  5.1734e-09,\n",
      "          1.1618e-09,  1.5833e-08,  3.6878e-08,  1.0539e-08,  1.7647e-08],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00],\n",
      "        [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "          0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00]])\n"
     ]
    }
   ],
   "source": [
    "# get gradients of nn.Softmax\n",
    "\n",
    "z.requires_grad = True\n",
    "z.retain_grad()\n",
    "pytorch_softmax_outputs = pytorch_softmax(z)\n",
    "pytorch_softmax_outputs.sum().backward()\n",
    "print(\"PyTorch Softmax Gradient:\", z.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0395, -0.1162, -0.0581, -0.0453, -0.1286,  0.0757,  0.0069, -0.0711,\n",
       "         -0.0142, -0.1009],\n",
       "        [-0.1577, -0.1052, -0.1655, -0.0139, -0.1342, -0.1679, -0.0448,  0.1317,\n",
       "         -0.0892, -0.0296],\n",
       "        [ 0.0880, -0.0337, -0.0529, -0.0826, -0.0171, -0.1002, -0.1225, -0.1121,\n",
       "          0.0509, -0.0456],\n",
       "        [-0.1719, -0.2328, -0.1720, -0.2228, -0.2369, -0.2246,  0.0033, -0.1809,\n",
       "         -0.2363,  0.1562],\n",
       "        [-0.1041,  0.0046, -0.1296, -0.0668, -0.0869, -0.0171, -0.0134,  0.0384,\n",
       "         -0.0435,  0.0653]], grad_fn=<SumBackward1>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_softmax.gradient(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='toc2_'></a>[Playbook: Sampling Methodologies in Large Language Models](#toc0_)\n",
    "\n",
    "Main thing is to answer the question: why does temperature in llm enable the\n",
    "model to be more random when it is high and more deterministic when it is low?\n",
    "worth noting that if greedy sampling then it is deterministic, if sampling from\n",
    "multinomial then it is random - and dependent on softmax. but if softmax\n",
    "preserves order then how does it become more random? Precisely why i said greedy\n",
    "sampling is deterministic since the order is preserved but multinomial sampling\n",
    "is random but the order is also preserved - the key lies in the sharpen/dampen\n",
    "effect of the softmax distribution. If sharp, means dominated by 1 value\n",
    "usually, 0.99, so samplign from that converges to greedy sampling -\n",
    "deterministic. If dampened, means more uniform, so sampling from that converges\n",
    "to more diverse sampling. But is if converge to uniform no right.\n",
    "\n",
    "-   softmax sharpens/dampens distribution\n",
    "-   multinomial enables randomness\n",
    "-   greedy sampling enables deterministic\n",
    "-   and multinomial with T=0 converges to greedy = deterministic sampling```\n",
    "\n",
    "And SINCE the softmax function is not invariant under scaling, we can introduce\n",
    "a temperature parameter $T$ to control the entropy of the output distribution.\n",
    "BECAUSE TEMPERATURE IS EFFECTIVELY SCALING! The temperature is a way to control\n",
    "the entropy of a distribution, while preserving the relative ranks of each\n",
    "event.\n",
    "\n",
    "\n",
    "## <a id='toc2_1_'></a>[Sampling Methodologies (Deep Learning: Foundations and Concepts)](#toc0_)\n",
    "\n",
    "We have seen that the output of a decoder transformer is a probability\n",
    "distribution over values for the next token in the sequence, from which a\n",
    "particular value for that token must be chosen to extend the sequence. There are\n",
    "several options for selecting the value of the token based on the computed\n",
    "probabilities (Holtzman et al., 2019). One obvious approach, called greedy\n",
    "search, is simply to select the token with the highest probability. This has the\n",
    "effect of making the model deterministic, in that a given input sequence always\n",
    "generates the same output sequence. Note that simply choosing the highest\n",
    "probability token at each stage is not the same as selecting the highest\n",
    "probability sequence of tokens. To find the most probable sequence, we would\n",
    "need to maximize the joint distribution over all tokens, which is given by\n",
    "\n",
    "$$\n",
    "p\\left(\\mathbf{y}_1, \\ldots, \\mathbf{y}_N\\right)=\\prod_{n=1}^N p\\left(\\mathbf{y}_n \\mid \\mathbf{y}_1, \\ldots, \\mathbf{y}_{n-1}\\right)\n",
    "$$\n",
    "\n",
    "If there are $N$ steps in the sequence and the number of token values in the\n",
    "dictionary is $K$ then the total number of sequences is\n",
    "$\\mathcal{O}\\left(K^N\\right)$, which grows exponentially with the length of the\n",
    "sequence, and hence finding the single most probable sequence is infeasible. By\n",
    "comparison, greedy search has cost $\\mathcal{O}(K N)$, which is linear in the\n",
    "sequence length.\n",
    "\n",
    "One technique that has the potential to generate higher probability sequences\n",
    "than greedy search is called beam search. Instead of choosing the single most\n",
    "probable token value at each step, we maintain a set of $B$ hypotheses, where\n",
    "$B$ is called the beam width, each consisting of a sequence of token values up\n",
    "to step $n$. We then feed all these sequences through the network, and for each\n",
    "sequence we find the $B$ most probable token values, thereby creating $B^2$\n",
    "possible hypotheses for the extended sequence. This list is then pruned by\n",
    "selecting the most probable $B$ hypotheses according to the total probability of\n",
    "the extended sequence. Thus, the beam search algorithm maintains $B$ alternative\n",
    "sequences and keeps track of their probabilities, finally selecting the most\n",
    "probable sequence amongst those considered. Because the probability of a\n",
    "sequence is obtained by multiplying the probabilities at each step of the\n",
    "sequence and since these probability are always less than or equal to one, a\n",
    "long sequence will generally have a lower probability than a short one, biasing\n",
    "the results towards short sequences. For this reason the sequence probabilities\n",
    "are generally normalized by the corresponding lengths of the sequence before\n",
    "making comparisons. Beam search has cost $\\mathcal{O}(B K N)$, which is again\n",
    "linear in the sequence length. However, the cost of generating a sequence is\n",
    "increased by a factor of $B$, and so for very large language models, where the\n",
    "cost of inference can become significant, this makes beam search much less\n",
    "attractive.\n",
    "\n",
    "One problem with approaches such as greedy search and beam search is that they\n",
    "limit the diversity of potential outputs and can even cause the generation\n",
    "process to become stuck in a loop, where the same sub-sequence of words is\n",
    "repeated over and over. As can be seen in Figure 12.17, human-generated text may\n",
    "have lower probability and hence be more surprising with respect to a given\n",
    "model than automatically generated text.\n",
    "\n",
    "Instead of trying to find a sequence with the highest probability, we can\n",
    "instead generate successive tokens simply by sampling from the softmax\n",
    "distribution at each step. However, this can lead to sequences that are\n",
    "nonsensical. This arises from the typically very large size of the token\n",
    "dictionary, in which there is a long tail of many token states each of which has\n",
    "a very small probability but which in aggregate account for a significant\n",
    "fraction of the total probability mass. This leads to the problem in which there\n",
    "is a significant chance that the system will make a bad choice for the next\n",
    "token.\n",
    "\n",
    "As a balance between these extremes, we can consider only the states having the\n",
    "top $K$ probabilities, for some choice of $K$, and then sample from these\n",
    "according to their renormalized probabilities. A variant of this approach,\n",
    "called top- $p$ sampling or nucleus sampling, calculates the cumulative\n",
    "probability of the top outputs until a threshold is reached and then samples\n",
    "from this restricted set of token states.\n",
    "\n",
    "A 'softer' version of top- $K$ sampling is to introduce a parameter $T$ called\n",
    "temperature into the definition of the softmax function (Hinton, Vinyals, and\n",
    "Dean, 2015) so that\n",
    "\n",
    "$$\n",
    "y_i=\\frac{\\exp \\left(a_i / T\\right)}{\\sum_j \\exp \\left(a_j / T\\right)}\n",
    "$$\n",
    "\n",
    "and then sample the next token from this modified distribution. When $T=0$, the\n",
    "probability mass is concentrated on the most probable state, with all other\n",
    "states having zero probability, and hence this becomes greedy selection. For\n",
    "$T=1$, we recover the unmodified softmax distribution, and as\n",
    "$T \\rightarrow \\infty$, the distribution becomes uniform across all states. By\n",
    "choosing a value in the range $0<T<1$, the probability is concentrated towards\n",
    "the higher values.\n",
    "\n",
    "One challenge with sequence generation is that during the learning phase, the\n",
    "model is trained on a human-generated input sequence, whereas when it is running\n",
    "generatively, the input sequence is itself generated from the model. This means\n",
    "that the model can drift away from the distribution of sequences seen during\n",
    "training.\n",
    "\n",
    "\n",
    "## <a id='toc2_2_'></a>[Multinomial](#toc0_)\n",
    "\n",
    "In multinomial (or probabilistic) sampling, the model samples from the entire\n",
    "probability distribution obtained after applying softmax:\n",
    "\n",
    "At higher temperatures, the probability distribution becomes more uniform,\n",
    "increasing the likelihood of sampling less probable tokens, thereby introducing\n",
    "more randomness or diversity into the selection process. At lower temperatures,\n",
    "the distribution becomes sharper, concentrating most of the probability mass on\n",
    "a few high-probability tokens. This makes the selection less random and more\n",
    "predictable, closely aligning with the greedy selection outcome but still\n",
    "allowing for some variability.\n",
    "\n",
    "KEY is to understand multinomial in the sampling.\n",
    "\n",
    "## <a id='toc2_3_'></a>[Greedy vs Probabilistic sampling](#toc0_)\n",
    "\n",
    "If your model employs a greedy strategy for selecting tokens (e.g., always\n",
    "choosing the token with the highest probability), then adjusting the temperature\n",
    "won't change the selected token. This approach is common in tasks where\n",
    "precision is critical, and the aim is to reduce randomness to a minimum, such as\n",
    "in certain classification tasks or when generating text where maximum coherence\n",
    "is desired."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='toc3_'></a>[How to Derive Sigmoid and Softmax Functions from Exponential Family in Machine Learning Context](#toc0_)\n",
    "\n",
    "REFERENCE:\n",
    "\n",
    "-   6.2.2.2, 6.2.2.3 of The Deep Learning Book by Goodfellow et al.\n",
    "-   3.4. of Deep Learning: Foundations and Concepts by Bishop et al.\n",
    "\n",
    "SAMPLE CONTENT BELOW (TO BE REFINED): We can derive via exponential family.\n",
    "\n",
    "## <a id='toc3_1_'></a>[Bernoulli Distribution as an Exponential Family Member](#toc0_)\n",
    "\n",
    "The Bernoulli distribution can be expressed in the exponential family form as\n",
    "follows:\n",
    "\n",
    "$$\n",
    "p(y | \\eta) = b(y) \\exp(\\eta^T y - A(\\eta))\n",
    "$$\n",
    "\n",
    "For the Bernoulli distribution:\n",
    "\n",
    "-   $y$ is the binary outcome (0 or 1).\n",
    "-   $\\eta$ (or $\\theta$ in some formulations) is the natural parameter of the\n",
    "    distribution.\n",
    "-   The base measure $b(y) = 1$, since it doesn't affect the form of the\n",
    "    Bernoulli distribution.\n",
    "-   The sufficient statistic $y$ is the identity function of the outcome.\n",
    "\n",
    "To match the Bernoulli distribution to the exponential family form, we recognize\n",
    "that $p(y | \\eta)$ for $y \\in \\{0,1\\}$ is given by\n",
    "$p(y = 1 | \\eta) =\n",
    "\\sigma(\\eta)$ and $p(y = 0 | \\eta) = 1 - \\sigma(\\eta)$, where\n",
    "$\\sigma(\\eta)$ is the sigmoid function. The Bernoulli distribution can be\n",
    "written as:\n",
    "\n",
    "$$\n",
    "p(y | \\eta) = \\sigma(\\eta)^y (1 - \\sigma(\\eta))^{1-y}\n",
    "$$\n",
    "\n",
    "## <a id='toc3_2_'></a>[Expressing Bernoulli in Exponential Family Form](#toc0_)\n",
    "\n",
    "Let's express the Bernoulli distribution in the form that highlights the\n",
    "exponential family structure. To do this, note that the probability of success\n",
    "$p = \\sigma(\\eta)$ where $\\sigma(\\eta)$ is the sigmoid function. By definition:\n",
    "\n",
    "$$\n",
    "\\sigma(\\eta) = \\frac{1}{1 + e^{-\\eta}}\n",
    "$$\n",
    "\n",
    "So, we have:\n",
    "\n",
    "$$\n",
    "p(y | \\eta) = \\frac{e^{\\eta y}}{1 + e^{\\eta}}\n",
    "$$\n",
    "\n",
    "where the natural parameter $\\eta = \\log\\left(\\frac{p}{1-p}\\right)$, and\n",
    "$A(\\eta) = -\\log(1 - p) = \\log(1 + e^{\\eta})$.\n",
    "\n",
    "## <a id='toc3_3_'></a>[Derivation of the Sigmoid Function](#toc0_)\n",
    "\n",
    "The sigmoid function is derived as the transformation of the natural parameter\n",
    "$\\eta$ back to the probability $p$. From the natural parameter, we have\n",
    "$\\eta = \\log\\left(\\frac{p}{1-p}\\right)$, solving for $p$ gives us the sigmoid\n",
    "function:\n",
    "\n",
    "$$\n",
    "\\eta = \\log\\left(\\frac{p}{1-p}\\right) \\Rightarrow e^{\\eta} = \\frac{p}{1-p} \\Rightarrow p = \\frac{e^{\\eta}}{1 + e^{\\eta}}\n",
    "$$\n",
    "\n",
    "By substituting $\\eta$ back with a linear combination of features (e.g.,\n",
    "$z =\n",
    "\\boldsymbol{w}^\\top \\boldsymbol{x} + b$ in machine learning), we obtain the\n",
    "sigmoid function used for binary classification:\n",
    "\n",
    "$$\n",
    "\\sigma(z) = \\frac{1}{1 + e^{-z}}\n",
    "$$\n",
    "\n",
    "In this manner, the sigmoid function is derived as a special case of applying\n",
    "the exponential family formulation to the Bernoulli distribution, with the\n",
    "natural parameter $\\eta$ serving as the link between the linear predictor and\n",
    "the probabilities of the outcomes.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "omniverse",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
