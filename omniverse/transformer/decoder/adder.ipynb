{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Training a Mini-GPT to Learn Two-Digit Addition\n",
        "\n",
        "[![Twitter Handle](https://img.shields.io/badge/Twitter-@gaohongnan-blue?style=social&logo=twitter)](https://twitter.com/gaohongnan)\n",
        "[![LinkedIn Profile](https://img.shields.io/badge/@gaohongnan-blue?style=social&logo=linkedin)](https://linkedin.com/in/gao-hongnan)\n",
        "[![GitHub Profile](https://img.shields.io/badge/GitHub-gao--hongnan-lightgrey?style=social&logo=github)](https://github.com/gao-hongnan)\n",
        "[![Code](https://img.shields.io/badge/View-Code-blue?style=flat-square&logo=github)](https://github.com/gao-hongnan/omniverse/tree/5221d5d8b9bd845568b2e323d908be282c6e8434/omnivault/transformer/projects/adder)\n",
        "![Tag](https://img.shields.io/badge/Tag-Structured_Musings-purple)\n",
        "\n",
        "```{contents}\n",
        ":local:\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Motivation\n",
        "\n",
        "Generative Pre-trained Transformer (GPT) are well known to perform bad on\n",
        "arithmetic tasks such as addition. This should not come as a surprise since GPT\n",
        "is a _language_ model and not a _math_ model. It is designed to train on a large\n",
        "corpus of text and learn the patterns and structure of natural language. While\n",
        "we do encounter many arithmetic operations in corpus, the encoding of these\n",
        "operations are often in a form that is in the text sense, not in the\n",
        "mathematical sense. After all, what GPT does best is to predict the next token\n",
        "over the entire **vocabulary** distribution.\n",
        "\n",
        "In one of the examples provided from the repository\n",
        "[minGPT](https://github.com/karpathy/minGPT/tree/master), Karpathy demonstrates\n",
        "training a GPT model to learn the addition of two numbers presented as strings.\n",
        "This is a simple task designed to illustrate how a decoder-only model can be\n",
        "trained to learn \"addition\". Thus, the input is a sequence of characters\n",
        "representing an addition operation (like \"12 + 35\") and the output is the\n",
        "sequence of characters representing the result of the addition (like \"47\").\n",
        "\n",
        "To this end, we replicate his example, which serves as a proof-of-concept to\n",
        "show that decoder only models, which are often used for language-related tasks,\n",
        "can learn other patterns or \"languages,\" such as the \"language\" of arithmetic."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 115,
      "metadata": {
        "id": "Cvk1SmuCrdzK"
      },
      "outputs": [],
      "source": [
        "from __future__ import annotations\n",
        "\n",
        "import os\n",
        "import time\n",
        "from dataclasses import dataclass\n",
        "from typing import Any, Callable, Dict, List, Optional, Tuple, Union\n",
        "\n",
        "import rich\n",
        "import torch\n",
        "from rich.pretty import pprint\n",
        "from torch import nn\n",
        "from torch.optim import Optimizer\n",
        "from torch.optim.lr_scheduler import LRScheduler\n",
        "from torch.utils.data import DataLoader, Dataset, Subset, random_split\n",
        "from omegaconf import OmegaConf as om\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 116,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "from pathlib import Path\n",
        "\n",
        "\n",
        "def find_root_dir(current_path: Path | None = None, marker: str = '.git') -> Path | None:\n",
        "    \"\"\"\n",
        "    Find the root directory by searching for a directory or file that serves as a\n",
        "    marker.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    current_path : Path | None\n",
        "        The starting path to search from. If None, the current working directory\n",
        "        `Path.cwd()` is used.\n",
        "    marker : str\n",
        "        The name of the file or directory that signifies the root.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    Path | None\n",
        "        The path to the root directory. Returns None if the marker is not found.\n",
        "    \"\"\"\n",
        "    if not current_path:\n",
        "        current_path = Path.cwd()\n",
        "    current_path = current_path.resolve()\n",
        "    for parent in [current_path, *current_path.parents]:\n",
        "        if (parent / marker).exists():\n",
        "            return parent\n",
        "    return None\n",
        "\n",
        "current_file_path = Path(os.getcwd())\n",
        "root_dir          = find_root_dir(current_file_path, marker='omnivault')\n",
        "\n",
        "if root_dir is not None:\n",
        "    sys.path.append(str(root_dir))\n",
        "    from omnivault._types._alias import Accuracy, Loss\n",
        "    from omnivault.transformer.config.composer import Composer, DataConfig\n",
        "    from omnivault.transformer.config.constants import MaybeConstant\n",
        "    from omnivault.transformer.config.decoder import (\n",
        "        AddNormConfig,\n",
        "        DecoderBlockConfig,\n",
        "        DecoderConfig,\n",
        "        MultiHeadedAttentionConfig,\n",
        "        PositionwiseFeedForwardConfig,\n",
        "    )\n",
        "    from omnivault.transformer.config.global_ import MaybeGlobal\n",
        "    from omnivault.transformer.config.trainer import TrainerConfig\n",
        "    from omnivault.transformer.config.optim import AdamConfig, OptimizerConfig\n",
        "    from omnivault.transformer.core.dataset import AdderDataset, create_loader, split_dataset, construct_dummy_batch_future_masks, construct_dummy_batch_target_padding_masks\n",
        "    from omnivault.transformer.core.trainer import Trainer\n",
        "    from omnivault.transformer.core.vocabulary import AdderVocabulary\n",
        "    from omnivault.transformer.decoder.core import GPTDecoder\n",
        "    from omnivault.transformer.modules.attention.core import ScaledDotProductAttention\n",
        "    from omnivault.transformer.utils.reproducibility import seed_all\n",
        "    from omnivault.transformer.core.tokenizer import AdderTokenizer\n",
        "    from omnivault.transformer.utils.general_utils import create_directory, download_file, validate_and_cleanup\n",
        "    from omnivault.transformer.utils.config_utils import load_yaml_config, merge_configs\n",
        "    from omnivault.core.logger import RichLogger\n",
        "    from omnivault.utils.inspector.core import get_field_annotations\n",
        "    import inspect\n",
        "else:\n",
        "    raise ImportError(\"Root directory not found.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 117,
      "metadata": {},
      "outputs": [],
      "source": [
        "yaml_cfg = load_yaml_config(yaml_path=root_dir / \"omnivault/transformer/projects/adder/config.yaml\")\n",
        "cfg = merge_configs(yaml_cfg, args_list=[])\n",
        "om.resolve(cfg)  # inplace ops"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 118,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Composer</span><span style=\"font-weight: bold\">(</span>\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #808000; text-decoration-color: #808000\">constants</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">MaybeConstant</span><span style=\"font-weight: bold\">(</span>\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">NUM_DIGITS</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>,\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">TOKENS</span>=<span style=\"font-weight: bold\">[</span>\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   │   </span><span style=\"color: #008000; text-decoration-color: #008000\">'0'</span>,\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   │   </span><span style=\"color: #008000; text-decoration-color: #008000\">'1'</span>,\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   │   </span><span style=\"color: #008000; text-decoration-color: #008000\">'2'</span>,\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   │   </span><span style=\"color: #008000; text-decoration-color: #008000\">'3'</span>,\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   │   </span><span style=\"color: #008000; text-decoration-color: #008000\">'4'</span>,\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   │   </span><span style=\"color: #008000; text-decoration-color: #008000\">'5'</span>,\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   │   </span><span style=\"color: #008000; text-decoration-color: #008000\">'6'</span>,\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   │   </span><span style=\"color: #008000; text-decoration-color: #008000\">'7'</span>,\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   │   </span><span style=\"color: #008000; text-decoration-color: #008000\">'8'</span>,\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   │   </span><span style=\"color: #008000; text-decoration-color: #008000\">'9'</span>,\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   │   </span><span style=\"color: #008000; text-decoration-color: #008000\">'+'</span>,\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   │   </span><span style=\"color: #008000; text-decoration-color: #008000\">'*'</span>,\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   │   </span><span style=\"color: #008000; text-decoration-color: #008000\">'-'</span>,\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   │   </span><span style=\"color: #008000; text-decoration-color: #008000\">'='</span>,\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   │   </span><span style=\"color: #008000; text-decoration-color: #008000\">'&lt;BOS&gt;'</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   │   </span><span style=\"color: #008000; text-decoration-color: #008000\">'&lt;EOS&gt;'</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   │   </span><span style=\"color: #008000; text-decoration-color: #008000\">'&lt;PAD&gt;'</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   │   </span><span style=\"color: #008000; text-decoration-color: #008000\">'&lt;UNK&gt;'</span>\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"font-weight: bold\">]</span>\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"font-weight: bold\">)</span>,\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #808000; text-decoration-color: #808000\">logger</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">LoggerConfig</span><span style=\"font-weight: bold\">(</span>\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">log_file</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">module_name</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">propagate</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>,\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">log_root_dir</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">rich_handler_config</span>=<span style=\"font-weight: bold\">{</span>\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   │   </span><span style=\"color: #008000; text-decoration-color: #008000\">'level'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'INFO'</span>,\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   │   </span><span style=\"color: #008000; text-decoration-color: #008000\">'console'</span>: MISSING,\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   │   </span><span style=\"color: #008000; text-decoration-color: #008000\">'show_level'</span>: <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   │   </span><span style=\"color: #008000; text-decoration-color: #008000\">'show_path'</span>: <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   │   </span><span style=\"color: #008000; text-decoration-color: #008000\">'show_time'</span>: <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   │   </span><span style=\"color: #008000; text-decoration-color: #008000\">'rich_tracebacks'</span>: <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   │   </span><span style=\"color: #008000; text-decoration-color: #008000\">'markup'</span>: <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   │   </span><span style=\"color: #008000; text-decoration-color: #008000\">'log_time_format'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'[%Y-%m-%d %H:%M:%S]'</span>\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"font-weight: bold\">}</span>\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"font-weight: bold\">)</span>,\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #808000; text-decoration-color: #808000\">global_</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">MaybeGlobal</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">seed</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">42</span>, <span style=\"color: #808000; text-decoration-color: #808000\">debug</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>, <span style=\"color: #808000; text-decoration-color: #808000\">debug_samples</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">100</span><span style=\"font-weight: bold\">)</span>,\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #808000; text-decoration-color: #808000\">data</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">DataConfig</span><span style=\"font-weight: bold\">(</span>\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">context_length</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">11</span>,\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">dataset_name</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'adder_dataset'</span>,\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">dataset_size</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10000</span>,\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">dataset_path</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'./data/adder/adder_dataset.txt'</span>,\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">dataset_dir</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'./data/adder'</span>,\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">dataset_url</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'https://raw.githubusercontent.com/gao-hongnan/omniverse/dev/omnivault/transformer/projects/adder/assets/adder_dataset.txt'</span>,\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">split</span>=<span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.7</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.2</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1</span><span style=\"font-weight: bold\">]</span>,\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">collate_fn</span>=<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'batch_first'</span>: <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'pad_token_id'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">16</span><span style=\"font-weight: bold\">}</span>,\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">train_loader</span>=<span style=\"font-weight: bold\">{</span>\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   │   </span><span style=\"color: #008000; text-decoration-color: #008000\">'batch_size'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">32</span>,\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   │   </span><span style=\"color: #008000; text-decoration-color: #008000\">'shuffle'</span>: <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   │   </span><span style=\"color: #008000; text-decoration-color: #008000\">'num_workers'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>,\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   │   </span><span style=\"color: #008000; text-decoration-color: #008000\">'pin_memory'</span>: <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>,\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   │   </span><span style=\"color: #008000; text-decoration-color: #008000\">'drop_last'</span>: <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"font-weight: bold\">}</span>,\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">valid_loader</span>=<span style=\"font-weight: bold\">{</span>\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   │   </span><span style=\"color: #008000; text-decoration-color: #008000\">'batch_size'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">32</span>,\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   │   </span><span style=\"color: #008000; text-decoration-color: #008000\">'shuffle'</span>: <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>,\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   │   </span><span style=\"color: #008000; text-decoration-color: #008000\">'num_workers'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>,\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   │   </span><span style=\"color: #008000; text-decoration-color: #008000\">'pin_memory'</span>: <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>,\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   │   </span><span style=\"color: #008000; text-decoration-color: #008000\">'drop_last'</span>: <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"font-weight: bold\">}</span>,\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">test_loader</span>=<span style=\"font-weight: bold\">{</span>\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   │   </span><span style=\"color: #008000; text-decoration-color: #008000\">'batch_size'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">128</span>,\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   │   </span><span style=\"color: #008000; text-decoration-color: #008000\">'shuffle'</span>: <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>,\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   │   </span><span style=\"color: #008000; text-decoration-color: #008000\">'num_workers'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>,\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   │   </span><span style=\"color: #008000; text-decoration-color: #008000\">'pin_memory'</span>: <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>,\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   │   </span><span style=\"color: #008000; text-decoration-color: #008000\">'drop_last'</span>: <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"font-weight: bold\">}</span>\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"font-weight: bold\">)</span>,\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #808000; text-decoration-color: #808000\">model</span>=<span style=\"color: #800080; text-decoration-color: #800080\">MISSING</span>,\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #808000; text-decoration-color: #808000\">optimizer</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">AdamConfig</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">name</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'torch.optim.Adam'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">lr</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.2</span>, <span style=\"color: #808000; text-decoration-color: #808000\">betas</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.9</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.98</span><span style=\"font-weight: bold\">)</span>, <span style=\"color: #808000; text-decoration-color: #808000\">eps</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1e-09</span>, <span style=\"color: #808000; text-decoration-color: #808000\">weight_decay</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0</span><span style=\"font-weight: bold\">)</span>,\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #808000; text-decoration-color: #808000\">criterion</span>=<span style=\"color: #800080; text-decoration-color: #800080\">MISSING</span>,\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #808000; text-decoration-color: #808000\">scheduler</span>=<span style=\"color: #800080; text-decoration-color: #800080\">MISSING</span>,\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #808000; text-decoration-color: #808000\">trainer</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">TrainerConfig</span><span style=\"font-weight: bold\">(</span>\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">device</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">device</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">type</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'cpu'</span><span style=\"font-weight: bold\">)</span>,\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">max_epochs</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>,\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">log_every_n_steps</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>,\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">eval_every_n_steps</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>,\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">step_scheduler_on_batch_or_epoch</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'epoch'</span>,\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">use_amp</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>,\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">autocast_config</span>=<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'enabled'</span>: <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'dtype'</span>: torch.float16, <span style=\"color: #008000; text-decoration-color: #008000\">'cache_enabled'</span>: <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">}</span>,\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">scaler_config</span>=<span style=\"font-weight: bold\">{</span>\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   │   </span><span style=\"color: #008000; text-decoration-color: #008000\">'enabled'</span>: <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>,\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   │   </span><span style=\"color: #008000; text-decoration-color: #008000\">'init_scale'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">65536.0</span>,\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   │   </span><span style=\"color: #008000; text-decoration-color: #008000\">'growth_factor'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2.0</span>,\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   │   </span><span style=\"color: #008000; text-decoration-color: #008000\">'backoff_factor'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.5</span>,\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   │   </span><span style=\"color: #008000; text-decoration-color: #008000\">'growth_interval'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2000</span>\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"font-weight: bold\">}</span>,\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">gradient_accumulation_steps</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>,\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">clip_grad_norm</span>=<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'max_norm'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.0</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'norm_type'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2.0</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'error_if_nonfinite'</span>: <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'foreach'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span><span style=\"font-weight: bold\">}</span>,\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">apply_weight_decay_to_different_param_groups</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>,\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">save_dir</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'checkpoints'</span>,\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">save_every_epoch</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>,\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">save_best_only</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">monitor</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'valid_this_epoch_average_loss'</span>,\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">mode</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'min'</span>\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"font-weight: bold\">)</span>,\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #808000; text-decoration-color: #808000\">generator</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">GeneratorConfig</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">max_tokens</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1000</span>, <span style=\"color: #808000; text-decoration-color: #808000\">temperature</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.0</span>, <span style=\"color: #808000; text-decoration-color: #808000\">greedy</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>, <span style=\"color: #808000; text-decoration-color: #808000\">top_k</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>, <span style=\"color: #808000; text-decoration-color: #808000\">top_p</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span><span style=\"font-weight: bold\">)</span>\n",
              "<span style=\"font-weight: bold\">)</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1;35mComposer\u001b[0m\u001b[1m(\u001b[0m\n",
              "\u001b[2;32m│   \u001b[0m\u001b[33mconstants\u001b[0m=\u001b[1;35mMaybeConstant\u001b[0m\u001b[1m(\u001b[0m\n",
              "\u001b[2;32m│   │   \u001b[0m\u001b[33mNUM_DIGITS\u001b[0m=\u001b[1;36m2\u001b[0m,\n",
              "\u001b[2;32m│   │   \u001b[0m\u001b[33mTOKENS\u001b[0m=\u001b[1m[\u001b[0m\n",
              "\u001b[2;32m│   │   │   \u001b[0m\u001b[32m'0'\u001b[0m,\n",
              "\u001b[2;32m│   │   │   \u001b[0m\u001b[32m'1'\u001b[0m,\n",
              "\u001b[2;32m│   │   │   \u001b[0m\u001b[32m'2'\u001b[0m,\n",
              "\u001b[2;32m│   │   │   \u001b[0m\u001b[32m'3'\u001b[0m,\n",
              "\u001b[2;32m│   │   │   \u001b[0m\u001b[32m'4'\u001b[0m,\n",
              "\u001b[2;32m│   │   │   \u001b[0m\u001b[32m'5'\u001b[0m,\n",
              "\u001b[2;32m│   │   │   \u001b[0m\u001b[32m'6'\u001b[0m,\n",
              "\u001b[2;32m│   │   │   \u001b[0m\u001b[32m'7'\u001b[0m,\n",
              "\u001b[2;32m│   │   │   \u001b[0m\u001b[32m'8'\u001b[0m,\n",
              "\u001b[2;32m│   │   │   \u001b[0m\u001b[32m'9'\u001b[0m,\n",
              "\u001b[2;32m│   │   │   \u001b[0m\u001b[32m'+'\u001b[0m,\n",
              "\u001b[2;32m│   │   │   \u001b[0m\u001b[32m'*'\u001b[0m,\n",
              "\u001b[2;32m│   │   │   \u001b[0m\u001b[32m'-'\u001b[0m,\n",
              "\u001b[2;32m│   │   │   \u001b[0m\u001b[32m'='\u001b[0m,\n",
              "\u001b[2;32m│   │   │   \u001b[0m\u001b[32m'\u001b[0m\u001b[32m<\u001b[0m\u001b[32mBOS\u001b[0m\u001b[32m>'\u001b[0m\u001b[39m,\u001b[0m\n",
              "\u001b[2;32m│   │   │   \u001b[0m\u001b[32m'<EOS>'\u001b[0m\u001b[39m,\u001b[0m\n",
              "\u001b[2;32m│   │   │   \u001b[0m\u001b[32m'<PAD>'\u001b[0m\u001b[39m,\u001b[0m\n",
              "\u001b[2;32m│   │   │   \u001b[0m\u001b[32m'<UNK\u001b[0m\u001b[32m>\u001b[0m\u001b[32m'\u001b[0m\n",
              "\u001b[2;32m│   │   \u001b[0m\u001b[1m]\u001b[0m\n",
              "\u001b[2;32m│   \u001b[0m\u001b[1m)\u001b[0m,\n",
              "\u001b[2;32m│   \u001b[0m\u001b[33mlogger\u001b[0m=\u001b[1;35mLoggerConfig\u001b[0m\u001b[1m(\u001b[0m\n",
              "\u001b[2;32m│   │   \u001b[0m\u001b[33mlog_file\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
              "\u001b[2;32m│   │   \u001b[0m\u001b[33mmodule_name\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
              "\u001b[2;32m│   │   \u001b[0m\u001b[33mpropagate\u001b[0m=\u001b[3;91mFalse\u001b[0m,\n",
              "\u001b[2;32m│   │   \u001b[0m\u001b[33mlog_root_dir\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
              "\u001b[2;32m│   │   \u001b[0m\u001b[33mrich_handler_config\u001b[0m=\u001b[1m{\u001b[0m\n",
              "\u001b[2;32m│   │   │   \u001b[0m\u001b[32m'level'\u001b[0m: \u001b[32m'INFO'\u001b[0m,\n",
              "\u001b[2;32m│   │   │   \u001b[0m\u001b[32m'console'\u001b[0m: MISSING,\n",
              "\u001b[2;32m│   │   │   \u001b[0m\u001b[32m'show_level'\u001b[0m: \u001b[3;92mTrue\u001b[0m,\n",
              "\u001b[2;32m│   │   │   \u001b[0m\u001b[32m'show_path'\u001b[0m: \u001b[3;92mTrue\u001b[0m,\n",
              "\u001b[2;32m│   │   │   \u001b[0m\u001b[32m'show_time'\u001b[0m: \u001b[3;92mTrue\u001b[0m,\n",
              "\u001b[2;32m│   │   │   \u001b[0m\u001b[32m'rich_tracebacks'\u001b[0m: \u001b[3;92mTrue\u001b[0m,\n",
              "\u001b[2;32m│   │   │   \u001b[0m\u001b[32m'markup'\u001b[0m: \u001b[3;92mTrue\u001b[0m,\n",
              "\u001b[2;32m│   │   │   \u001b[0m\u001b[32m'log_time_format'\u001b[0m: \u001b[32m'\u001b[0m\u001b[32m[\u001b[0m\u001b[32m%Y-%m-%d %H:%M:%S\u001b[0m\u001b[32m]\u001b[0m\u001b[32m'\u001b[0m\n",
              "\u001b[2;32m│   │   \u001b[0m\u001b[1m}\u001b[0m\n",
              "\u001b[2;32m│   \u001b[0m\u001b[1m)\u001b[0m,\n",
              "\u001b[2;32m│   \u001b[0m\u001b[33mglobal_\u001b[0m=\u001b[1;35mMaybeGlobal\u001b[0m\u001b[1m(\u001b[0m\u001b[33mseed\u001b[0m=\u001b[1;36m42\u001b[0m, \u001b[33mdebug\u001b[0m=\u001b[3;92mTrue\u001b[0m, \u001b[33mdebug_samples\u001b[0m=\u001b[1;36m100\u001b[0m\u001b[1m)\u001b[0m,\n",
              "\u001b[2;32m│   \u001b[0m\u001b[33mdata\u001b[0m=\u001b[1;35mDataConfig\u001b[0m\u001b[1m(\u001b[0m\n",
              "\u001b[2;32m│   │   \u001b[0m\u001b[33mcontext_length\u001b[0m=\u001b[1;36m11\u001b[0m,\n",
              "\u001b[2;32m│   │   \u001b[0m\u001b[33mdataset_name\u001b[0m=\u001b[32m'adder_dataset'\u001b[0m,\n",
              "\u001b[2;32m│   │   \u001b[0m\u001b[33mdataset_size\u001b[0m=\u001b[1;36m10000\u001b[0m,\n",
              "\u001b[2;32m│   │   \u001b[0m\u001b[33mdataset_path\u001b[0m=\u001b[32m'./data/adder/adder_dataset.txt'\u001b[0m,\n",
              "\u001b[2;32m│   │   \u001b[0m\u001b[33mdataset_dir\u001b[0m=\u001b[32m'./data/adder'\u001b[0m,\n",
              "\u001b[2;32m│   │   \u001b[0m\u001b[33mdataset_url\u001b[0m=\u001b[32m'https://raw.githubusercontent.com/gao-hongnan/omniverse/dev/omnivault/transformer/projects/adder/assets/adder_dataset.txt'\u001b[0m,\n",
              "\u001b[2;32m│   │   \u001b[0m\u001b[33msplit\u001b[0m=\u001b[1m[\u001b[0m\u001b[1;36m0.7\u001b[0m, \u001b[1;36m0.2\u001b[0m, \u001b[1;36m0.1\u001b[0m\u001b[1m]\u001b[0m,\n",
              "\u001b[2;32m│   │   \u001b[0m\u001b[33mcollate_fn\u001b[0m=\u001b[1m{\u001b[0m\u001b[32m'batch_first'\u001b[0m: \u001b[3;92mTrue\u001b[0m, \u001b[32m'pad_token_id'\u001b[0m: \u001b[1;36m16\u001b[0m\u001b[1m}\u001b[0m,\n",
              "\u001b[2;32m│   │   \u001b[0m\u001b[33mtrain_loader\u001b[0m=\u001b[1m{\u001b[0m\n",
              "\u001b[2;32m│   │   │   \u001b[0m\u001b[32m'batch_size'\u001b[0m: \u001b[1;36m32\u001b[0m,\n",
              "\u001b[2;32m│   │   │   \u001b[0m\u001b[32m'shuffle'\u001b[0m: \u001b[3;92mTrue\u001b[0m,\n",
              "\u001b[2;32m│   │   │   \u001b[0m\u001b[32m'num_workers'\u001b[0m: \u001b[1;36m0\u001b[0m,\n",
              "\u001b[2;32m│   │   │   \u001b[0m\u001b[32m'pin_memory'\u001b[0m: \u001b[3;91mFalse\u001b[0m,\n",
              "\u001b[2;32m│   │   │   \u001b[0m\u001b[32m'drop_last'\u001b[0m: \u001b[3;91mFalse\u001b[0m\n",
              "\u001b[2;32m│   │   \u001b[0m\u001b[1m}\u001b[0m,\n",
              "\u001b[2;32m│   │   \u001b[0m\u001b[33mvalid_loader\u001b[0m=\u001b[1m{\u001b[0m\n",
              "\u001b[2;32m│   │   │   \u001b[0m\u001b[32m'batch_size'\u001b[0m: \u001b[1;36m32\u001b[0m,\n",
              "\u001b[2;32m│   │   │   \u001b[0m\u001b[32m'shuffle'\u001b[0m: \u001b[3;91mFalse\u001b[0m,\n",
              "\u001b[2;32m│   │   │   \u001b[0m\u001b[32m'num_workers'\u001b[0m: \u001b[1;36m0\u001b[0m,\n",
              "\u001b[2;32m│   │   │   \u001b[0m\u001b[32m'pin_memory'\u001b[0m: \u001b[3;91mFalse\u001b[0m,\n",
              "\u001b[2;32m│   │   │   \u001b[0m\u001b[32m'drop_last'\u001b[0m: \u001b[3;91mFalse\u001b[0m\n",
              "\u001b[2;32m│   │   \u001b[0m\u001b[1m}\u001b[0m,\n",
              "\u001b[2;32m│   │   \u001b[0m\u001b[33mtest_loader\u001b[0m=\u001b[1m{\u001b[0m\n",
              "\u001b[2;32m│   │   │   \u001b[0m\u001b[32m'batch_size'\u001b[0m: \u001b[1;36m128\u001b[0m,\n",
              "\u001b[2;32m│   │   │   \u001b[0m\u001b[32m'shuffle'\u001b[0m: \u001b[3;91mFalse\u001b[0m,\n",
              "\u001b[2;32m│   │   │   \u001b[0m\u001b[32m'num_workers'\u001b[0m: \u001b[1;36m0\u001b[0m,\n",
              "\u001b[2;32m│   │   │   \u001b[0m\u001b[32m'pin_memory'\u001b[0m: \u001b[3;91mFalse\u001b[0m,\n",
              "\u001b[2;32m│   │   │   \u001b[0m\u001b[32m'drop_last'\u001b[0m: \u001b[3;91mFalse\u001b[0m\n",
              "\u001b[2;32m│   │   \u001b[0m\u001b[1m}\u001b[0m\n",
              "\u001b[2;32m│   \u001b[0m\u001b[1m)\u001b[0m,\n",
              "\u001b[2;32m│   \u001b[0m\u001b[33mmodel\u001b[0m=\u001b[35mMISSING\u001b[0m,\n",
              "\u001b[2;32m│   \u001b[0m\u001b[33moptimizer\u001b[0m=\u001b[1;35mAdamConfig\u001b[0m\u001b[1m(\u001b[0m\u001b[33mname\u001b[0m=\u001b[32m'torch.optim.Adam'\u001b[0m, \u001b[33mlr\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.2\u001b[0m, \u001b[33mbetas\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m0.9\u001b[0m, \u001b[1;36m0.98\u001b[0m\u001b[1m)\u001b[0m, \u001b[33meps\u001b[0m=\u001b[1;36m1e\u001b[0m\u001b[1;36m-09\u001b[0m, \u001b[33mweight_decay\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.0\u001b[0m\u001b[1m)\u001b[0m,\n",
              "\u001b[2;32m│   \u001b[0m\u001b[33mcriterion\u001b[0m=\u001b[35mMISSING\u001b[0m,\n",
              "\u001b[2;32m│   \u001b[0m\u001b[33mscheduler\u001b[0m=\u001b[35mMISSING\u001b[0m,\n",
              "\u001b[2;32m│   \u001b[0m\u001b[33mtrainer\u001b[0m=\u001b[1;35mTrainerConfig\u001b[0m\u001b[1m(\u001b[0m\n",
              "\u001b[2;32m│   │   \u001b[0m\u001b[33mdevice\u001b[0m=\u001b[1;35mdevice\u001b[0m\u001b[1m(\u001b[0m\u001b[33mtype\u001b[0m=\u001b[32m'cpu'\u001b[0m\u001b[1m)\u001b[0m,\n",
              "\u001b[2;32m│   │   \u001b[0m\u001b[33mmax_epochs\u001b[0m=\u001b[1;36m2\u001b[0m,\n",
              "\u001b[2;32m│   │   \u001b[0m\u001b[33mlog_every_n_steps\u001b[0m=\u001b[1;36m1\u001b[0m,\n",
              "\u001b[2;32m│   │   \u001b[0m\u001b[33meval_every_n_steps\u001b[0m=\u001b[1;36m1\u001b[0m,\n",
              "\u001b[2;32m│   │   \u001b[0m\u001b[33mstep_scheduler_on_batch_or_epoch\u001b[0m=\u001b[32m'epoch'\u001b[0m,\n",
              "\u001b[2;32m│   │   \u001b[0m\u001b[33muse_amp\u001b[0m=\u001b[3;91mFalse\u001b[0m,\n",
              "\u001b[2;32m│   │   \u001b[0m\u001b[33mautocast_config\u001b[0m=\u001b[1m{\u001b[0m\u001b[32m'enabled'\u001b[0m: \u001b[3;91mFalse\u001b[0m, \u001b[32m'dtype'\u001b[0m: torch.float16, \u001b[32m'cache_enabled'\u001b[0m: \u001b[3;92mTrue\u001b[0m\u001b[1m}\u001b[0m,\n",
              "\u001b[2;32m│   │   \u001b[0m\u001b[33mscaler_config\u001b[0m=\u001b[1m{\u001b[0m\n",
              "\u001b[2;32m│   │   │   \u001b[0m\u001b[32m'enabled'\u001b[0m: \u001b[3;91mFalse\u001b[0m,\n",
              "\u001b[2;32m│   │   │   \u001b[0m\u001b[32m'init_scale'\u001b[0m: \u001b[1;36m65536.0\u001b[0m,\n",
              "\u001b[2;32m│   │   │   \u001b[0m\u001b[32m'growth_factor'\u001b[0m: \u001b[1;36m2.0\u001b[0m,\n",
              "\u001b[2;32m│   │   │   \u001b[0m\u001b[32m'backoff_factor'\u001b[0m: \u001b[1;36m0.5\u001b[0m,\n",
              "\u001b[2;32m│   │   │   \u001b[0m\u001b[32m'growth_interval'\u001b[0m: \u001b[1;36m2000\u001b[0m\n",
              "\u001b[2;32m│   │   \u001b[0m\u001b[1m}\u001b[0m,\n",
              "\u001b[2;32m│   │   \u001b[0m\u001b[33mgradient_accumulation_steps\u001b[0m=\u001b[1;36m1\u001b[0m,\n",
              "\u001b[2;32m│   │   \u001b[0m\u001b[33mclip_grad_norm\u001b[0m=\u001b[1m{\u001b[0m\u001b[32m'max_norm'\u001b[0m: \u001b[1;36m1.0\u001b[0m, \u001b[32m'norm_type'\u001b[0m: \u001b[1;36m2.0\u001b[0m, \u001b[32m'error_if_nonfinite'\u001b[0m: \u001b[3;91mFalse\u001b[0m, \u001b[32m'foreach'\u001b[0m: \u001b[3;35mNone\u001b[0m\u001b[1m}\u001b[0m,\n",
              "\u001b[2;32m│   │   \u001b[0m\u001b[33mapply_weight_decay_to_different_param_groups\u001b[0m=\u001b[3;91mFalse\u001b[0m,\n",
              "\u001b[2;32m│   │   \u001b[0m\u001b[33msave_dir\u001b[0m=\u001b[32m'checkpoints'\u001b[0m,\n",
              "\u001b[2;32m│   │   \u001b[0m\u001b[33msave_every_epoch\u001b[0m=\u001b[3;91mFalse\u001b[0m,\n",
              "\u001b[2;32m│   │   \u001b[0m\u001b[33msave_best_only\u001b[0m=\u001b[3;92mTrue\u001b[0m,\n",
              "\u001b[2;32m│   │   \u001b[0m\u001b[33mmonitor\u001b[0m=\u001b[32m'valid_this_epoch_average_loss'\u001b[0m,\n",
              "\u001b[2;32m│   │   \u001b[0m\u001b[33mmode\u001b[0m=\u001b[32m'min'\u001b[0m\n",
              "\u001b[2;32m│   \u001b[0m\u001b[1m)\u001b[0m,\n",
              "\u001b[2;32m│   \u001b[0m\u001b[33mgenerator\u001b[0m=\u001b[1;35mGeneratorConfig\u001b[0m\u001b[1m(\u001b[0m\u001b[33mmax_tokens\u001b[0m=\u001b[1;36m1000\u001b[0m, \u001b[33mtemperature\u001b[0m=\u001b[1;36m1\u001b[0m\u001b[1;36m.0\u001b[0m, \u001b[33mgreedy\u001b[0m=\u001b[3;91mFalse\u001b[0m, \u001b[33mtop_k\u001b[0m=\u001b[3;35mNone\u001b[0m, \u001b[33mtop_p\u001b[0m=\u001b[3;35mNone\u001b[0m\u001b[1m)\u001b[0m\n",
              "\u001b[1m)\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "constants: MaybeConstant = MaybeConstant(NUM_DIGITS=2, TOKENS=[\n",
        "            \"0\",\n",
        "            \"1\",\n",
        "            \"2\",\n",
        "            \"3\",\n",
        "            \"4\",\n",
        "            \"5\",\n",
        "            \"6\",\n",
        "            \"7\",\n",
        "            \"8\",\n",
        "            \"9\",\n",
        "            \"+\",\n",
        "            \"*\",\n",
        "            \"-\",\n",
        "            \"=\",\n",
        "            \"<BOS>\",\n",
        "            \"<EOS>\",\n",
        "            \"<PAD>\",\n",
        "            \"<UNK>\",\n",
        "        ]\n",
        ")\n",
        "global_config: MaybeGlobal = MaybeGlobal(seed=42, debug=True, debug_samples=100)\n",
        "data_config: DataConfig = DataConfig(**cfg.data)\n",
        "optimizer_config = AdamConfig(name=\"torch.optim.Adam\", lr=0.2, betas=(0.9, 0.98), eps=1e-9)\n",
        "trainer_config = TrainerConfig(device=\"cpu\")\n",
        "\n",
        "composer = Composer(constants=constants, global_=global_config, data=data_config, optimizer=optimizer_config, trainer=trainer_config)\n",
        "pprint(composer)\n",
        "\n",
        "LOGGER = RichLogger(**composer.logger.model_dump(mode=\"python\")).logger\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Reproducibility\n",
        "\n",
        "Reproducibility in deep learning ensures that experiments can be repeated with\n",
        "identical results, critical for verifying research findings and deploying\n",
        "reliable models. Distributed training introduces complexity because it involves\n",
        "multiple computation units which may not synchronize their random states\n",
        "perfectly. If training is paused and resumed, ensuring each unit starts with the\n",
        "correct seed to reproduce the exact computational path becomes challenging. To\n",
        "address this, one can find more sophisticated examples in libraries like\n",
        "Composer, where the whole library's core is built around training deep neural\n",
        "nets in any environment (distributed or not) with reproducibility in mind.\n",
        "\n",
        "```{admonition} References\n",
        ":class: seealso\n",
        "\n",
        "-   [Composer](https://github.com/mosaicml/composer/blob/dev/composer/utils/reproducibility.py)\n",
        "-   [PyTorch Reproducibility](https://pytorch.org/docs/stable/notes/randomness.html)\n",
        "-   [PyTorch Worker](https://pytorch.org/docs/stable/notes/randomness.html#dataloader)\n",
        "-   [PyTorch deterministic algorithms](https://pytorch.org/docs/stable/generated/torch.use_deterministic_algorithms.html)\n",
        "-   [CUBLAS reproducibility](https://docs.nvidia.com/cuda/cublas/index.html#cublasApi_reproducibility)\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 119,
      "metadata": {
        "id": "mWV1lAHkrdzN"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[('seed', <class 'int'>, 1992), ('seed_torch', <class 'bool'>, True), ('set_torch_deterministic', <class 'bool'>, True)]\n",
            "\n",
            "\n",
            "Seeds all relevant random number generators to ensure reproducible\n",
            "outcomes. Optionally seeds PyTorch and activates deterministic\n",
            "behavior in PyTorch based on the flags provided.\n",
            "\n",
            "Parameters\n",
            "----------\n",
            "seed : int, default 1992\n",
            "    The seed number for reproducibility.\n",
            "seed_torch : bool, default True\n",
            "    If True, seeds PyTorch's RNGs.\n",
            "set_torch_deterministic : bool, default True\n",
            "    If True, activates deterministic mode in PyTorch.\n",
            "\n",
            "Returns\n",
            "-------\n",
            "seed : int\n",
            "    The seed used for reproducibility.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "42"
            ]
          },
          "execution_count": 119,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "print(get_field_annotations(func_or_method = seed_all)[0])\n",
        "print(\"\\n\")\n",
        "print(inspect.getdoc(seed_all))\n",
        "\n",
        "seed_all(composer.global_.seed, seed_torch=True, set_torch_deterministic=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Vocabulary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 120,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span>\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #008000; text-decoration-color: #008000\">'0'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>,\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #008000; text-decoration-color: #008000\">'1'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>,\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #008000; text-decoration-color: #008000\">'2'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>,\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #008000; text-decoration-color: #008000\">'3'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>,\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #008000; text-decoration-color: #008000\">'4'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>,\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #008000; text-decoration-color: #008000\">'5'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>,\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #008000; text-decoration-color: #008000\">'6'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6</span>,\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #008000; text-decoration-color: #008000\">'7'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">7</span>,\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #008000; text-decoration-color: #008000\">'8'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8</span>,\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #008000; text-decoration-color: #008000\">'9'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">9</span>,\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #008000; text-decoration-color: #008000\">'+'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span>,\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #008000; text-decoration-color: #008000\">'*'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">11</span>,\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #008000; text-decoration-color: #008000\">'-'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">12</span>,\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #008000; text-decoration-color: #008000\">'='</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">13</span>,\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #008000; text-decoration-color: #008000\">'&lt;BOS&gt;'</span><span style=\"color: #000000; text-decoration-color: #000000\">: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">14</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #008000; text-decoration-color: #008000\">'&lt;EOS&gt;'</span><span style=\"color: #000000; text-decoration-color: #000000\">: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">15</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #008000; text-decoration-color: #008000\">'&lt;PAD&gt;'</span><span style=\"color: #000000; text-decoration-color: #000000\">: </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">16</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #008000; text-decoration-color: #008000\">'&lt;UNK&gt;'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">17</span>\n",
              "<span style=\"font-weight: bold\">}</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m{\u001b[0m\n",
              "\u001b[2;32m│   \u001b[0m\u001b[32m'0'\u001b[0m: \u001b[1;36m0\u001b[0m,\n",
              "\u001b[2;32m│   \u001b[0m\u001b[32m'1'\u001b[0m: \u001b[1;36m1\u001b[0m,\n",
              "\u001b[2;32m│   \u001b[0m\u001b[32m'2'\u001b[0m: \u001b[1;36m2\u001b[0m,\n",
              "\u001b[2;32m│   \u001b[0m\u001b[32m'3'\u001b[0m: \u001b[1;36m3\u001b[0m,\n",
              "\u001b[2;32m│   \u001b[0m\u001b[32m'4'\u001b[0m: \u001b[1;36m4\u001b[0m,\n",
              "\u001b[2;32m│   \u001b[0m\u001b[32m'5'\u001b[0m: \u001b[1;36m5\u001b[0m,\n",
              "\u001b[2;32m│   \u001b[0m\u001b[32m'6'\u001b[0m: \u001b[1;36m6\u001b[0m,\n",
              "\u001b[2;32m│   \u001b[0m\u001b[32m'7'\u001b[0m: \u001b[1;36m7\u001b[0m,\n",
              "\u001b[2;32m│   \u001b[0m\u001b[32m'8'\u001b[0m: \u001b[1;36m8\u001b[0m,\n",
              "\u001b[2;32m│   \u001b[0m\u001b[32m'9'\u001b[0m: \u001b[1;36m9\u001b[0m,\n",
              "\u001b[2;32m│   \u001b[0m\u001b[32m'+'\u001b[0m: \u001b[1;36m10\u001b[0m,\n",
              "\u001b[2;32m│   \u001b[0m\u001b[32m'*'\u001b[0m: \u001b[1;36m11\u001b[0m,\n",
              "\u001b[2;32m│   \u001b[0m\u001b[32m'-'\u001b[0m: \u001b[1;36m12\u001b[0m,\n",
              "\u001b[2;32m│   \u001b[0m\u001b[32m'='\u001b[0m: \u001b[1;36m13\u001b[0m,\n",
              "\u001b[2;32m│   \u001b[0m\u001b[32m'\u001b[0m\u001b[32m<\u001b[0m\u001b[32mBOS\u001b[0m\u001b[32m>'\u001b[0m\u001b[39m: \u001b[0m\u001b[1;36m14\u001b[0m\u001b[39m,\u001b[0m\n",
              "\u001b[2;32m│   \u001b[0m\u001b[32m'<EOS>'\u001b[0m\u001b[39m: \u001b[0m\u001b[1;36m15\u001b[0m\u001b[39m,\u001b[0m\n",
              "\u001b[2;32m│   \u001b[0m\u001b[32m'<PAD>'\u001b[0m\u001b[39m: \u001b[0m\u001b[1;36m16\u001b[0m\u001b[39m,\u001b[0m\n",
              "\u001b[2;32m│   \u001b[0m\u001b[32m'<UNK\u001b[0m\u001b[32m>\u001b[0m\u001b[32m'\u001b[0m: \u001b[1;36m17\u001b[0m\n",
              "\u001b[1m}\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">{</span>\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'0'</span>,\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'1'</span>,\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'2'</span>,\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'3'</span>,\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'4'</span>,\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'5'</span>,\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'6'</span>,\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">7</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'7'</span>,\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'8'</span>,\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">9</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'9'</span>,\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'+'</span>,\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">11</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'*'</span>,\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">12</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'-'</span>,\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">13</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'='</span>,\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">14</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'&lt;BOS&gt;'</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">15</span><span style=\"color: #000000; text-decoration-color: #000000\">: </span><span style=\"color: #008000; text-decoration-color: #008000\">'&lt;EOS&gt;'</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">16</span><span style=\"color: #000000; text-decoration-color: #000000\">: </span><span style=\"color: #008000; text-decoration-color: #008000\">'&lt;PAD&gt;'</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">17</span><span style=\"color: #000000; text-decoration-color: #000000\">: </span><span style=\"color: #008000; text-decoration-color: #008000\">'&lt;UNK&gt;'</span>\n",
              "<span style=\"font-weight: bold\">}</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m{\u001b[0m\n",
              "\u001b[2;32m│   \u001b[0m\u001b[1;36m0\u001b[0m: \u001b[32m'0'\u001b[0m,\n",
              "\u001b[2;32m│   \u001b[0m\u001b[1;36m1\u001b[0m: \u001b[32m'1'\u001b[0m,\n",
              "\u001b[2;32m│   \u001b[0m\u001b[1;36m2\u001b[0m: \u001b[32m'2'\u001b[0m,\n",
              "\u001b[2;32m│   \u001b[0m\u001b[1;36m3\u001b[0m: \u001b[32m'3'\u001b[0m,\n",
              "\u001b[2;32m│   \u001b[0m\u001b[1;36m4\u001b[0m: \u001b[32m'4'\u001b[0m,\n",
              "\u001b[2;32m│   \u001b[0m\u001b[1;36m5\u001b[0m: \u001b[32m'5'\u001b[0m,\n",
              "\u001b[2;32m│   \u001b[0m\u001b[1;36m6\u001b[0m: \u001b[32m'6'\u001b[0m,\n",
              "\u001b[2;32m│   \u001b[0m\u001b[1;36m7\u001b[0m: \u001b[32m'7'\u001b[0m,\n",
              "\u001b[2;32m│   \u001b[0m\u001b[1;36m8\u001b[0m: \u001b[32m'8'\u001b[0m,\n",
              "\u001b[2;32m│   \u001b[0m\u001b[1;36m9\u001b[0m: \u001b[32m'9'\u001b[0m,\n",
              "\u001b[2;32m│   \u001b[0m\u001b[1;36m10\u001b[0m: \u001b[32m'+'\u001b[0m,\n",
              "\u001b[2;32m│   \u001b[0m\u001b[1;36m11\u001b[0m: \u001b[32m'*'\u001b[0m,\n",
              "\u001b[2;32m│   \u001b[0m\u001b[1;36m12\u001b[0m: \u001b[32m'-'\u001b[0m,\n",
              "\u001b[2;32m│   \u001b[0m\u001b[1;36m13\u001b[0m: \u001b[32m'='\u001b[0m,\n",
              "\u001b[2;32m│   \u001b[0m\u001b[1;36m14\u001b[0m: \u001b[32m'\u001b[0m\u001b[32m<\u001b[0m\u001b[32mBOS\u001b[0m\u001b[32m>'\u001b[0m\u001b[39m,\u001b[0m\n",
              "\u001b[2;32m│   \u001b[0m\u001b[1;36m15\u001b[0m\u001b[39m: \u001b[0m\u001b[32m'<EOS>'\u001b[0m\u001b[39m,\u001b[0m\n",
              "\u001b[2;32m│   \u001b[0m\u001b[1;36m16\u001b[0m\u001b[39m: \u001b[0m\u001b[32m'<PAD>'\u001b[0m\u001b[39m,\u001b[0m\n",
              "\u001b[2;32m│   \u001b[0m\u001b[1;36m17\u001b[0m\u001b[39m: \u001b[0m\u001b[32m'<UNK\u001b[0m\u001b[32m>\u001b[0m\u001b[32m'\u001b[0m\n",
              "\u001b[1m}\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">18</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1;36m18\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "vocabulary = AdderVocabulary.from_tokens(tokens=constants.TOKENS, num_digits=constants.NUM_DIGITS)  # type: ignore[attr-defined]\n",
        "token_to_index = vocabulary.token_to_index\n",
        "index_to_token = vocabulary.index_to_token\n",
        "vocab_size = vocabulary.vocab_size\n",
        "pprint(token_to_index)\n",
        "pprint(index_to_token)\n",
        "pprint(vocab_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Assign `vocab_size` to `composer.model` because we don't want to hardcode\n",
        "`vocab_size` beforehand, and want to derive concrete values from the\n",
        "`Vocabulary` object."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 121,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[2024-03-21 23:01:07] </span><span style=\"color: #800000; text-decoration-color: #800000\">ERROR   </span> _Missing instances are immutable                                     <a href=\"file:///var/folders/cy/12tl7y917h51vcpszr1tw0nr0000gn/T/ipykernel_11692/2890644827.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2890644827.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///var/folders/cy/12tl7y917h51vcpszr1tw0nr0000gn/T/ipykernel_11692/2890644827.py#4\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">4</span></a>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[2;36m[2024-03-21 23:01:07]\u001b[0m\u001b[2;36m \u001b[0m\u001b[31mERROR   \u001b[0m _Missing instances are immutable                                     \u001b]8;id=288389;file:///var/folders/cy/12tl7y917h51vcpszr1tw0nr0000gn/T/ipykernel_11692/2890644827.py\u001b\\\u001b[2m2890644827.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=256787;file:///var/folders/cy/12tl7y917h51vcpszr1tw0nr0000gn/T/ipykernel_11692/2890644827.py#4\u001b\\\u001b[2m4\u001b[0m\u001b]8;;\u001b\\\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[2024-03-21 23:01:07] </span><span style=\"color: #800000; text-decoration-color: #800000\">ERROR   </span> _Missing instances are immutable                                     <a href=\"file:///var/folders/cy/12tl7y917h51vcpszr1tw0nr0000gn/T/ipykernel_11692/2890644827.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2890644827.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///var/folders/cy/12tl7y917h51vcpszr1tw0nr0000gn/T/ipykernel_11692/2890644827.py#4\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">4</span></a>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[2;36m[2024-03-21 23:01:07]\u001b[0m\u001b[2;36m \u001b[0m\u001b[31mERROR   \u001b[0m _Missing instances are immutable                                     \u001b]8;id=709570;file:///var/folders/cy/12tl7y917h51vcpszr1tw0nr0000gn/T/ipykernel_11692/2890644827.py\u001b\\\u001b[2m2890644827.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=776646;file:///var/folders/cy/12tl7y917h51vcpszr1tw0nr0000gn/T/ipykernel_11692/2890644827.py#4\u001b\\\u001b[2m4\u001b[0m\u001b]8;;\u001b\\\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[2024-03-21 23:01:07] </span><span style=\"color: #800000; text-decoration-color: #800000\">ERROR   </span> _Missing instances are immutable                                     <a href=\"file:///var/folders/cy/12tl7y917h51vcpszr1tw0nr0000gn/T/ipykernel_11692/2890644827.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2890644827.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///var/folders/cy/12tl7y917h51vcpszr1tw0nr0000gn/T/ipykernel_11692/2890644827.py#4\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">4</span></a>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[2;36m[2024-03-21 23:01:07]\u001b[0m\u001b[2;36m \u001b[0m\u001b[31mERROR   \u001b[0m _Missing instances are immutable                                     \u001b]8;id=442417;file:///var/folders/cy/12tl7y917h51vcpszr1tw0nr0000gn/T/ipykernel_11692/2890644827.py\u001b\\\u001b[2m2890644827.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=33326;file:///var/folders/cy/12tl7y917h51vcpszr1tw0nr0000gn/T/ipykernel_11692/2890644827.py#4\u001b\\\u001b[2m4\u001b[0m\u001b]8;;\u001b\\\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "try:\n",
        "    composer.model.vocab_size = vocab_size\n",
        "except AttributeError as err:\n",
        "    LOGGER.error(err)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Ah okay haha, this is the price of writing overly complex and useless code to\n",
        "look fancy and you end up a mess. Anyways, we will handle this later on where\n",
        "we can explicitly instantiate the model config class."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Tokenization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 122,
      "metadata": {},
      "outputs": [],
      "source": [
        "tokenizer = AdderTokenizer(vocabulary=vocabulary)\n",
        "assert tokenizer.vocabulary.token_to_index == token_to_index\n",
        "assert tokenizer.vocabulary.index_to_token == index_to_token"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 123,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">14</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">15</span><span style=\"font-weight: bold\">]</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m[\u001b[0m\u001b[1;36m14\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m15\u001b[0m\u001b[1m]\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "pprint(tokenizer.encode(\"1\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 124,
      "metadata": {},
      "outputs": [],
      "source": [
        "sequence = \"15+57=072\"\n",
        "sequences = [\"15+57=072\", \"01+02=003\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 125,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Encoded sentence: [14, 1, 5, 10, 5, 7, 13, 0, 7, 2, 15]\n",
            "Decoded sentence: 15+57=072\n"
          ]
        }
      ],
      "source": [
        "encoded_sentence = tokenizer.encode(sequence)\n",
        "print(f\"Encoded sentence: {encoded_sentence}\")\n",
        "\n",
        "decoded_sentence = tokenizer.decode(encoded_sentence)\n",
        "print(f\"Decoded sentence: {decoded_sentence}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 126,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Encoded sentences: [[14, 1, 5, 10, 5, 7, 13, 0, 7, 2, 15], [14, 0, 1, 10, 0, 2, 13, 0, 0, 3, 15]]\n",
            "Decoded sentences: ['15+57=072', '01+02=003']\n"
          ]
        }
      ],
      "source": [
        "encoded_sentences = tokenizer.encode_batch(sequences)  # type: ignore[attr-defined]\n",
        "print(f\"Encoded sentences: {encoded_sentences}\")\n",
        "decoded_sentences = tokenizer.decode_batch(encoded_sentences)  # type: ignore[attr-defined]\n",
        "print(f\"Decoded sentences: {decoded_sentences}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 127,
      "metadata": {},
      "outputs": [],
      "source": [
        "# PAD = vocabulary.token_to_index[vocabulary.PAD]\n",
        "# UNK = vocabulary.token_to_index[vocabulary.UNK]\n",
        "# ADD = vocabulary.token_to_index[vocabulary.ADD]\n",
        "# EQUAL = vocabulary.token_to_index[vocabulary.EQUAL]\n",
        "# BOS = vocabulary.token_to_index[vocabulary.BOS]\n",
        "# EOS = vocabulary.token_to_index[vocabulary.EOS]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Create Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 128,
      "metadata": {
        "id": "ZX9ORv5IrdzR"
      },
      "outputs": [],
      "source": [
        "def pad_number(num: int, length: int) -> str:\n",
        "    \"\"\"\n",
        "    Pad numbers with zeros in front so that they have uniform length.\n",
        "\n",
        "    Note, if a + b = c and num digits allowed to add is 2, then for\n",
        "    a and b we always pad to length 2, but for c we always pad to length 3.\n",
        "\n",
        "    Example\n",
        "    -------\n",
        "    6 + 90 = 96 -> 06 + 90 = 096\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    num : int\n",
        "        Number to be padded.\n",
        "    num_digits : int\n",
        "        Length of the resulting padded number string.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    str\n",
        "        Padded number string.\n",
        "    \"\"\"\n",
        "    return str(num).zfill(length)\n",
        "\n",
        "\n",
        "def equation_to_string(a: int, b: int, c: int, num_digits: int) -> str:\n",
        "    \"\"\"\n",
        "    Formats the addition equation as a string.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    a : int\n",
        "        First addend.\n",
        "    b : int\n",
        "        Second addend.\n",
        "    c : int\n",
        "        Sum of a and b.\n",
        "    num_digits : int\n",
        "        Number of digits each number in the equation should have.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    str\n",
        "        Formatted equation string.\n",
        "    \"\"\"\n",
        "    padded_a = pad_number(a, num_digits)\n",
        "    padded_b = pad_number(b, num_digits)\n",
        "    padded_c = pad_number(c, num_digits + 1) # note the padding here!\n",
        "    return f\"{padded_a}+{padded_b}={padded_c}\"\n",
        "\n",
        "def decode_equation(vocab: AdderVocabulary, equation: torch.Tensor | List[int]) -> str:\n",
        "    \"\"\"\n",
        "    Convert an equation in list format to string format.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    equation : List[int]\n",
        "        The equation in list format.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    str\n",
        "        The equation in string format.\n",
        "    \"\"\"\n",
        "    if isinstance(equation, torch.Tensor):\n",
        "        equation = equation.tolist()\n",
        "\n",
        "    UNK = vocab.token_to_index[vocab.UNK]\n",
        "    decoded_equation = \"\".join([str(index_to_token.get(x, UNK)) for x in equation])\n",
        "    return decoded_equation.replace(\"<BOS>\", \"\").replace(\"<EOS>\", \"\")\n",
        "\n",
        "def batch_decode_equation(vocab: AdderVocabulary, equations: torch.Tensor | List[List[int]]) -> List[str]:\n",
        "    decoded_equations = []\n",
        "    for equation in equations:\n",
        "        decoded_equation = decode_equation(vocab, equation)\n",
        "        decoded_equations.append(decoded_equation)\n",
        "    return decoded_equations\n",
        "\n",
        "def encode_equation(vocab: AdderVocabulary, equation: str, num_digits: int, device: torch.device) -> torch.Tensor:\n",
        "    \"\"\"\n",
        "    Convert an equation (up to the equal sign in it) in string format to a list.\n",
        "\n",
        "    Parameters\n",
        "    ----------\n",
        "    equation : str\n",
        "        The equation in string format.\n",
        "    num_digits : int\n",
        "        Number of digits each number in the equation should have.\n",
        "    device : torch.device\n",
        "        The device to which the tensor should be sent.\n",
        "\n",
        "    Returns\n",
        "    -------\n",
        "    torch.Tensor\n",
        "        The equation in list format as a tensor.\n",
        "    \"\"\"\n",
        "    plus_idx = equation.index(vocab.ADD)\n",
        "    equal_idx = equation.index(vocab.EQUAL)\n",
        "\n",
        "    BOS = vocab.token_to_index[vocab.BOS]\n",
        "    UNK = vocab.token_to_index[vocab.UNK]\n",
        "\n",
        "    a = pad_number(int(equation[:plus_idx]), num_digits)\n",
        "    b = pad_number(int(equation[plus_idx + 1:equal_idx]), num_digits)\n",
        "\n",
        "    new_equation = f\"{a}+{b}=\"\n",
        "\n",
        "    return torch.tensor(\n",
        "        [BOS] + [token_to_index.get(n, UNK) for n in new_equation],\n",
        "        dtype=torch.int\n",
        "    ).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 129,
      "metadata": {
        "id": "SovDUghLrdzR"
      },
      "outputs": [],
      "source": [
        "def create_add_dataset(\n",
        "    vocab: AdderVocabulary, num_digits: int, dataset_size: int, rng_seed: int = 1337\n",
        ") -> Tuple[List[torch.Tensor], List[str]]:\n",
        "    BOS = vocab.token_to_index[vocab.BOS]\n",
        "    EOS = vocab.token_to_index[vocab.EOS]\n",
        "    UNK = vocab.token_to_index[vocab.UNK]\n",
        "\n",
        "    rng = torch.Generator()\n",
        "    rng.manual_seed(rng_seed)\n",
        "\n",
        "    max_num = 10**num_digits - 1\n",
        "\n",
        "    dataset_str = []\n",
        "    for _ in range(dataset_size):\n",
        "        a = torch.randint(low=0, high=max_num + 1, size=(1,), generator=rng).item()\n",
        "        b = torch.randint(low=0, high=max_num + 1, size=(1,), generator=rng).item()\n",
        "        c = a + b\n",
        "\n",
        "        equation = equation_to_string(a, b, c, num_digits)\n",
        "\n",
        "        dataset_str.append(equation)\n",
        "\n",
        "    dataset_tensor = [\n",
        "        torch.tensor([BOS] + [token_to_index.get(n, UNK) for n in x] + [EOS])\n",
        "        for x in dataset_str\n",
        "    ]\n",
        "    return dataset_tensor, dataset_str"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 130,
      "metadata": {
        "id": "xEfK777ErdzR",
        "outputId": "20b75567-38b1-4e96-9892-08f60d18195d"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[</span>\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">tensor</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">14</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">7</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">13</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">7</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">15</span><span style=\"font-weight: bold\">])</span>,\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">tensor</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">14</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">9</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">13</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">9</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">15</span><span style=\"font-weight: bold\">])</span>,\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">tensor</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">14</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">9</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">13</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">15</span><span style=\"font-weight: bold\">])</span>,\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">tensor</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">14</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">13</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">15</span><span style=\"font-weight: bold\">])</span>\n",
              "<span style=\"font-weight: bold\">]</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m[\u001b[0m\n",
              "\u001b[2;32m│   \u001b[0m\u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m14\u001b[0m,  \u001b[1;36m1\u001b[0m,  \u001b[1;36m5\u001b[0m, \u001b[1;36m10\u001b[0m,  \u001b[1;36m5\u001b[0m,  \u001b[1;36m7\u001b[0m, \u001b[1;36m13\u001b[0m,  \u001b[1;36m0\u001b[0m,  \u001b[1;36m7\u001b[0m,  \u001b[1;36m2\u001b[0m, \u001b[1;36m15\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m,\n",
              "\u001b[2;32m│   \u001b[0m\u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m14\u001b[0m,  \u001b[1;36m9\u001b[0m,  \u001b[1;36m2\u001b[0m, \u001b[1;36m10\u001b[0m,  \u001b[1;36m0\u001b[0m,  \u001b[1;36m0\u001b[0m, \u001b[1;36m13\u001b[0m,  \u001b[1;36m0\u001b[0m,  \u001b[1;36m9\u001b[0m,  \u001b[1;36m2\u001b[0m, \u001b[1;36m15\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m,\n",
              "\u001b[2;32m│   \u001b[0m\u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m14\u001b[0m,  \u001b[1;36m9\u001b[0m,  \u001b[1;36m5\u001b[0m, \u001b[1;36m10\u001b[0m,  \u001b[1;36m5\u001b[0m,  \u001b[1;36m3\u001b[0m, \u001b[1;36m13\u001b[0m,  \u001b[1;36m1\u001b[0m,  \u001b[1;36m4\u001b[0m,  \u001b[1;36m8\u001b[0m, \u001b[1;36m15\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m,\n",
              "\u001b[2;32m│   \u001b[0m\u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m14\u001b[0m,  \u001b[1;36m1\u001b[0m,  \u001b[1;36m5\u001b[0m, \u001b[1;36m10\u001b[0m,  \u001b[1;36m1\u001b[0m,  \u001b[1;36m0\u001b[0m, \u001b[1;36m13\u001b[0m,  \u001b[1;36m0\u001b[0m,  \u001b[1;36m2\u001b[0m,  \u001b[1;36m5\u001b[0m, \u001b[1;36m15\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\n",
              "\u001b[1m]\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'15+57=072'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'92+00=092'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'95+53=148'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'15+10=025'</span><span style=\"font-weight: bold\">]</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m[\u001b[0m\u001b[32m'15+\u001b[0m\u001b[32m57\u001b[0m\u001b[32m=\u001b[0m\u001b[32m072\u001b[0m\u001b[32m'\u001b[0m, \u001b[32m'92+\u001b[0m\u001b[32m00\u001b[0m\u001b[32m=\u001b[0m\u001b[32m092\u001b[0m\u001b[32m'\u001b[0m, \u001b[32m'95+\u001b[0m\u001b[32m53\u001b[0m\u001b[32m=\u001b[0m\u001b[32m148\u001b[0m\u001b[32m'\u001b[0m, \u001b[32m'15+\u001b[0m\u001b[32m10\u001b[0m\u001b[32m=\u001b[0m\u001b[32m025\u001b[0m\u001b[32m'\u001b[0m\u001b[1m]\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "dataset_tensor, dataset_str = create_add_dataset(vocab=vocabulary, num_digits=2, dataset_size=4)\n",
        "pprint(dataset_tensor)\n",
        "pprint(dataset_str)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 131,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Decoded equation: 15+57=072\n"
          ]
        }
      ],
      "source": [
        "print(f\"Decoded equation: {decode_equation(vocabulary, dataset_tensor[0])}\")\n",
        "assert (\n",
        "    decode_equation(vocabulary, dataset_tensor[0])\n",
        "    == dataset_str[0]\n",
        "    == decode_equation(vocabulary, [15, 1, 5, 10, 5, 7, 13, 0, 7, 2, 14])\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "if we encode equation, we can encode up to equal sign like below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 132,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Encoded equation: tensor([14,  1,  5, 10,  5,  7, 13], dtype=torch.int32)\n"
          ]
        }
      ],
      "source": [
        "print(f\"Encoded equation: {encode_equation(vocabulary, dataset_str[0], num_digits=2, device=composer.trainer.device)}\")\n",
        "\n",
        "torch.testing.assert_close(\n",
        "    encode_equation(vocabulary, dataset_str[0], num_digits=2, device=composer.trainer.device),\n",
        "    torch.tensor([14, 1, 5, 10, 5, 7, 13], dtype=torch.int32),\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Uncomment the below code to generate the dataset into a text file and yes, I am\n",
        "lazy to add a config variable for whether to generate the dataset or not."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 133,
      "metadata": {},
      "outputs": [],
      "source": [
        "# dataset, dataset_str = create_add_dataset(vocab, self.num_digits, self.dataset_size)\n",
        "\n",
        "# write dataset_str to a file\n",
        "# with open(\"dataset_str.txt\", \"w\") as f:\n",
        "#     for item in dataset_str:\n",
        "#         f.write(\"%s\\n\" % item)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Encoding Strategy Overview\n",
        "\n",
        "Our strategy for encoding arithmetic expressions is pretty self-explanatory,\n",
        "where given a string `D1 + D2 = D3`, we encode it as `<BOS>D1+D2=0D3<EOS>`.\n",
        "However, this is verbose for clarity sake. In fact, Karpathy's encoding strategy\n",
        "simplifies arithmetic expressions by concatenating the digits of operands and\n",
        "the result into a single string without explicit symbols for operations or\n",
        "equality. This method relies on a fixed number of digits (`num_digits`) for\n",
        "operands, which streamlines the model's interpretation of the sequence. For\n",
        "example, if `num_digits` is set to 2, every encoded expression is structured to\n",
        "follow a predictable pattern: the first two digits represent the first operand,\n",
        "the next two digits represent the second operand, and the final digits are\n",
        "encoded as 3 digits because the max sum of two 2-digit numbers is 199, which is\n",
        "3 digits. The digits of the result are encoded in reverse order. This\n",
        "counterintuitive approach is designed to align with the GPT model's learning\n",
        "algorithm, facilitating easier learning of the addition operation by mimicking\n",
        "the traditional right-to-left calculation process in addition.\n",
        "\n",
        "To illustrate, let's examine the encoding of arithmetic expressions with\n",
        "`num_digits=2`:\n",
        "\n",
        "For the expression `6 + 39 = 45`, we have the following:\n",
        "\n",
        "-   The first two digits `06` represent the number 6, zero-padded to adhere to\n",
        "    the `num_digits=2` requirement.\n",
        "-   The next two digits `39` represent the number 39, already fitting the digit\n",
        "    requirement.\n",
        "-   The final part `054` represents the result 45, reversed to `54` and preceded\n",
        "    by a zero to maintain the total length of $2n + (n + 1) = 7 $ digits for\n",
        "    `num_digits=2`.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nHs3grM1rdzS"
      },
      "source": [
        "## Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 134,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100   97k  100   97k    0     0   244k      0 --:--:-- --:--:-- --:--:--  244k\n"
          ]
        }
      ],
      "source": [
        "create_directory(composer.data.dataset_dir)\n",
        "download_file(url=composer.data.dataset_url, output_path=composer.data.dataset_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 135,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">(</span>\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">tensor</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">14</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">10</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">7</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">13</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">7</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span><span style=\"font-weight: bold\">])</span>,\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">tensor</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">16</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">16</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">16</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">16</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">16</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">16</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">7</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">15</span><span style=\"font-weight: bold\">])</span>,\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">tensor</span><span style=\"font-weight: bold\">([</span><span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>, <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>, <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>, <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>, <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>, <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>, <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>, <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>, <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>, <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">])</span>,\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">tensor</span><span style=\"font-weight: bold\">([[</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>, <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>, <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>, <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>, <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>, <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>, <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>, <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>, <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>, <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">]</span>,\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"font-weight: bold\">[</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,  <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>, <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>, <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>, <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>, <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>, <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>, <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>, <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>, <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">]</span>,\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"font-weight: bold\">[</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,  <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,  <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>, <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>, <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>, <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>, <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>, <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>, <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>, <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">]</span>,\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"font-weight: bold\">[</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,  <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,  <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,  <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>, <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>, <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>, <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>, <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>, <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>, <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">]</span>,\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"font-weight: bold\">[</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,  <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,  <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,  <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,  <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>, <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>, <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>, <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>, <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>, <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">]</span>,\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"font-weight: bold\">[</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,  <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,  <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,  <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,  <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,  <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>, <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>, <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>, <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>, <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">]</span>,\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"font-weight: bold\">[</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,  <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,  <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,  <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,  <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,  <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,  <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>, <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>, <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>, <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">]</span>,\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"font-weight: bold\">[</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,  <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,  <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,  <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,  <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,  <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,  <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,  <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>, <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>, <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">]</span>,\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"font-weight: bold\">[</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,  <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,  <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,  <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,  <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,  <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,  <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,  <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,  <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>, <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">]</span>,\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"font-weight: bold\">[</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,  <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,  <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,  <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,  <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,  <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,  <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,  <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,  <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,  <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">]])</span>\n",
              "<span style=\"font-weight: bold\">)</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m(\u001b[0m\n",
              "\u001b[2;32m│   \u001b[0m\u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m14\u001b[0m,  \u001b[1;36m1\u001b[0m,  \u001b[1;36m5\u001b[0m, \u001b[1;36m10\u001b[0m,  \u001b[1;36m5\u001b[0m,  \u001b[1;36m7\u001b[0m, \u001b[1;36m13\u001b[0m,  \u001b[1;36m0\u001b[0m,  \u001b[1;36m7\u001b[0m,  \u001b[1;36m2\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m,\n",
              "\u001b[2;32m│   \u001b[0m\u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m16\u001b[0m, \u001b[1;36m16\u001b[0m, \u001b[1;36m16\u001b[0m, \u001b[1;36m16\u001b[0m, \u001b[1;36m16\u001b[0m, \u001b[1;36m16\u001b[0m,  \u001b[1;36m0\u001b[0m,  \u001b[1;36m7\u001b[0m,  \u001b[1;36m2\u001b[0m, \u001b[1;36m15\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m,\n",
              "\u001b[2;32m│   \u001b[0m\u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[3;92mTrue\u001b[0m, \u001b[3;92mTrue\u001b[0m, \u001b[3;92mTrue\u001b[0m, \u001b[3;92mTrue\u001b[0m, \u001b[3;92mTrue\u001b[0m, \u001b[3;92mTrue\u001b[0m, \u001b[3;92mTrue\u001b[0m, \u001b[3;92mTrue\u001b[0m, \u001b[3;92mTrue\u001b[0m, \u001b[3;92mTrue\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m,\n",
              "\u001b[2;32m│   \u001b[0m\u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m \u001b[3;92mTrue\u001b[0m, \u001b[3;91mFalse\u001b[0m, \u001b[3;91mFalse\u001b[0m, \u001b[3;91mFalse\u001b[0m, \u001b[3;91mFalse\u001b[0m, \u001b[3;91mFalse\u001b[0m, \u001b[3;91mFalse\u001b[0m, \u001b[3;91mFalse\u001b[0m, \u001b[3;91mFalse\u001b[0m, \u001b[3;91mFalse\u001b[0m\u001b[1m]\u001b[0m,\n",
              "\u001b[2;32m│   │   \u001b[0m\u001b[1m[\u001b[0m \u001b[3;92mTrue\u001b[0m,  \u001b[3;92mTrue\u001b[0m, \u001b[3;91mFalse\u001b[0m, \u001b[3;91mFalse\u001b[0m, \u001b[3;91mFalse\u001b[0m, \u001b[3;91mFalse\u001b[0m, \u001b[3;91mFalse\u001b[0m, \u001b[3;91mFalse\u001b[0m, \u001b[3;91mFalse\u001b[0m, \u001b[3;91mFalse\u001b[0m\u001b[1m]\u001b[0m,\n",
              "\u001b[2;32m│   │   \u001b[0m\u001b[1m[\u001b[0m \u001b[3;92mTrue\u001b[0m,  \u001b[3;92mTrue\u001b[0m,  \u001b[3;92mTrue\u001b[0m, \u001b[3;91mFalse\u001b[0m, \u001b[3;91mFalse\u001b[0m, \u001b[3;91mFalse\u001b[0m, \u001b[3;91mFalse\u001b[0m, \u001b[3;91mFalse\u001b[0m, \u001b[3;91mFalse\u001b[0m, \u001b[3;91mFalse\u001b[0m\u001b[1m]\u001b[0m,\n",
              "\u001b[2;32m│   │   \u001b[0m\u001b[1m[\u001b[0m \u001b[3;92mTrue\u001b[0m,  \u001b[3;92mTrue\u001b[0m,  \u001b[3;92mTrue\u001b[0m,  \u001b[3;92mTrue\u001b[0m, \u001b[3;91mFalse\u001b[0m, \u001b[3;91mFalse\u001b[0m, \u001b[3;91mFalse\u001b[0m, \u001b[3;91mFalse\u001b[0m, \u001b[3;91mFalse\u001b[0m, \u001b[3;91mFalse\u001b[0m\u001b[1m]\u001b[0m,\n",
              "\u001b[2;32m│   │   \u001b[0m\u001b[1m[\u001b[0m \u001b[3;92mTrue\u001b[0m,  \u001b[3;92mTrue\u001b[0m,  \u001b[3;92mTrue\u001b[0m,  \u001b[3;92mTrue\u001b[0m,  \u001b[3;92mTrue\u001b[0m, \u001b[3;91mFalse\u001b[0m, \u001b[3;91mFalse\u001b[0m, \u001b[3;91mFalse\u001b[0m, \u001b[3;91mFalse\u001b[0m, \u001b[3;91mFalse\u001b[0m\u001b[1m]\u001b[0m,\n",
              "\u001b[2;32m│   │   \u001b[0m\u001b[1m[\u001b[0m \u001b[3;92mTrue\u001b[0m,  \u001b[3;92mTrue\u001b[0m,  \u001b[3;92mTrue\u001b[0m,  \u001b[3;92mTrue\u001b[0m,  \u001b[3;92mTrue\u001b[0m,  \u001b[3;92mTrue\u001b[0m, \u001b[3;91mFalse\u001b[0m, \u001b[3;91mFalse\u001b[0m, \u001b[3;91mFalse\u001b[0m, \u001b[3;91mFalse\u001b[0m\u001b[1m]\u001b[0m,\n",
              "\u001b[2;32m│   │   \u001b[0m\u001b[1m[\u001b[0m \u001b[3;92mTrue\u001b[0m,  \u001b[3;92mTrue\u001b[0m,  \u001b[3;92mTrue\u001b[0m,  \u001b[3;92mTrue\u001b[0m,  \u001b[3;92mTrue\u001b[0m,  \u001b[3;92mTrue\u001b[0m,  \u001b[3;92mTrue\u001b[0m, \u001b[3;91mFalse\u001b[0m, \u001b[3;91mFalse\u001b[0m, \u001b[3;91mFalse\u001b[0m\u001b[1m]\u001b[0m,\n",
              "\u001b[2;32m│   │   \u001b[0m\u001b[1m[\u001b[0m \u001b[3;92mTrue\u001b[0m,  \u001b[3;92mTrue\u001b[0m,  \u001b[3;92mTrue\u001b[0m,  \u001b[3;92mTrue\u001b[0m,  \u001b[3;92mTrue\u001b[0m,  \u001b[3;92mTrue\u001b[0m,  \u001b[3;92mTrue\u001b[0m,  \u001b[3;92mTrue\u001b[0m, \u001b[3;91mFalse\u001b[0m, \u001b[3;91mFalse\u001b[0m\u001b[1m]\u001b[0m,\n",
              "\u001b[2;32m│   │   \u001b[0m\u001b[1m[\u001b[0m \u001b[3;92mTrue\u001b[0m,  \u001b[3;92mTrue\u001b[0m,  \u001b[3;92mTrue\u001b[0m,  \u001b[3;92mTrue\u001b[0m,  \u001b[3;92mTrue\u001b[0m,  \u001b[3;92mTrue\u001b[0m,  \u001b[3;92mTrue\u001b[0m,  \u001b[3;92mTrue\u001b[0m,  \u001b[3;92mTrue\u001b[0m, \u001b[3;91mFalse\u001b[0m\u001b[1m]\u001b[0m,\n",
              "\u001b[2;32m│   │   \u001b[0m\u001b[1m[\u001b[0m \u001b[3;92mTrue\u001b[0m,  \u001b[3;92mTrue\u001b[0m,  \u001b[3;92mTrue\u001b[0m,  \u001b[3;92mTrue\u001b[0m,  \u001b[3;92mTrue\u001b[0m,  \u001b[3;92mTrue\u001b[0m,  \u001b[3;92mTrue\u001b[0m,  \u001b[3;92mTrue\u001b[0m,  \u001b[3;92mTrue\u001b[0m,  \u001b[3;92mTrue\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\n",
              "\u001b[1m)\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "with open(composer.data.dataset_path, \"r\") as file:\n",
        "    sequences = [line.strip() for line in file]\n",
        "\n",
        "dataset = AdderDataset(data=sequences, tokenizer=tokenizer)\n",
        "\n",
        "pprint(next(iter(dataset)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Construct Batches, Collate Function and DataLoader\n",
        "\n",
        "We first reverse engineer what our dataset is returning. The disclaimer here is\n",
        "that for decoder only models like GPT, many people often omit the padding mask\n",
        "since all the samples $\\mathbf{x}$ are chunked to sequence/context length of\n",
        "window size $T$, and future masks are usually handled within the `Attention`\n",
        "class since we will never attend to the future tokens. However, for the sake of\n",
        "clarity, we will include the padding and future mask in the dataset (i.e.\n",
        "actually it is for the sake of my own understanding when I started to implement\n",
        "decoder from scratch)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 136,
      "metadata": {},
      "outputs": [],
      "source": [
        "input, target, target_padding_mask, future_mask = next(iter(dataset))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Input and Target\n",
        "\n",
        "I think if you've read my\n",
        "[section here](https://www.gaohongnan.com/transformer/decoder/implementation.html#construction-of-input-and-target-sequences),\n",
        "then we would easily see that given an input sequence $\\mathbf{x}$, the target\n",
        "sequence $\\mathbf{y}$ is simply the input sequence $\\mathbf{x}$ shifted by one\n",
        "time step to the left. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 137,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Input : tensor([14,  1,  5, 10,  5,  7, 13,  0,  7,  2])\n",
            "Target: tensor([16, 16, 16, 16, 16, 16,  0,  7,  2, 15])\n"
          ]
        }
      ],
      "source": [
        "print(f\"Input : {input}\")\n",
        "print(f\"Target: {target}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Target Padding Mask\n",
        "\n",
        "When you're dealing with sequences of different lengths, you pad the shorter\n",
        "sequences with a special token `PAD` (usually $0$ or $-100$) to make them the\n",
        "same length as the longest one in the batch. These paddings should not\n",
        "contribute to the model's learning, so you need to mask them out. In practice,\n",
        "you'll often see a mask argument in `Attention` layers in PyTorch where if\n",
        "`True`, the attention scores are set to `-inf` for the padded positions so that\n",
        "these positions become zero after the softmax operation, thereby not\n",
        "contributing to the weighted sum of the input sequence.\n",
        "\n",
        "In a decoder-only model like GPT, the input sequence is essentially the target.\n",
        "The model aims to generate tokens that come after the given input, treating it\n",
        "as the \"history\" or \"context\" for the task of text generation. Unlike\n",
        "encoder-decoder models like the original Transformer, where the encoder\n",
        "processes a source sequence and the decoder generates a target sequence, a\n",
        "decoder-only model works solely with what would traditionally be considered the\n",
        "target sequence.\n",
        "\n",
        "Consequently, although the terminology \"target padding mask\" might seem more\n",
        "intuitive in the context of encoder-decoder models, where the distinction\n",
        "between source (input) and target (output) sequences is clear. The distinction\n",
        "is blurred in decoder-only models like GPT as the model processes input to\n",
        "predict the next token in a sequence. Here, the source is essentially the target\n",
        "at different stages of processing: the model uses previous tokens (source) to\n",
        "predict the next token (target). However, during my implementation, I was mainly\n",
        "referring to transformer models that use encoder-decoder architecture, and the\n",
        "terminology therefore stemmed from that context.\n",
        "\n",
        "The definition of a target padding mask is a binary mark that ignores pad-tokens\n",
        "in the source input (in decoder only model, the source is the target). And the\n",
        "shape is $(\\mathcal{B}, T)$.\n",
        "\n",
        "Let's illustrate the target padding mask with an example. Suppose we have a\n",
        "batch of sequences with different lengths:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 138,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">7</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">9</span><span style=\"font-weight: bold\">]</span>, <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6</span><span style=\"font-weight: bold\">]</span>, <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">12</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">11</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">17</span><span style=\"font-weight: bold\">]</span>, <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span><span style=\"font-weight: bold\">]]</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m5\u001b[0m, \u001b[1;36m7\u001b[0m, \u001b[1;36m9\u001b[0m\u001b[1m]\u001b[0m, \u001b[1m[\u001b[0m\u001b[1;36m8\u001b[0m, \u001b[1;36m6\u001b[0m\u001b[1m]\u001b[0m, \u001b[1m[\u001b[0m\u001b[1;36m3\u001b[0m, \u001b[1;36m12\u001b[0m, \u001b[1;36m4\u001b[0m, \u001b[1;36m11\u001b[0m, \u001b[1;36m17\u001b[0m\u001b[1m]\u001b[0m, \u001b[1m[\u001b[0m\u001b[1;36m2\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m4\u001b[0m, \u001b[1;36m5\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "target_batch = [\n",
        "    [5, 7, 9],\n",
        "    [8, 6],\n",
        "    [3, 12, 4, 11, 17],\n",
        "    [2, 1, 4, 5],\n",
        "]\n",
        "pprint(target_batch)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "If we try to \"batch\" these sequences, PyTorch would throw an error indicating\n",
        "that you need all sequences to have the same length."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 139,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[2024-03-21 23:01:08] </span><span style=\"color: #800000; text-decoration-color: #800000\">ERROR   </span> expected sequence of length <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span> at dim <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> <span style=\"font-weight: bold\">(</span>got <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span><span style=\"font-weight: bold\">)</span>                       <a href=\"file:///var/folders/cy/12tl7y917h51vcpszr1tw0nr0000gn/T/ipykernel_11692/1205213247.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1205213247.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///var/folders/cy/12tl7y917h51vcpszr1tw0nr0000gn/T/ipykernel_11692/1205213247.py#4\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">4</span></a>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[2;36m[2024-03-21 23:01:08]\u001b[0m\u001b[2;36m \u001b[0m\u001b[31mERROR   \u001b[0m expected sequence of length \u001b[1;36m3\u001b[0m at dim \u001b[1;36m1\u001b[0m \u001b[1m(\u001b[0mgot \u001b[1;36m2\u001b[0m\u001b[1m)\u001b[0m                       \u001b]8;id=529903;file:///var/folders/cy/12tl7y917h51vcpszr1tw0nr0000gn/T/ipykernel_11692/1205213247.py\u001b\\\u001b[2m1205213247.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=631262;file:///var/folders/cy/12tl7y917h51vcpszr1tw0nr0000gn/T/ipykernel_11692/1205213247.py#4\u001b\\\u001b[2m4\u001b[0m\u001b]8;;\u001b\\\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[2024-03-21 23:01:08] </span><span style=\"color: #800000; text-decoration-color: #800000\">ERROR   </span> expected sequence of length <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span> at dim <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> <span style=\"font-weight: bold\">(</span>got <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span><span style=\"font-weight: bold\">)</span>                       <a href=\"file:///var/folders/cy/12tl7y917h51vcpszr1tw0nr0000gn/T/ipykernel_11692/1205213247.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1205213247.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///var/folders/cy/12tl7y917h51vcpszr1tw0nr0000gn/T/ipykernel_11692/1205213247.py#4\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">4</span></a>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[2;36m[2024-03-21 23:01:08]\u001b[0m\u001b[2;36m \u001b[0m\u001b[31mERROR   \u001b[0m expected sequence of length \u001b[1;36m3\u001b[0m at dim \u001b[1;36m1\u001b[0m \u001b[1m(\u001b[0mgot \u001b[1;36m2\u001b[0m\u001b[1m)\u001b[0m                       \u001b]8;id=681453;file:///var/folders/cy/12tl7y917h51vcpszr1tw0nr0000gn/T/ipykernel_11692/1205213247.py\u001b\\\u001b[2m1205213247.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=735392;file:///var/folders/cy/12tl7y917h51vcpszr1tw0nr0000gn/T/ipykernel_11692/1205213247.py#4\u001b\\\u001b[2m4\u001b[0m\u001b]8;;\u001b\\\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[2024-03-21 23:01:08] </span><span style=\"color: #800000; text-decoration-color: #800000\">ERROR   </span> expected sequence of length <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span> at dim <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> <span style=\"font-weight: bold\">(</span>got <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span><span style=\"font-weight: bold\">)</span>                       <a href=\"file:///var/folders/cy/12tl7y917h51vcpszr1tw0nr0000gn/T/ipykernel_11692/1205213247.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">1205213247.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///var/folders/cy/12tl7y917h51vcpszr1tw0nr0000gn/T/ipykernel_11692/1205213247.py#4\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">4</span></a>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[2;36m[2024-03-21 23:01:08]\u001b[0m\u001b[2;36m \u001b[0m\u001b[31mERROR   \u001b[0m expected sequence of length \u001b[1;36m3\u001b[0m at dim \u001b[1;36m1\u001b[0m \u001b[1m(\u001b[0mgot \u001b[1;36m2\u001b[0m\u001b[1m)\u001b[0m                       \u001b]8;id=617889;file:///var/folders/cy/12tl7y917h51vcpszr1tw0nr0000gn/T/ipykernel_11692/1205213247.py\u001b\\\u001b[2m1205213247.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=291704;file:///var/folders/cy/12tl7y917h51vcpszr1tw0nr0000gn/T/ipykernel_11692/1205213247.py#4\u001b\\\u001b[2m4\u001b[0m\u001b]8;;\u001b\\\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "try:\n",
        "    target_batch = torch.tensor(target_batch, dtype=torch.int64)\n",
        "except ValueError as err:\n",
        "    LOGGER.error(err)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To address this issue, we could pad the sequences to the same length and create a mask to indicate\n",
        "which positions are padded.  We pad the shorter sequences with a special token `PAD`\n",
        "to make them the same length as the longest one in the batch. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 140,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">7</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">9</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">16</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">16</span><span style=\"font-weight: bold\">]</span>, <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">16</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">16</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">16</span><span style=\"font-weight: bold\">]</span>, <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">12</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">11</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">17</span><span style=\"font-weight: bold\">]</span>, <span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">16</span><span style=\"font-weight: bold\">]]</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m5\u001b[0m, \u001b[1;36m7\u001b[0m, \u001b[1;36m9\u001b[0m, \u001b[1;36m16\u001b[0m, \u001b[1;36m16\u001b[0m\u001b[1m]\u001b[0m, \u001b[1m[\u001b[0m\u001b[1;36m8\u001b[0m, \u001b[1;36m6\u001b[0m, \u001b[1;36m16\u001b[0m, \u001b[1;36m16\u001b[0m, \u001b[1;36m16\u001b[0m\u001b[1m]\u001b[0m, \u001b[1m[\u001b[0m\u001b[1;36m3\u001b[0m, \u001b[1;36m12\u001b[0m, \u001b[1;36m4\u001b[0m, \u001b[1;36m11\u001b[0m, \u001b[1;36m17\u001b[0m\u001b[1m]\u001b[0m, \u001b[1m[\u001b[0m\u001b[1;36m2\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m4\u001b[0m, \u001b[1;36m5\u001b[0m, \u001b[1;36m16\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">tensor</span><span style=\"font-weight: bold\">([[</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">7</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">9</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">16</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">16</span><span style=\"font-weight: bold\">]</span>,\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"font-weight: bold\">[</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">16</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">16</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">16</span><span style=\"font-weight: bold\">]</span>,\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"font-weight: bold\">[</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">12</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">11</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">17</span><span style=\"font-weight: bold\">]</span>,\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"font-weight: bold\">[</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">16</span><span style=\"font-weight: bold\">]])</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m \u001b[1;36m5\u001b[0m,  \u001b[1;36m7\u001b[0m,  \u001b[1;36m9\u001b[0m, \u001b[1;36m16\u001b[0m, \u001b[1;36m16\u001b[0m\u001b[1m]\u001b[0m,\n",
              "\u001b[2;32m│   │   \u001b[0m\u001b[1m[\u001b[0m \u001b[1;36m8\u001b[0m,  \u001b[1;36m6\u001b[0m, \u001b[1;36m16\u001b[0m, \u001b[1;36m16\u001b[0m, \u001b[1;36m16\u001b[0m\u001b[1m]\u001b[0m,\n",
              "\u001b[2;32m│   │   \u001b[0m\u001b[1m[\u001b[0m \u001b[1;36m3\u001b[0m, \u001b[1;36m12\u001b[0m,  \u001b[1;36m4\u001b[0m, \u001b[1;36m11\u001b[0m, \u001b[1;36m17\u001b[0m\u001b[1m]\u001b[0m,\n",
              "\u001b[2;32m│   │   \u001b[0m\u001b[1m[\u001b[0m \u001b[1;36m2\u001b[0m,  \u001b[1;36m1\u001b[0m,  \u001b[1;36m4\u001b[0m,  \u001b[1;36m5\u001b[0m, \u001b[1;36m16\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "PAD = vocabulary.token_to_index[vocabulary.PAD]\n",
        "\n",
        "max_len = max(len(seq) for seq in target_batch)\n",
        "target_batch = [seq + [PAD] * (max_len - len(seq)) for seq in target_batch]\n",
        "pprint(target_batch)\n",
        "\n",
        "target_batch = torch.tensor(target_batch, dtype=torch.int64)\n",
        "pprint(target_batch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 141,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">tensor</span><span style=\"font-weight: bold\">([[</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,  <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,  <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>, <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>, <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">]</span>,\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"font-weight: bold\">[</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,  <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>, <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>, <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>, <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">]</span>,\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"font-weight: bold\">[</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,  <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,  <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,  <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,  <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">]</span>,\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"font-weight: bold\">[</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,  <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,  <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,  <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>, <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">]])</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m \u001b[3;92mTrue\u001b[0m,  \u001b[3;92mTrue\u001b[0m,  \u001b[3;92mTrue\u001b[0m, \u001b[3;91mFalse\u001b[0m, \u001b[3;91mFalse\u001b[0m\u001b[1m]\u001b[0m,\n",
              "\u001b[2;32m│   │   \u001b[0m\u001b[1m[\u001b[0m \u001b[3;92mTrue\u001b[0m,  \u001b[3;92mTrue\u001b[0m, \u001b[3;91mFalse\u001b[0m, \u001b[3;91mFalse\u001b[0m, \u001b[3;91mFalse\u001b[0m\u001b[1m]\u001b[0m,\n",
              "\u001b[2;32m│   │   \u001b[0m\u001b[1m[\u001b[0m \u001b[3;92mTrue\u001b[0m,  \u001b[3;92mTrue\u001b[0m,  \u001b[3;92mTrue\u001b[0m,  \u001b[3;92mTrue\u001b[0m,  \u001b[3;92mTrue\u001b[0m\u001b[1m]\u001b[0m,\n",
              "\u001b[2;32m│   │   \u001b[0m\u001b[1m[\u001b[0m \u001b[3;92mTrue\u001b[0m,  \u001b[3;92mTrue\u001b[0m,  \u001b[3;92mTrue\u001b[0m,  \u001b[3;92mTrue\u001b[0m, \u001b[3;91mFalse\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "batch_size, seq_len = target_batch.size()\n",
        "\n",
        "target_padding_mask = target_batch != PAD\n",
        "\n",
        "pprint(target_padding_mask)\n",
        "\n",
        "assert target_padding_mask.size() == (batch_size, seq_len) == (4, 5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Of course, we would need a _batch_ of these masks, so we would have a shape of\n",
        "$(\\mathcal{B}, T)$ like mentioned above. As we will see later, we will still\n",
        "need to broadcast the shape to $(\\mathcal{B}, 1, T, T)$ to match the shape of\n",
        "the attention scores.\n",
        "\n",
        "Theoretically speaking, it is possible for the sequence length $T$ to vary\n",
        "across samples $\\mathbf{x}$. However, we usually have the same length for all\n",
        "samples in GPT, and in this particular case, we do know that each sample\n",
        "necessarily have the same length by _design_. However, for the sake of\n",
        "explanation, we note that in our `Dataset`, it will only generate 1 single\n",
        "sample data point and do not worry about different sequence length across other\n",
        "samples in the dataset $\\mathcal{S}$, but in deep learning we train in\n",
        "mini-batches $\\mathcal{B}$, and with different batch sizes we may encounter\n",
        "issues (i.e. matrix multiplication may not work)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Future Mask\n",
        "\n",
        "In the decoder, each position can only attend to positions that come before it\n",
        "in the sequence to maintain the auto-regressive property. This is different from\n",
        "the encoder, where all positions can attend to all other positions.\n",
        "\n",
        "The definition of future mask is basically a look-ahead mask to ensure that each\n",
        "position only attends to positions before it in the sequence where we mask out\n",
        "future positions (i.e., positions that come after the current position) so that\n",
        "they don't contribute to the current attention scores. Before the softmax\n",
        "operation, we'll mark these positions as `-inf` so that they become zero after\n",
        "the softmax operation - effectively zeroing out the attention scores for future\n",
        "positions. What does zeroing out these masked logits actually does? Basically,\n",
        "the attention mechanism can be thought of as a weighted average of all the\n",
        "tokens in the input sequence. Each token is assigned a weight, with higher\n",
        "weights indicating more relevance to the token under consideration. If a certain\n",
        "token should not be considered at all (e.g., it's a future token that should not\n",
        "be visible to the current decoder step, or it's a padding token), its weight\n",
        "should be zero.\n",
        "\n",
        "The shape of the future mask is $(T, T)$ for a target sequence/sample\n",
        "$\\mathbf{x}$ of length $T$. Let's see a concrete example to illustrate the\n",
        "future mask."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 142,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">tensor</span><span style=\"font-weight: bold\">([[</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>, <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>, <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>, <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>, <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">]</span>,\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"font-weight: bold\">[</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,  <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>, <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>, <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>, <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">]</span>,\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"font-weight: bold\">[</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,  <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,  <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>, <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>, <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">]</span>,\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"font-weight: bold\">[</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,  <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,  <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,  <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>, <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">]</span>,\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"font-weight: bold\">[</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,  <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,  <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,  <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,  <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">]])</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m \u001b[3;92mTrue\u001b[0m, \u001b[3;91mFalse\u001b[0m, \u001b[3;91mFalse\u001b[0m, \u001b[3;91mFalse\u001b[0m, \u001b[3;91mFalse\u001b[0m\u001b[1m]\u001b[0m,\n",
              "\u001b[2;32m│   │   \u001b[0m\u001b[1m[\u001b[0m \u001b[3;92mTrue\u001b[0m,  \u001b[3;92mTrue\u001b[0m, \u001b[3;91mFalse\u001b[0m, \u001b[3;91mFalse\u001b[0m, \u001b[3;91mFalse\u001b[0m\u001b[1m]\u001b[0m,\n",
              "\u001b[2;32m│   │   \u001b[0m\u001b[1m[\u001b[0m \u001b[3;92mTrue\u001b[0m,  \u001b[3;92mTrue\u001b[0m,  \u001b[3;92mTrue\u001b[0m, \u001b[3;91mFalse\u001b[0m, \u001b[3;91mFalse\u001b[0m\u001b[1m]\u001b[0m,\n",
              "\u001b[2;32m│   │   \u001b[0m\u001b[1m[\u001b[0m \u001b[3;92mTrue\u001b[0m,  \u001b[3;92mTrue\u001b[0m,  \u001b[3;92mTrue\u001b[0m,  \u001b[3;92mTrue\u001b[0m, \u001b[3;91mFalse\u001b[0m\u001b[1m]\u001b[0m,\n",
              "\u001b[2;32m│   │   \u001b[0m\u001b[1m[\u001b[0m \u001b[3;92mTrue\u001b[0m,  \u001b[3;92mTrue\u001b[0m,  \u001b[3;92mTrue\u001b[0m,  \u001b[3;92mTrue\u001b[0m,  \u001b[3;92mTrue\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "seq_len = 5\n",
        "future_mask = torch.triu(torch.ones(seq_len, seq_len), diagonal=1)\n",
        "future_mask = future_mask == 0\n",
        "\n",
        "pprint(future_mask)\n",
        "assert future_mask.size() == (seq_len, seq_len) == (5, 5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Merge Padding and Future Masks\n",
        "\n",
        "We see from our `decoder` implementation below, that one of the method is \n",
        "creating the target masks. In other words, we are creating the target padding\n",
        "masks and future masks, and merging them together. \n",
        "\n",
        "\n",
        "```{code-block} md\n",
        "---\n",
        "linenos: true\n",
        "emphasize-lines: 27\n",
        "---\n",
        "\n",
        "def create_target_masks(\n",
        "    self,\n",
        "    batch_size: int,\n",
        "    seq_len: int,\n",
        "    target_padding_masks: torch.BoolTensor | NotGiven = NOT_GIVEN,\n",
        "    future_masks: torch.BoolTensor | NotGiven = NOT_GIVEN,\n",
        ") -> torch.BoolTensor:\n",
        "    target_masks_shape = (batch_size, 1, seq_len, seq_len)\n",
        "    if target_padding_masks is NOT_GIVEN and future_masks is NOT_GIVEN:\n",
        "        target_padding_masks = cast(\n",
        "            torch.BoolTensor, construct_dummy_batch_target_padding_masks(batch_size, seq_len)\n",
        "        )\n",
        "        future_masks = cast(torch.BoolTensor, construct_dummy_batch_future_masks(batch_size, seq_len))\n",
        "\n",
        "    if target_padding_masks is NOT_GIVEN:\n",
        "        target_padding_masks = cast(\n",
        "            torch.BoolTensor, construct_dummy_batch_target_padding_masks(batch_size, seq_len)\n",
        "        )\n",
        "\n",
        "    if future_masks is NOT_GIVEN:\n",
        "        future_masks = cast(torch.BoolTensor, construct_dummy_batch_future_masks(batch_size, seq_len))\n",
        "\n",
        "    assert target_padding_masks.shape == future_masks.shape == target_masks_shape  # type: ignore[union-attr]\n",
        "\n",
        "    return cast(\n",
        "        torch.BoolTensor,\n",
        "        torch.logical_and(cast(torch.Tensor, target_padding_masks), cast(torch.Tensor, future_masks)).bool(),\n",
        "    )\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The purpose of applying `logical_and` between `target_padding_mask` and\n",
        "`future_mask` is to combine the constraints from both masks when calculating\n",
        "self-attention scores in the transformer's decoder. The `target_padding_mask` is\n",
        "designed to mask out the padding tokens in the input sequence, while the\n",
        "`future_mask` ensures that a given position cannot attend to future positions in\n",
        "the sequence. By combining these masks, you can perform the necessary masking\n",
        "for both padding and future tokens in a single step.\n",
        "\n",
        "Here's how it works:\n",
        "\n",
        "1. `target_padding_mask`: Masks out the padding tokens so that they don't\n",
        "   contribute to the attention calculations. True values mean \"attend to this\n",
        "   token,\" and False values mean \"ignore this token.\"\n",
        "\n",
        "2. `future_mask`: The future mask is created as a lower triangular matrix, where\n",
        "   the lower triangle, including the diagonal, is filled with ones, and the\n",
        "   upper triangle is filled with zeros. Masks out future tokens in a sequence so\n",
        "   that a token at a given position can only attend to positions that come\n",
        "   before it (and itself). True values mean \"attend to this token,\" and False\n",
        "   values mean \"ignore this token.\"\n",
        "\n",
        "3. `logical_and(target_padding_mask, future_mask)`: Combines the two masks. A\n",
        "   True in the resulting mask means that the condition for both padding and\n",
        "   future attention is satisfied.\n",
        "\n",
        "By combining these two masks, the decoder obeys the autoregressive property,\n",
        "ensuring it doesn't see future tokens, while also ignoring padding tokens in the\n",
        "input sequence. We may term it the `target_mask`.\n",
        "\n",
        "#### First Sample First Token\n",
        "\n",
        "-   `target_padding_mask` has size of `[4, 5]`.\n",
        "    -   We zoom in to the first row (sample) which is of length 5.\n",
        "    -   This length 5 is the sequence length, which is `T, T, T, F, F`\n",
        "        indicating the last 2 tokens being padded.\n",
        "-   `future_mask` has size of `[5, 5]`.\n",
        "    -   We note that this is indepedent of batch size. Each sample should have\n",
        "        the same future mask shape of `[L, L]`.\n",
        "    -   This `L=5` should necessary be same for the sequence length in\n",
        "        `target_padding_mask`.\n",
        "-   First, let's consider one batch of 4 samples. What we do first is to\n",
        "    broadcast `future_mask` to `[4, 5, 5]` because we want each sample/row in\n",
        "    the batch to have the same future mask. As shown below:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 143,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">tensor</span><span style=\"font-weight: bold\">([[</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>, <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>, <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>, <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>, <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">]</span>,\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"font-weight: bold\">[</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,  <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>, <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>, <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>, <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">]</span>,\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"font-weight: bold\">[</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,  <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,  <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>, <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>, <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">]</span>,\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"font-weight: bold\">[</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,  <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,  <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,  <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>, <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">]</span>,\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"font-weight: bold\">[</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,  <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,  <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,  <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,  <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">]])</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m \u001b[3;92mTrue\u001b[0m, \u001b[3;91mFalse\u001b[0m, \u001b[3;91mFalse\u001b[0m, \u001b[3;91mFalse\u001b[0m, \u001b[3;91mFalse\u001b[0m\u001b[1m]\u001b[0m,\n",
              "\u001b[2;32m│   │   \u001b[0m\u001b[1m[\u001b[0m \u001b[3;92mTrue\u001b[0m,  \u001b[3;92mTrue\u001b[0m, \u001b[3;91mFalse\u001b[0m, \u001b[3;91mFalse\u001b[0m, \u001b[3;91mFalse\u001b[0m\u001b[1m]\u001b[0m,\n",
              "\u001b[2;32m│   │   \u001b[0m\u001b[1m[\u001b[0m \u001b[3;92mTrue\u001b[0m,  \u001b[3;92mTrue\u001b[0m,  \u001b[3;92mTrue\u001b[0m, \u001b[3;91mFalse\u001b[0m, \u001b[3;91mFalse\u001b[0m\u001b[1m]\u001b[0m,\n",
              "\u001b[2;32m│   │   \u001b[0m\u001b[1m[\u001b[0m \u001b[3;92mTrue\u001b[0m,  \u001b[3;92mTrue\u001b[0m,  \u001b[3;92mTrue\u001b[0m,  \u001b[3;92mTrue\u001b[0m, \u001b[3;91mFalse\u001b[0m\u001b[1m]\u001b[0m,\n",
              "\u001b[2;32m│   │   \u001b[0m\u001b[1m[\u001b[0m \u001b[3;92mTrue\u001b[0m,  \u001b[3;92mTrue\u001b[0m,  \u001b[3;92mTrue\u001b[0m,  \u001b[3;92mTrue\u001b[0m,  \u001b[3;92mTrue\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">tensor</span><span style=\"font-weight: bold\">([[[</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>, <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>, <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>, <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>, <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">]</span>,\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │    </span><span style=\"font-weight: bold\">[</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,  <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>, <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>, <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>, <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">]</span>,\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │    </span><span style=\"font-weight: bold\">[</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,  <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,  <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>, <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>, <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">]</span>,\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │    </span><span style=\"font-weight: bold\">[</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,  <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,  <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,  <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>, <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">]</span>,\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │    </span><span style=\"font-weight: bold\">[</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,  <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,  <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,  <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,  <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">]]</span>,\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span>\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"font-weight: bold\">[[</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>, <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>, <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>, <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>, <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">]</span>,\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │    </span><span style=\"font-weight: bold\">[</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,  <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>, <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>, <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>, <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">]</span>,\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │    </span><span style=\"font-weight: bold\">[</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,  <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,  <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>, <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>, <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">]</span>,\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │    </span><span style=\"font-weight: bold\">[</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,  <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,  <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,  <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>, <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">]</span>,\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │    </span><span style=\"font-weight: bold\">[</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,  <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,  <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,  <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,  <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">]]</span>,\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span>\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"font-weight: bold\">[[</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>, <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>, <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>, <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>, <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">]</span>,\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │    </span><span style=\"font-weight: bold\">[</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,  <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>, <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>, <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>, <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">]</span>,\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │    </span><span style=\"font-weight: bold\">[</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,  <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,  <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>, <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>, <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">]</span>,\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │    </span><span style=\"font-weight: bold\">[</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,  <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,  <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,  <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>, <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">]</span>,\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │    </span><span style=\"font-weight: bold\">[</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,  <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,  <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,  <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,  <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">]]</span>,\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span>\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"font-weight: bold\">[[</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>, <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>, <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>, <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>, <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">]</span>,\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │    </span><span style=\"font-weight: bold\">[</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,  <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>, <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>, <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>, <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">]</span>,\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │    </span><span style=\"font-weight: bold\">[</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,  <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,  <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>, <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>, <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">]</span>,\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │    </span><span style=\"font-weight: bold\">[</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,  <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,  <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,  <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>, <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">]</span>,\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │    </span><span style=\"font-weight: bold\">[</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,  <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,  <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,  <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,  <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">]]])</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m \u001b[3;92mTrue\u001b[0m, \u001b[3;91mFalse\u001b[0m, \u001b[3;91mFalse\u001b[0m, \u001b[3;91mFalse\u001b[0m, \u001b[3;91mFalse\u001b[0m\u001b[1m]\u001b[0m,\n",
              "\u001b[2;32m│   │    \u001b[0m\u001b[1m[\u001b[0m \u001b[3;92mTrue\u001b[0m,  \u001b[3;92mTrue\u001b[0m, \u001b[3;91mFalse\u001b[0m, \u001b[3;91mFalse\u001b[0m, \u001b[3;91mFalse\u001b[0m\u001b[1m]\u001b[0m,\n",
              "\u001b[2;32m│   │    \u001b[0m\u001b[1m[\u001b[0m \u001b[3;92mTrue\u001b[0m,  \u001b[3;92mTrue\u001b[0m,  \u001b[3;92mTrue\u001b[0m, \u001b[3;91mFalse\u001b[0m, \u001b[3;91mFalse\u001b[0m\u001b[1m]\u001b[0m,\n",
              "\u001b[2;32m│   │    \u001b[0m\u001b[1m[\u001b[0m \u001b[3;92mTrue\u001b[0m,  \u001b[3;92mTrue\u001b[0m,  \u001b[3;92mTrue\u001b[0m,  \u001b[3;92mTrue\u001b[0m, \u001b[3;91mFalse\u001b[0m\u001b[1m]\u001b[0m,\n",
              "\u001b[2;32m│   │    \u001b[0m\u001b[1m[\u001b[0m \u001b[3;92mTrue\u001b[0m,  \u001b[3;92mTrue\u001b[0m,  \u001b[3;92mTrue\u001b[0m,  \u001b[3;92mTrue\u001b[0m,  \u001b[3;92mTrue\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m,\n",
              "\u001b[2;32m│   │   \u001b[0m\n",
              "\u001b[2;32m│   │   \u001b[0m\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m \u001b[3;92mTrue\u001b[0m, \u001b[3;91mFalse\u001b[0m, \u001b[3;91mFalse\u001b[0m, \u001b[3;91mFalse\u001b[0m, \u001b[3;91mFalse\u001b[0m\u001b[1m]\u001b[0m,\n",
              "\u001b[2;32m│   │    \u001b[0m\u001b[1m[\u001b[0m \u001b[3;92mTrue\u001b[0m,  \u001b[3;92mTrue\u001b[0m, \u001b[3;91mFalse\u001b[0m, \u001b[3;91mFalse\u001b[0m, \u001b[3;91mFalse\u001b[0m\u001b[1m]\u001b[0m,\n",
              "\u001b[2;32m│   │    \u001b[0m\u001b[1m[\u001b[0m \u001b[3;92mTrue\u001b[0m,  \u001b[3;92mTrue\u001b[0m,  \u001b[3;92mTrue\u001b[0m, \u001b[3;91mFalse\u001b[0m, \u001b[3;91mFalse\u001b[0m\u001b[1m]\u001b[0m,\n",
              "\u001b[2;32m│   │    \u001b[0m\u001b[1m[\u001b[0m \u001b[3;92mTrue\u001b[0m,  \u001b[3;92mTrue\u001b[0m,  \u001b[3;92mTrue\u001b[0m,  \u001b[3;92mTrue\u001b[0m, \u001b[3;91mFalse\u001b[0m\u001b[1m]\u001b[0m,\n",
              "\u001b[2;32m│   │    \u001b[0m\u001b[1m[\u001b[0m \u001b[3;92mTrue\u001b[0m,  \u001b[3;92mTrue\u001b[0m,  \u001b[3;92mTrue\u001b[0m,  \u001b[3;92mTrue\u001b[0m,  \u001b[3;92mTrue\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m,\n",
              "\u001b[2;32m│   │   \u001b[0m\n",
              "\u001b[2;32m│   │   \u001b[0m\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m \u001b[3;92mTrue\u001b[0m, \u001b[3;91mFalse\u001b[0m, \u001b[3;91mFalse\u001b[0m, \u001b[3;91mFalse\u001b[0m, \u001b[3;91mFalse\u001b[0m\u001b[1m]\u001b[0m,\n",
              "\u001b[2;32m│   │    \u001b[0m\u001b[1m[\u001b[0m \u001b[3;92mTrue\u001b[0m,  \u001b[3;92mTrue\u001b[0m, \u001b[3;91mFalse\u001b[0m, \u001b[3;91mFalse\u001b[0m, \u001b[3;91mFalse\u001b[0m\u001b[1m]\u001b[0m,\n",
              "\u001b[2;32m│   │    \u001b[0m\u001b[1m[\u001b[0m \u001b[3;92mTrue\u001b[0m,  \u001b[3;92mTrue\u001b[0m,  \u001b[3;92mTrue\u001b[0m, \u001b[3;91mFalse\u001b[0m, \u001b[3;91mFalse\u001b[0m\u001b[1m]\u001b[0m,\n",
              "\u001b[2;32m│   │    \u001b[0m\u001b[1m[\u001b[0m \u001b[3;92mTrue\u001b[0m,  \u001b[3;92mTrue\u001b[0m,  \u001b[3;92mTrue\u001b[0m,  \u001b[3;92mTrue\u001b[0m, \u001b[3;91mFalse\u001b[0m\u001b[1m]\u001b[0m,\n",
              "\u001b[2;32m│   │    \u001b[0m\u001b[1m[\u001b[0m \u001b[3;92mTrue\u001b[0m,  \u001b[3;92mTrue\u001b[0m,  \u001b[3;92mTrue\u001b[0m,  \u001b[3;92mTrue\u001b[0m,  \u001b[3;92mTrue\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m,\n",
              "\u001b[2;32m│   │   \u001b[0m\n",
              "\u001b[2;32m│   │   \u001b[0m\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m \u001b[3;92mTrue\u001b[0m, \u001b[3;91mFalse\u001b[0m, \u001b[3;91mFalse\u001b[0m, \u001b[3;91mFalse\u001b[0m, \u001b[3;91mFalse\u001b[0m\u001b[1m]\u001b[0m,\n",
              "\u001b[2;32m│   │    \u001b[0m\u001b[1m[\u001b[0m \u001b[3;92mTrue\u001b[0m,  \u001b[3;92mTrue\u001b[0m, \u001b[3;91mFalse\u001b[0m, \u001b[3;91mFalse\u001b[0m, \u001b[3;91mFalse\u001b[0m\u001b[1m]\u001b[0m,\n",
              "\u001b[2;32m│   │    \u001b[0m\u001b[1m[\u001b[0m \u001b[3;92mTrue\u001b[0m,  \u001b[3;92mTrue\u001b[0m,  \u001b[3;92mTrue\u001b[0m, \u001b[3;91mFalse\u001b[0m, \u001b[3;91mFalse\u001b[0m\u001b[1m]\u001b[0m,\n",
              "\u001b[2;32m│   │    \u001b[0m\u001b[1m[\u001b[0m \u001b[3;92mTrue\u001b[0m,  \u001b[3;92mTrue\u001b[0m,  \u001b[3;92mTrue\u001b[0m,  \u001b[3;92mTrue\u001b[0m, \u001b[3;91mFalse\u001b[0m\u001b[1m]\u001b[0m,\n",
              "\u001b[2;32m│   │    \u001b[0m\u001b[1m[\u001b[0m \u001b[3;92mTrue\u001b[0m,  \u001b[3;92mTrue\u001b[0m,  \u001b[3;92mTrue\u001b[0m,  \u001b[3;92mTrue\u001b[0m,  \u001b[3;92mTrue\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">torch.Size</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span><span style=\"font-weight: bold\">])</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m4\u001b[0m, \u001b[1;36m5\u001b[0m, \u001b[1;36m5\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "pprint(future_mask)\n",
        "future_mask = future_mask.view(1, seq_len, seq_len).expand(size=(batch_size, -1, -1))\n",
        "pprint(future_mask)\n",
        "pprint(future_mask.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "-   Now, we can zoom in to one particular sample since both\n",
        "    `target_padding_mask` and `future_mask` have the same first dimension of\n",
        "    batch size.\n",
        "-   What is incomplete is that we need to broadcast `target_padding_mask`'s last\n",
        "    dimension to have the same dimensions as `future_mask`. This means we\n",
        "    broadcast `[4, 5]` to `[4, 5, 5]`. But why?\n",
        "-   For simplicity, we slice the first same of both below.\n",
        "-   The first row of the `future_mask` of the first sample is `T, F, F, F, F`.\n",
        "    This corresponds to what? This is the future mask of the first token in the\n",
        "    sequence. Well, that is confusing, because it apparently have 5 elements,\n",
        "    and has \"information\" of the other 4 tokens in the sequence. Let's explain\n",
        "    in details below:\n",
        "    -   Regarding the first row of the `future_mask` in the first sample, which\n",
        "        is `[T, F, F, F, F]`, it might initially seem confusing why there are 5\n",
        "        elements. Each of these elements, in fact, corresponds to whether the\n",
        "        first token can attend to other tokens at each respective position in\n",
        "        the sequence. Here's how to interpret it:\n",
        "        -   The first element (`True`) indicates that the first token can attend\n",
        "            to itself.\n",
        "        -   The next four elements (`False`) specify that the first token should\n",
        "            not attend to any of the future tokens in the sequence.\n",
        "-   Consequently, what is the first token in the sequence of the\n",
        "    `target_padding_mask`? Recall earlier we mentioned that the first sample's\n",
        "    `target_padding_mask` is `T, T, T, F, F` and therefore the first token in\n",
        "    the sequence is `T`.\n",
        "-   What do we want to achieve here? We want to make sure that the model does\n",
        "    not **attend** to tokens in the sequence that are masked with `False`.\n",
        "-   In other words, the first token in the sequence of the first sample has\n",
        "    `target_padding_mask` of `T` and `future_masks` of `T, F, F, F, F`.\n",
        "-   We need to broadcast this `T` to `T, T, T, T, T` to align with\n",
        "    `T, F, F, F, F` because? Because we need ensure that this first token in the\n",
        "    sequence is also able to considered in relation to every other token in the\n",
        "    sequence.\n",
        "-   So the first token is not a padded token, which is `T`, similarly, the first\n",
        "    token needs to attend to itself at the first position, hence `T` and `T`\n",
        "    give `T`. But for the second `T` in the now broadcasted\n",
        "    `target_padding_mask`, it is still representing the first token or?\n",
        "-   Broadcasting the first token's `target_padding_mask` value of `T` to\n",
        "    `[T, T, T, T, T]` ensures that when this first token is being considered for\n",
        "    attention computations, it is free to attend to any position, barring any\n",
        "    restrictions set by `future_mask`.\n",
        "-   Tricky: after broadcasting, each `T` in `[T, T, T, T, T]` is still\n",
        "    representing the first token. They indicate that when the first token is\n",
        "    compared with _any_ token in the sequence (including itself), it is not a\n",
        "    padding token. The element-wise `AND` with the `future_mask` then further\n",
        "    refines this by restricting it from attending to future tokens.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 144,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">tensor</span><span style=\"font-weight: bold\">([[</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,  <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,  <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>, <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>, <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">]</span>,\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"font-weight: bold\">[</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,  <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>, <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>, <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>, <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">]</span>,\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"font-weight: bold\">[</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,  <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,  <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,  <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,  <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">]</span>,\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"font-weight: bold\">[</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,  <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,  <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,  <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>, <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">]])</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m \u001b[3;92mTrue\u001b[0m,  \u001b[3;92mTrue\u001b[0m,  \u001b[3;92mTrue\u001b[0m, \u001b[3;91mFalse\u001b[0m, \u001b[3;91mFalse\u001b[0m\u001b[1m]\u001b[0m,\n",
              "\u001b[2;32m│   │   \u001b[0m\u001b[1m[\u001b[0m \u001b[3;92mTrue\u001b[0m,  \u001b[3;92mTrue\u001b[0m, \u001b[3;91mFalse\u001b[0m, \u001b[3;91mFalse\u001b[0m, \u001b[3;91mFalse\u001b[0m\u001b[1m]\u001b[0m,\n",
              "\u001b[2;32m│   │   \u001b[0m\u001b[1m[\u001b[0m \u001b[3;92mTrue\u001b[0m,  \u001b[3;92mTrue\u001b[0m,  \u001b[3;92mTrue\u001b[0m,  \u001b[3;92mTrue\u001b[0m,  \u001b[3;92mTrue\u001b[0m\u001b[1m]\u001b[0m,\n",
              "\u001b[2;32m│   │   \u001b[0m\u001b[1m[\u001b[0m \u001b[3;92mTrue\u001b[0m,  \u001b[3;92mTrue\u001b[0m,  \u001b[3;92mTrue\u001b[0m,  \u001b[3;92mTrue\u001b[0m, \u001b[3;91mFalse\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">tensor</span><span style=\"font-weight: bold\">([</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,  <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,  <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>, <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>, <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">])</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m \u001b[3;92mTrue\u001b[0m,  \u001b[3;92mTrue\u001b[0m,  \u001b[3;92mTrue\u001b[0m, \u001b[3;91mFalse\u001b[0m, \u001b[3;91mFalse\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">tensor</span><span style=\"font-weight: bold\">([[[</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,  <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,  <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>, <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>, <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">]</span>,\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │    </span><span style=\"font-weight: bold\">[</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,  <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,  <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>, <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>, <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">]</span>,\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │    </span><span style=\"font-weight: bold\">[</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,  <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,  <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>, <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>, <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">]</span>,\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │    </span><span style=\"font-weight: bold\">[</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,  <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,  <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>, <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>, <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">]</span>,\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │    </span><span style=\"font-weight: bold\">[</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,  <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,  <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>, <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>, <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">]]</span>,\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span>\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"font-weight: bold\">[[</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,  <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>, <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>, <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>, <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">]</span>,\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │    </span><span style=\"font-weight: bold\">[</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,  <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>, <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>, <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>, <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">]</span>,\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │    </span><span style=\"font-weight: bold\">[</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,  <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>, <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>, <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>, <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">]</span>,\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │    </span><span style=\"font-weight: bold\">[</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,  <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>, <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>, <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>, <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">]</span>,\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │    </span><span style=\"font-weight: bold\">[</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,  <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>, <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>, <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>, <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">]]</span>,\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span>\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"font-weight: bold\">[[</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,  <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,  <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,  <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,  <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">]</span>,\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │    </span><span style=\"font-weight: bold\">[</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,  <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,  <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,  <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,  <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">]</span>,\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │    </span><span style=\"font-weight: bold\">[</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,  <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,  <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,  <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,  <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">]</span>,\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │    </span><span style=\"font-weight: bold\">[</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,  <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,  <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,  <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,  <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">]</span>,\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │    </span><span style=\"font-weight: bold\">[</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,  <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,  <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,  <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,  <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">]]</span>,\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span>\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"font-weight: bold\">[[</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,  <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,  <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,  <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>, <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">]</span>,\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │    </span><span style=\"font-weight: bold\">[</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,  <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,  <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,  <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>, <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">]</span>,\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │    </span><span style=\"font-weight: bold\">[</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,  <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,  <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,  <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>, <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">]</span>,\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │    </span><span style=\"font-weight: bold\">[</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,  <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,  <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,  <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>, <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">]</span>,\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │    </span><span style=\"font-weight: bold\">[</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,  <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,  <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,  <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>, <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">]]])</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m \u001b[3;92mTrue\u001b[0m,  \u001b[3;92mTrue\u001b[0m,  \u001b[3;92mTrue\u001b[0m, \u001b[3;91mFalse\u001b[0m, \u001b[3;91mFalse\u001b[0m\u001b[1m]\u001b[0m,\n",
              "\u001b[2;32m│   │    \u001b[0m\u001b[1m[\u001b[0m \u001b[3;92mTrue\u001b[0m,  \u001b[3;92mTrue\u001b[0m,  \u001b[3;92mTrue\u001b[0m, \u001b[3;91mFalse\u001b[0m, \u001b[3;91mFalse\u001b[0m\u001b[1m]\u001b[0m,\n",
              "\u001b[2;32m│   │    \u001b[0m\u001b[1m[\u001b[0m \u001b[3;92mTrue\u001b[0m,  \u001b[3;92mTrue\u001b[0m,  \u001b[3;92mTrue\u001b[0m, \u001b[3;91mFalse\u001b[0m, \u001b[3;91mFalse\u001b[0m\u001b[1m]\u001b[0m,\n",
              "\u001b[2;32m│   │    \u001b[0m\u001b[1m[\u001b[0m \u001b[3;92mTrue\u001b[0m,  \u001b[3;92mTrue\u001b[0m,  \u001b[3;92mTrue\u001b[0m, \u001b[3;91mFalse\u001b[0m, \u001b[3;91mFalse\u001b[0m\u001b[1m]\u001b[0m,\n",
              "\u001b[2;32m│   │    \u001b[0m\u001b[1m[\u001b[0m \u001b[3;92mTrue\u001b[0m,  \u001b[3;92mTrue\u001b[0m,  \u001b[3;92mTrue\u001b[0m, \u001b[3;91mFalse\u001b[0m, \u001b[3;91mFalse\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m,\n",
              "\u001b[2;32m│   │   \u001b[0m\n",
              "\u001b[2;32m│   │   \u001b[0m\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m \u001b[3;92mTrue\u001b[0m,  \u001b[3;92mTrue\u001b[0m, \u001b[3;91mFalse\u001b[0m, \u001b[3;91mFalse\u001b[0m, \u001b[3;91mFalse\u001b[0m\u001b[1m]\u001b[0m,\n",
              "\u001b[2;32m│   │    \u001b[0m\u001b[1m[\u001b[0m \u001b[3;92mTrue\u001b[0m,  \u001b[3;92mTrue\u001b[0m, \u001b[3;91mFalse\u001b[0m, \u001b[3;91mFalse\u001b[0m, \u001b[3;91mFalse\u001b[0m\u001b[1m]\u001b[0m,\n",
              "\u001b[2;32m│   │    \u001b[0m\u001b[1m[\u001b[0m \u001b[3;92mTrue\u001b[0m,  \u001b[3;92mTrue\u001b[0m, \u001b[3;91mFalse\u001b[0m, \u001b[3;91mFalse\u001b[0m, \u001b[3;91mFalse\u001b[0m\u001b[1m]\u001b[0m,\n",
              "\u001b[2;32m│   │    \u001b[0m\u001b[1m[\u001b[0m \u001b[3;92mTrue\u001b[0m,  \u001b[3;92mTrue\u001b[0m, \u001b[3;91mFalse\u001b[0m, \u001b[3;91mFalse\u001b[0m, \u001b[3;91mFalse\u001b[0m\u001b[1m]\u001b[0m,\n",
              "\u001b[2;32m│   │    \u001b[0m\u001b[1m[\u001b[0m \u001b[3;92mTrue\u001b[0m,  \u001b[3;92mTrue\u001b[0m, \u001b[3;91mFalse\u001b[0m, \u001b[3;91mFalse\u001b[0m, \u001b[3;91mFalse\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m,\n",
              "\u001b[2;32m│   │   \u001b[0m\n",
              "\u001b[2;32m│   │   \u001b[0m\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m \u001b[3;92mTrue\u001b[0m,  \u001b[3;92mTrue\u001b[0m,  \u001b[3;92mTrue\u001b[0m,  \u001b[3;92mTrue\u001b[0m,  \u001b[3;92mTrue\u001b[0m\u001b[1m]\u001b[0m,\n",
              "\u001b[2;32m│   │    \u001b[0m\u001b[1m[\u001b[0m \u001b[3;92mTrue\u001b[0m,  \u001b[3;92mTrue\u001b[0m,  \u001b[3;92mTrue\u001b[0m,  \u001b[3;92mTrue\u001b[0m,  \u001b[3;92mTrue\u001b[0m\u001b[1m]\u001b[0m,\n",
              "\u001b[2;32m│   │    \u001b[0m\u001b[1m[\u001b[0m \u001b[3;92mTrue\u001b[0m,  \u001b[3;92mTrue\u001b[0m,  \u001b[3;92mTrue\u001b[0m,  \u001b[3;92mTrue\u001b[0m,  \u001b[3;92mTrue\u001b[0m\u001b[1m]\u001b[0m,\n",
              "\u001b[2;32m│   │    \u001b[0m\u001b[1m[\u001b[0m \u001b[3;92mTrue\u001b[0m,  \u001b[3;92mTrue\u001b[0m,  \u001b[3;92mTrue\u001b[0m,  \u001b[3;92mTrue\u001b[0m,  \u001b[3;92mTrue\u001b[0m\u001b[1m]\u001b[0m,\n",
              "\u001b[2;32m│   │    \u001b[0m\u001b[1m[\u001b[0m \u001b[3;92mTrue\u001b[0m,  \u001b[3;92mTrue\u001b[0m,  \u001b[3;92mTrue\u001b[0m,  \u001b[3;92mTrue\u001b[0m,  \u001b[3;92mTrue\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m,\n",
              "\u001b[2;32m│   │   \u001b[0m\n",
              "\u001b[2;32m│   │   \u001b[0m\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m \u001b[3;92mTrue\u001b[0m,  \u001b[3;92mTrue\u001b[0m,  \u001b[3;92mTrue\u001b[0m,  \u001b[3;92mTrue\u001b[0m, \u001b[3;91mFalse\u001b[0m\u001b[1m]\u001b[0m,\n",
              "\u001b[2;32m│   │    \u001b[0m\u001b[1m[\u001b[0m \u001b[3;92mTrue\u001b[0m,  \u001b[3;92mTrue\u001b[0m,  \u001b[3;92mTrue\u001b[0m,  \u001b[3;92mTrue\u001b[0m, \u001b[3;91mFalse\u001b[0m\u001b[1m]\u001b[0m,\n",
              "\u001b[2;32m│   │    \u001b[0m\u001b[1m[\u001b[0m \u001b[3;92mTrue\u001b[0m,  \u001b[3;92mTrue\u001b[0m,  \u001b[3;92mTrue\u001b[0m,  \u001b[3;92mTrue\u001b[0m, \u001b[3;91mFalse\u001b[0m\u001b[1m]\u001b[0m,\n",
              "\u001b[2;32m│   │    \u001b[0m\u001b[1m[\u001b[0m \u001b[3;92mTrue\u001b[0m,  \u001b[3;92mTrue\u001b[0m,  \u001b[3;92mTrue\u001b[0m,  \u001b[3;92mTrue\u001b[0m, \u001b[3;91mFalse\u001b[0m\u001b[1m]\u001b[0m,\n",
              "\u001b[2;32m│   │    \u001b[0m\u001b[1m[\u001b[0m \u001b[3;92mTrue\u001b[0m,  \u001b[3;92mTrue\u001b[0m,  \u001b[3;92mTrue\u001b[0m,  \u001b[3;92mTrue\u001b[0m, \u001b[3;91mFalse\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">torch.Size</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span><span style=\"font-weight: bold\">])</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m4\u001b[0m, \u001b[1;36m5\u001b[0m, \u001b[1;36m5\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "pprint(target_padding_mask)\n",
        "pprint(target_padding_mask[0])\n",
        "\n",
        "target_padding_mask = target_padding_mask.view(batch_size, 1, seq_len).expand(size=(batch_size, seq_len, seq_len))\n",
        "pprint(target_padding_mask)\n",
        "pprint(target_padding_mask.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 145,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">tensor</span><span style=\"font-weight: bold\">([[</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,  <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,  <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>, <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>, <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">]</span>,\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"font-weight: bold\">[</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,  <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,  <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>, <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>, <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">]</span>,\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"font-weight: bold\">[</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,  <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,  <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>, <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>, <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">]</span>,\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"font-weight: bold\">[</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,  <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,  <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>, <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>, <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">]</span>,\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"font-weight: bold\">[</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,  <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,  <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>, <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>, <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">]])</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m \u001b[3;92mTrue\u001b[0m,  \u001b[3;92mTrue\u001b[0m,  \u001b[3;92mTrue\u001b[0m, \u001b[3;91mFalse\u001b[0m, \u001b[3;91mFalse\u001b[0m\u001b[1m]\u001b[0m,\n",
              "\u001b[2;32m│   │   \u001b[0m\u001b[1m[\u001b[0m \u001b[3;92mTrue\u001b[0m,  \u001b[3;92mTrue\u001b[0m,  \u001b[3;92mTrue\u001b[0m, \u001b[3;91mFalse\u001b[0m, \u001b[3;91mFalse\u001b[0m\u001b[1m]\u001b[0m,\n",
              "\u001b[2;32m│   │   \u001b[0m\u001b[1m[\u001b[0m \u001b[3;92mTrue\u001b[0m,  \u001b[3;92mTrue\u001b[0m,  \u001b[3;92mTrue\u001b[0m, \u001b[3;91mFalse\u001b[0m, \u001b[3;91mFalse\u001b[0m\u001b[1m]\u001b[0m,\n",
              "\u001b[2;32m│   │   \u001b[0m\u001b[1m[\u001b[0m \u001b[3;92mTrue\u001b[0m,  \u001b[3;92mTrue\u001b[0m,  \u001b[3;92mTrue\u001b[0m, \u001b[3;91mFalse\u001b[0m, \u001b[3;91mFalse\u001b[0m\u001b[1m]\u001b[0m,\n",
              "\u001b[2;32m│   │   \u001b[0m\u001b[1m[\u001b[0m \u001b[3;92mTrue\u001b[0m,  \u001b[3;92mTrue\u001b[0m,  \u001b[3;92mTrue\u001b[0m, \u001b[3;91mFalse\u001b[0m, \u001b[3;91mFalse\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">tensor</span><span style=\"font-weight: bold\">([[</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>, <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>, <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>, <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>, <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">]</span>,\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"font-weight: bold\">[</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,  <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>, <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>, <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>, <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">]</span>,\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"font-weight: bold\">[</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,  <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,  <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>, <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>, <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">]</span>,\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"font-weight: bold\">[</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,  <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,  <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,  <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>, <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">]</span>,\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"font-weight: bold\">[</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,  <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,  <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,  <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,  <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">]])</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m \u001b[3;92mTrue\u001b[0m, \u001b[3;91mFalse\u001b[0m, \u001b[3;91mFalse\u001b[0m, \u001b[3;91mFalse\u001b[0m, \u001b[3;91mFalse\u001b[0m\u001b[1m]\u001b[0m,\n",
              "\u001b[2;32m│   │   \u001b[0m\u001b[1m[\u001b[0m \u001b[3;92mTrue\u001b[0m,  \u001b[3;92mTrue\u001b[0m, \u001b[3;91mFalse\u001b[0m, \u001b[3;91mFalse\u001b[0m, \u001b[3;91mFalse\u001b[0m\u001b[1m]\u001b[0m,\n",
              "\u001b[2;32m│   │   \u001b[0m\u001b[1m[\u001b[0m \u001b[3;92mTrue\u001b[0m,  \u001b[3;92mTrue\u001b[0m,  \u001b[3;92mTrue\u001b[0m, \u001b[3;91mFalse\u001b[0m, \u001b[3;91mFalse\u001b[0m\u001b[1m]\u001b[0m,\n",
              "\u001b[2;32m│   │   \u001b[0m\u001b[1m[\u001b[0m \u001b[3;92mTrue\u001b[0m,  \u001b[3;92mTrue\u001b[0m,  \u001b[3;92mTrue\u001b[0m,  \u001b[3;92mTrue\u001b[0m, \u001b[3;91mFalse\u001b[0m\u001b[1m]\u001b[0m,\n",
              "\u001b[2;32m│   │   \u001b[0m\u001b[1m[\u001b[0m \u001b[3;92mTrue\u001b[0m,  \u001b[3;92mTrue\u001b[0m,  \u001b[3;92mTrue\u001b[0m,  \u001b[3;92mTrue\u001b[0m,  \u001b[3;92mTrue\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">tensor</span><span style=\"font-weight: bold\">([[</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>, <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>, <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>, <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>, <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">]</span>,\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"font-weight: bold\">[</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,  <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>, <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>, <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>, <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">]</span>,\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"font-weight: bold\">[</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,  <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,  <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>, <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>, <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">]</span>,\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"font-weight: bold\">[</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,  <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,  <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>, <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>, <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">]</span>,\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"font-weight: bold\">[</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,  <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,  <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>, <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>, <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">]])</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m \u001b[3;92mTrue\u001b[0m, \u001b[3;91mFalse\u001b[0m, \u001b[3;91mFalse\u001b[0m, \u001b[3;91mFalse\u001b[0m, \u001b[3;91mFalse\u001b[0m\u001b[1m]\u001b[0m,\n",
              "\u001b[2;32m│   │   \u001b[0m\u001b[1m[\u001b[0m \u001b[3;92mTrue\u001b[0m,  \u001b[3;92mTrue\u001b[0m, \u001b[3;91mFalse\u001b[0m, \u001b[3;91mFalse\u001b[0m, \u001b[3;91mFalse\u001b[0m\u001b[1m]\u001b[0m,\n",
              "\u001b[2;32m│   │   \u001b[0m\u001b[1m[\u001b[0m \u001b[3;92mTrue\u001b[0m,  \u001b[3;92mTrue\u001b[0m,  \u001b[3;92mTrue\u001b[0m, \u001b[3;91mFalse\u001b[0m, \u001b[3;91mFalse\u001b[0m\u001b[1m]\u001b[0m,\n",
              "\u001b[2;32m│   │   \u001b[0m\u001b[1m[\u001b[0m \u001b[3;92mTrue\u001b[0m,  \u001b[3;92mTrue\u001b[0m,  \u001b[3;92mTrue\u001b[0m, \u001b[3;91mFalse\u001b[0m, \u001b[3;91mFalse\u001b[0m\u001b[1m]\u001b[0m,\n",
              "\u001b[2;32m│   │   \u001b[0m\u001b[1m[\u001b[0m \u001b[3;92mTrue\u001b[0m,  \u001b[3;92mTrue\u001b[0m,  \u001b[3;92mTrue\u001b[0m, \u001b[3;91mFalse\u001b[0m, \u001b[3;91mFalse\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "pprint(target_padding_mask[0])\n",
        "pprint(future_mask[0])\n",
        "pprint(target_padding_mask[0] & future_mask[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### First Sample Fourth Token\n",
        "\n",
        "Now let's look at another example—the 4th token in the sequence, where\n",
        "`target_padding_mask = [T, T, T, F, F]` and `future_mask` is a lower triangular\n",
        "matrix with `True`s.\n",
        "\n",
        "1. **4th Token's target_padding_mask**: The 4th token has a value of `F` in\n",
        "   `target_padding_mask`, indicating it's a padding token.\n",
        "\n",
        "2. **4th Row of future_mask**: The 4th row in `future_mask` is\n",
        "   `[True, True, True, True, False]`. This means that if this token were not a\n",
        "   padding token, it would be allowed to attend to all the previous tokens in\n",
        "   the sequence and itself, but not to any future token.\n",
        "\n",
        "3. **Broadcast target_padding_mask**: To align `target_padding_mask` with\n",
        "   `future_mask`, we'd broadcast `F` from the `target_padding_mask` to\n",
        "   `[F, F, F, F, F]`. This way, when we consider the 4th token in relation to\n",
        "   any other token in the sequence, it's still marked as a padding token.\n",
        "\n",
        "4. **Element-wise AND with future_mask**: After broadcasting, you'd perform an\n",
        "   element-wise AND between `[F, F, F, F, F]` and\n",
        "   `[True, True, True, True, False]`, resulting in `[F, F, F, F, F]`.\n",
        "\n",
        "5. **Interpretation**: This effectively means that the 4th token won't attend to\n",
        "   any other token in the sequence, and no token will attend to it either, as it\n",
        "   is a padding token.\n",
        "\n",
        "So, the masks are doing their jobs correctly: the `target_padding_mask`\n",
        "indicates whether each token is a padding token or not, and `future_mask`\n",
        "dictates the \"rules\" of attention regarding what each token can attend to.\n",
        "Combining them ensures that both conditions are met.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Further Add a Singleton Dimension in Target Masks\n",
        "\n",
        "Now both masks are of shape: `(B, L, L)` but we need to add a singleton\n",
        "dimension to the last dimension to make it `(B, 1, L, L)`.\n",
        "\n",
        "In deep learning frameworks like PyTorch, the dimensions of the tensors involved\n",
        "in operations like matrix multiplication or attention mechanisms often have\n",
        "specific semantic meanings. In the context of attention mechanisms, especially\n",
        "in the transformer architecture, the attention mask usually has a shape that is\n",
        "compatible with the attention logits for element-wise multiplication.\n",
        "\n",
        "In the transformer model, the attention logits are often computed as a dot\n",
        "product between query and key vectors, resulting in a tensor of shape\n",
        "`(Batch size, Num heads, Sequence length, Sequence length)` or `(B, H, L, L)`.\n",
        "Here, `B` is the batch size, `H` is the number of attention heads, and `L` is\n",
        "the sequence length.\n",
        "\n",
        "To make the mask tensor compatible for element-wise operations with this 4D\n",
        "tensor, it needs to have a shape that can be broadcasted to `(B, H, L, L)`. A\n",
        "mask of shape `(B, 1, L, L)` fulfills this requirement.\n",
        "\n",
        "The singleton dimension is added so that the mask can be easily broadcast to the\n",
        "shape of the attention logits tensor during the computation. When a tensor with\n",
        "shape `(B, 1, L, L)` is element-wise multiplied with a tensor of shape\n",
        "`(B, H, L, L)`, the singleton dimension (the `1`) allows the mask to be used for\n",
        "each attention head without explicitly replicating the mask `H` times. This is\n",
        "more memory-efficient and often faster.\n",
        "\n",
        "Thus, adding a singleton dimension in masks is a preparatory step that allows\n",
        "for efficient element-wise operations later in the model's forward pass.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 146,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">torch.Size</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span><span style=\"font-weight: bold\">])</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m4\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m5\u001b[0m, \u001b[1;36m5\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">torch.Size</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span><span style=\"font-weight: bold\">])</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m4\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m5\u001b[0m, \u001b[1;36m5\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">torch.Size</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span><span style=\"font-weight: bold\">])</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m4\u001b[0m, \u001b[1;36m1\u001b[0m, \u001b[1;36m5\u001b[0m, \u001b[1;36m5\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "target_padding_mask = target_padding_mask.unsqueeze(1)\n",
        "pprint(target_padding_mask.shape)\n",
        "\n",
        "future_mask = future_mask.unsqueeze(1)\n",
        "pprint(future_mask.shape)\n",
        "\n",
        "target_mask = target_padding_mask & future_mask\n",
        "pprint(target_mask.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Split to Train-Valid-Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 147,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(7000, 2000, 1000)"
            ]
          },
          "execution_count": 147,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "batch_size   = 256\n",
        "\n",
        "composer.data.train_loader[\"batch_size\"] = batch_size\n",
        "composer.data.valid_loader[\"batch_size\"] = batch_size\n",
        "composer.data.test_loader[\"batch_size\"] = batch_size\n",
        "\n",
        "train_dataset, valid_dataset, test_dataset = split_dataset(\n",
        "    dataset=dataset, split=composer.data.split, seed=composer.global_.seed\n",
        ")\n",
        "\n",
        "train_size, valid_size, test_size = len(train_dataset), len(valid_dataset), len(test_dataset)\n",
        "train_size, valid_size, test_size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 148,
      "metadata": {},
      "outputs": [],
      "source": [
        "# max_seq_len is determined by 1+ num_digits + 1 + num_digits + 1 + num_digits + 1 + 1\n",
        "# where the 1s represent BOS, Plus sign, Equal sign, the extra digit in the sum, EOS, respectively.\n",
        "max_seq_len = 1 + 1 + 1 + 1 + 2 * composer.constants.NUM_DIGITS + (composer.constants.NUM_DIGITS + 1)\n",
        "assert max_seq_len == composer.data.context_length"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Create DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 149,
      "metadata": {},
      "outputs": [],
      "source": [
        "train_loader = create_loader(\n",
        "    dataset=train_dataset,\n",
        "    loader_config=composer.data.train_loader,\n",
        "    collate_fn_config=composer.data.collate_fn,\n",
        ")\n",
        "\n",
        "valid_loader = create_loader(\n",
        "    dataset=valid_dataset,\n",
        "    loader_config=composer.data.valid_loader,\n",
        "    collate_fn_config=composer.data.collate_fn,\n",
        ")\n",
        "\n",
        "test_loader = create_loader(\n",
        "    dataset=test_dataset,\n",
        "    loader_config=composer.data.test_loader,\n",
        "    collate_fn_config=composer.data.collate_fn,\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The `collate_fn` defines how to combine these variable-length samples into a\n",
        "batch. This usually involves padding the sequences in the batch to a common\n",
        "length, which is typically the length of the longest sequence in the batch. Note\n",
        "here the padding in collate is \"redundant\" since in our earlier code we ensured\n",
        "that all sample has same number of characters by way of padding zeros in front.\n",
        "For example, `23 + 3 =26` will become `23 + 03 = 026`. Consequently, all samples\n",
        "in the mini-batch will have same length by definition."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 150,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Batch Size: 256\n",
            "Inputs Shape: torch.Size([256, 10])\n",
            "Targets Shape: torch.Size([256, 10])\n",
            "Decoded First Equation/Sample of the Batch: 31+04=035\n",
            "--------------------------------------------------------------------------------\n",
            "Batch Size: 256\n",
            "Inputs Shape: torch.Size([256, 10])\n",
            "Targets Shape: torch.Size([256, 10])\n",
            "Decoded First Equation/Sample of the Batch: 37+49=086\n",
            "--------------------------------------------------------------------------------\n",
            "Batch Size: 256\n",
            "Inputs Shape: torch.Size([256, 10])\n",
            "Targets Shape: torch.Size([256, 10])\n",
            "Decoded First Equation/Sample of the Batch: 47+26=073\n",
            "--------------------------------------------------------------------------------\n",
            "Batch Size: 256\n",
            "Inputs Shape: torch.Size([256, 10])\n",
            "Targets Shape: torch.Size([256, 10])\n",
            "Decoded First Equation/Sample of the Batch: 53+05=058\n",
            "--------------------------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "torch.manual_seed(composer.global_.seed)\n",
        "\n",
        "batch_index = 0\n",
        "for batch in train_loader:\n",
        "    # Each batch is a tuple containing all elements for the batch\n",
        "    inputs_padded, targets_padded, padding_masks_padded_and_expanded, future_masks_expanded = batch\n",
        "\n",
        "    # Print the length of each component in the batch\n",
        "    print(\"Batch Size:\", len(inputs_padded))\n",
        "\n",
        "    # Now you can print shapes or other properties of each batch element\n",
        "    print(\"Inputs Shape:\", inputs_padded.shape)\n",
        "    print(\"Targets Shape:\", targets_padded.shape)\n",
        "\n",
        "    # Decoding and other processing can be done here\n",
        "    # For example, decoding the first sequence in the batch\n",
        "    print(\"Decoded First Equation/Sample of the Batch:\", decode_equation(vocabulary, inputs_padded[0].tolist()))\n",
        "\n",
        "    print(\"-\" * 80)\n",
        "\n",
        "    batch_index += 1\n",
        "    if batch_index == 4: break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 151,
      "metadata": {
        "id": "NTROZtD4rdzc",
        "outputId": "253c0d26-f2d1-49ad-bd5c-b623d6c79339"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "model_size: 270226, train_set_size: 7000\n"
          ]
        }
      ],
      "source": [
        "# Create individual component configurations\n",
        "masked_self_attention_mha_config = MultiHeadedAttentionConfig(\n",
        "     attention=ScaledDotProductAttention(),\n",
        "    d_model=128, H=4, dropout=0.1\n",
        ")\n",
        "\n",
        "feed_forward_config = PositionwiseFeedForwardConfig(\n",
        "    d_model=128, d_ff=256, activation=nn.GELU(approximate=\"tanh\"), dropout=0.1, bias=True\n",
        ")\n",
        "\n",
        "add_norm_config_1 = AddNormConfig(feature_dim=128, dropout=0.1)\n",
        "add_norm_config_2 = AddNormConfig(feature_dim=128, dropout=0.1)\n",
        "\n",
        "# Create DecoderBlockConfig\n",
        "decoder_block_config = DecoderBlockConfig(\n",
        "    masked_self_attention_mha=masked_self_attention_mha_config,\n",
        "    feed_forward=feed_forward_config,\n",
        "    add_norm_1=add_norm_config_1,\n",
        "    add_norm_2=add_norm_config_2,\n",
        ")\n",
        "\n",
        "# Create the overall DecoderConfig\n",
        "model_config = DecoderConfig(\n",
        "    d_model=128,\n",
        "    vocab_size=vocab_size,\n",
        "    context_length=max_seq_len,\n",
        "    num_decoder_blocks=2,\n",
        "    dropout=0.1,\n",
        "    decoder_block=decoder_block_config,\n",
        ")\n",
        "\n",
        "model = GPTDecoder(model_config).to(composer.trainer.device)\n",
        "\n",
        "model_size = model.total_trainable_parameters\n",
        "print(f'model_size: {model_size}, train_set_size: {train_size}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Training Paradigm\n",
        "\n",
        "### Optimizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Learning Rate Scheduler\n",
        "\n",
        "see common utils"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Loss\n",
        "\n",
        "Talk and link to bottom notes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 152,
      "metadata": {
        "id": "TpbLlCLRrdzc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Adam (\n",
            "Parameter Group 0\n",
            "    amsgrad: False\n",
            "    betas: (0.9, 0.98)\n",
            "    capturable: False\n",
            "    differentiable: False\n",
            "    eps: 1e-09\n",
            "    foreach: None\n",
            "    fused: None\n",
            "    lr: 0.2\n",
            "    maximize: False\n",
            "    weight_decay: 0.0\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "warmup_steps = 3 * len(train_loader)\n",
        "# lr first increases in the warmup steps, and then decays\n",
        "lr_fn        = lambda step: model_config.d_model**(-0.5) * min([(step+1)**(-0.5), (step+1)*warmup_steps**(-1.5)])\n",
        "# optimizer    = torch.optim.Adam(model.parameters(), lr=0.2, betas=(0.9, 0.98), eps=1e-9)\n",
        "\n",
        "# optimizer_config = OptimizerConfig(name=\"torch.optim.Adam\", lr=0.2, betas=(0.9, 0.98), eps=1e-9)\n",
        "# optimizer   = optimizer_config.build(params=model.parameters())\n",
        "\n",
        "# optimizer_config = OptimizerConfig(name=\"torch.optim.Adam\", lr=0.2)\n",
        "# optimizer   = optimizer_config.build(params=model.parameters(), betas=(0.9, 0.98), eps=1e-9)\n",
        "\n",
        "optimizer   = composer.optimizer.build(params=model.parameters())\n",
        "print(optimizer)\n",
        "scheduler    = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=lr_fn)\n",
        "criterion    = nn.CrossEntropyLoss(ignore_index=PAD, reduction=\"mean\")\n",
        "\n",
        "\n",
        "@dataclass\n",
        "class Metrics:\n",
        "    loss: Loss\n",
        "    accuracy: Accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bVvd-RL-rdzd"
      },
      "source": [
        "1. `input` is indeed `[bs, 10]` because max len is 11, so removed last token.\n",
        "2. `target` should be `[bs, 10]` but left shifted of the real original input but somehow i got 11.\n",
        "3. Think of vocab size to be num classes in my classification problem. But the"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 153,
      "metadata": {},
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'optimizer_pydantic_config' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[153], line 10\u001b[0m\n\u001b[1;32m      4\u001b[0m     optimizer \u001b[38;5;241m=\u001b[39m optimizer_pydantic_config\u001b[38;5;241m.\u001b[39mbuild(\n\u001b[1;32m      5\u001b[0m         params\u001b[38;5;241m=\u001b[39mapply_weight_decay_to_different_param_groups(\n\u001b[1;32m      6\u001b[0m             model\u001b[38;5;241m=\u001b[39mmodel, weight_decay\u001b[38;5;241m=\u001b[39mcomposer\u001b[38;5;241m.\u001b[39moptimizer\u001b[38;5;241m.\u001b[39mweight_decay\n\u001b[1;32m      7\u001b[0m         )\n\u001b[1;32m      8\u001b[0m     )\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 10\u001b[0m     optimizer \u001b[38;5;241m=\u001b[39m \u001b[43moptimizer_pydantic_config\u001b[49m\u001b[38;5;241m.\u001b[39mbuild(params\u001b[38;5;241m=\u001b[39mmodel\u001b[38;5;241m.\u001b[39mparameters())\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# Create criterion\u001b[39;00m\n\u001b[1;32m     13\u001b[0m criterion \u001b[38;5;241m=\u001b[39m criterion_pydantic_config\u001b[38;5;241m.\u001b[39mcreate_instance()\n",
            "\u001b[0;31mNameError\u001b[0m: name 'optimizer_pydantic_config' is not defined"
          ]
        }
      ],
      "source": [
        "    # Create optimizer based on model parameters\n",
        "    if composer.trainer.apply_weight_decay_to_different_param_groups:\n",
        "        assert hasattr(composer.optimizer, \"weight_decay\")\n",
        "        optimizer = optimizer_pydantic_config.build(\n",
        "            params=apply_weight_decay_to_different_param_groups(\n",
        "                model=model, weight_decay=composer.optimizer.weight_decay\n",
        "            )\n",
        "        )\n",
        "    else:\n",
        "        optimizer = optimizer_pydantic_config.build(params=model.parameters())\n",
        "\n",
        "    # Create criterion\n",
        "    criterion = criterion_pydantic_config.create_instance()\n",
        "    assert criterion.ignore_index == vocabulary.token_to_index[vocabulary.PAD]\n",
        "\n",
        "    # Create Scheduler noam\n",
        "    # TODO: this part is hardcoded in a way since we are using LambdaLR.\n",
        "    # I do not have time to make it more \"automated\" so this is anti-config-pattern.\n",
        "    warmup_steps = 3 * len(train_loader)\n",
        "\n",
        "    # lr first increases in the warmup steps, and then decays\n",
        "    noam = lambda step: noam_lr_decay(step, d_model=composer.model.d_model, warmup_steps=warmup_steps)  # noqa: E731\n",
        "\n",
        "    scheduler_config_cls = SCHEDULER_REGISTRY[cfg.scheduler.name]\n",
        "\n",
        "\n",
        "    if issubclass(scheduler_config_cls, LambdaLRConfig):\n",
        "        scheduler_pydantic_config = scheduler_config_cls(lr_lambda=noam, **cfg.scheduler)\n",
        "    else:\n",
        "        scheduler_pydantic_config = scheduler_config_cls(**cfg.scheduler)  # type: ignore[assignment]\n",
        "\n",
        "    assert composer.scheduler is MISSING  # now it is MISSING for us to fill up.\n",
        "    composer.scheduler = scheduler_pydantic_config\n",
        "    scheduler = scheduler_pydantic_config.build(optimizer=optimizer)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">State</span><span style=\"font-weight: bold\">(</span>\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #808000; text-decoration-color: #808000\">model</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">GPTDecoder</span><span style=\"font-weight: bold\">(</span>\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">  </span><span style=\"font-weight: bold\">(</span>tok_embed<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Embedding</span><span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">18</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">128</span><span style=\"font-weight: bold\">)</span>\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">  </span><span style=\"font-weight: bold\">(</span>decoder_blocks<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">ModuleList</span><span style=\"font-weight: bold\">(</span>\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>-<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">)</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span> x <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">GPTDecoderBlock</span><span style=\"font-weight: bold\">(</span>\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│     </span><span style=\"font-weight: bold\">(</span>masked_self_attention_mha<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">MultiHeadedAttention</span><span style=\"font-weight: bold\">(</span>\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"font-weight: bold\">(</span>W_Q<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Linear</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">in_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">128</span>, <span style=\"color: #808000; text-decoration-color: #808000\">out_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">128</span>, <span style=\"color: #808000; text-decoration-color: #808000\">bias</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">)</span>\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"font-weight: bold\">(</span>W_K<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Linear</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">in_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">128</span>, <span style=\"color: #808000; text-decoration-color: #808000\">out_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">128</span>, <span style=\"color: #808000; text-decoration-color: #808000\">bias</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">)</span>\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"font-weight: bold\">(</span>W_V<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Linear</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">in_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">128</span>, <span style=\"color: #808000; text-decoration-color: #808000\">out_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">128</span>, <span style=\"color: #808000; text-decoration-color: #808000\">bias</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">)</span>\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"font-weight: bold\">(</span>W_O<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Linear</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">in_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">128</span>, <span style=\"color: #808000; text-decoration-color: #808000\">out_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">128</span>, <span style=\"color: #808000; text-decoration-color: #808000\">bias</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">)</span>\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"font-weight: bold\">(</span>attention<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">ScaledDotProductAttention</span><span style=\"font-weight: bold\">(</span>\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │     </span><span style=\"font-weight: bold\">(</span>dropout<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Dropout</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">p</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0</span>, <span style=\"color: #808000; text-decoration-color: #808000\">inplace</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">)</span>\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"font-weight: bold\">)</span>\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"font-weight: bold\">(</span>dropout<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Dropout</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">p</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1</span>, <span style=\"color: #808000; text-decoration-color: #808000\">inplace</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">)</span>\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│     </span><span style=\"font-weight: bold\">)</span>\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│     </span><span style=\"font-weight: bold\">(</span>feed_forward<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">PositionwiseFeedForward</span><span style=\"font-weight: bold\">(</span>\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"font-weight: bold\">(</span>ffn<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">ModuleDict</span><span style=\"font-weight: bold\">(</span>\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │     </span><span style=\"font-weight: bold\">(</span>context_fc<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Linear</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">in_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">128</span>, <span style=\"color: #808000; text-decoration-color: #808000\">out_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">256</span>, <span style=\"color: #808000; text-decoration-color: #808000\">bias</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │     </span><span style=\"font-weight: bold\">(</span>activation<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">GELU</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">approximate</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'tanh'</span><span style=\"font-weight: bold\">)</span>\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │     </span><span style=\"font-weight: bold\">(</span>context_projection<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Linear</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">in_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">256</span>, <span style=\"color: #808000; text-decoration-color: #808000\">out_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">128</span>, <span style=\"color: #808000; text-decoration-color: #808000\">bias</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │     </span><span style=\"font-weight: bold\">(</span>dropout<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Dropout</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">p</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1</span>, <span style=\"color: #808000; text-decoration-color: #808000\">inplace</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">)</span>\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"font-weight: bold\">)</span>\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│     </span><span style=\"font-weight: bold\">)</span>\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│     </span><span style=\"font-weight: bold\">(</span>add_norm_1<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">AddNorm</span><span style=\"font-weight: bold\">(</span>\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"font-weight: bold\">(</span>dropout<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Dropout</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">p</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1</span>, <span style=\"color: #808000; text-decoration-color: #808000\">inplace</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">)</span>\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"font-weight: bold\">(</span>layer_norm<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">LayerNorm</span><span style=\"font-weight: bold\">((</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">128</span>,<span style=\"font-weight: bold\">)</span>, <span style=\"color: #808000; text-decoration-color: #808000\">eps</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1e-05</span>, <span style=\"color: #808000; text-decoration-color: #808000\">elementwise_affine</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│     </span><span style=\"font-weight: bold\">)</span>\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│     </span><span style=\"font-weight: bold\">(</span>add_norm_2<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">AddNorm</span><span style=\"font-weight: bold\">(</span>\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"font-weight: bold\">(</span>dropout<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Dropout</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">p</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1</span>, <span style=\"color: #808000; text-decoration-color: #808000\">inplace</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">)</span>\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"font-weight: bold\">(</span>layer_norm<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">LayerNorm</span><span style=\"font-weight: bold\">((</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">128</span>,<span style=\"font-weight: bold\">)</span>, <span style=\"color: #808000; text-decoration-color: #808000\">eps</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1e-05</span>, <span style=\"color: #808000; text-decoration-color: #808000\">elementwise_affine</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│     </span><span style=\"font-weight: bold\">)</span>\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"font-weight: bold\">)</span>\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">  </span><span style=\"font-weight: bold\">)</span>\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">  </span><span style=\"font-weight: bold\">(</span>dropout<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Dropout</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">p</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1</span>, <span style=\"color: #808000; text-decoration-color: #808000\">inplace</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">)</span>\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">  </span><span style=\"font-weight: bold\">(</span>layer_norm<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">LayerNorm</span><span style=\"font-weight: bold\">((</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">128</span>,<span style=\"font-weight: bold\">)</span>, <span style=\"color: #808000; text-decoration-color: #808000\">eps</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1e-05</span>, <span style=\"color: #808000; text-decoration-color: #808000\">elementwise_affine</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">  </span><span style=\"font-weight: bold\">(</span>head<span style=\"font-weight: bold\">)</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Linear</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">in_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">128</span>, <span style=\"color: #808000; text-decoration-color: #808000\">out_features</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">18</span>, <span style=\"color: #808000; text-decoration-color: #808000\">bias</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">)</span>\n",
              "<span style=\"font-weight: bold\">)</span>,\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #808000; text-decoration-color: #808000\">criterion</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">CrossEntropyLoss</span><span style=\"font-weight: bold\">()</span>,\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #808000; text-decoration-color: #808000\">optimizer</span>=<span style=\"color: #800080; text-decoration-color: #800080\">Adam</span> <span style=\"font-weight: bold\">(</span>\n",
              "Parameter Group <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span>amsgrad: <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span>betas: <span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.9</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.98</span><span style=\"font-weight: bold\">)</span>\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span>capturable: <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span>differentiable: <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span>eps: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1e-09</span>\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span>foreach: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span>fused: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span>initial_lr: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.2</span>\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span>lr: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2.2961808030073203e-05</span>\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span>maximize: <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span>weight_decay: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0</span>\n",
              "<span style=\"font-weight: bold\">)</span>,\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #808000; text-decoration-color: #808000\">scheduler</span>=<span style=\"font-weight: bold\">&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">torch.optim.lr_scheduler.LambdaLR</span><span style=\"color: #000000; text-decoration-color: #000000\"> object at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0x1657a0730</span><span style=\"color: #000000; text-decoration-color: #000000\">&gt;,</span>\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #808000; text-decoration-color: #808000\">epoch_index</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #808000; text-decoration-color: #808000\">train_batch_index</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #808000; text-decoration-color: #808000\">step_index</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #808000; text-decoration-color: #808000\">history</span><span style=\"color: #000000; text-decoration-color: #000000\">=</span><span style=\"color: #000000; text-decoration-color: #000000; font-weight: bold\">{}</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #808000; text-decoration-color: #808000\">vocabulary</span><span style=\"color: #000000; text-decoration-color: #000000\">=&lt;omnivault.transformer.core.vocabulary.AdderVocabulary object at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0x1659237f0</span><span style=\"color: #000000; text-decoration-color: #000000\">&gt;,</span>\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #808000; text-decoration-color: #808000\">tokenizer</span><span style=\"color: #000000; text-decoration-color: #000000\">=&lt;omnivault.transformer.core.tokenizer.AdderTokenizer object at </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0x1659233d0</span><span style=\"font-weight: bold\">&gt;</span>\n",
              "<span style=\"font-weight: bold\">)</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1;35mState\u001b[0m\u001b[1m(\u001b[0m\n",
              "\u001b[2;32m│   \u001b[0m\u001b[33mmodel\u001b[0m=\u001b[1;35mGPTDecoder\u001b[0m\u001b[1m(\u001b[0m\n",
              "\u001b[2;32m  \u001b[0m\u001b[1m(\u001b[0mtok_embed\u001b[1m)\u001b[0m: \u001b[1;35mEmbedding\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m18\u001b[0m, \u001b[1;36m128\u001b[0m\u001b[1m)\u001b[0m\n",
              "\u001b[2;32m  \u001b[0m\u001b[1m(\u001b[0mdecoder_blocks\u001b[1m)\u001b[0m: \u001b[1;35mModuleList\u001b[0m\u001b[1m(\u001b[0m\n",
              "\u001b[2;32m│   \u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m0\u001b[0m-\u001b[1;36m1\u001b[0m\u001b[1m)\u001b[0m: \u001b[1;36m2\u001b[0m x \u001b[1;35mGPTDecoderBlock\u001b[0m\u001b[1m(\u001b[0m\n",
              "\u001b[2;32m│     \u001b[0m\u001b[1m(\u001b[0mmasked_self_attention_mha\u001b[1m)\u001b[0m: \u001b[1;35mMultiHeadedAttention\u001b[0m\u001b[1m(\u001b[0m\n",
              "\u001b[2;32m│   │   \u001b[0m\u001b[1m(\u001b[0mW_Q\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m128\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m128\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
              "\u001b[2;32m│   │   \u001b[0m\u001b[1m(\u001b[0mW_K\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m128\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m128\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
              "\u001b[2;32m│   │   \u001b[0m\u001b[1m(\u001b[0mW_V\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m128\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m128\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
              "\u001b[2;32m│   │   \u001b[0m\u001b[1m(\u001b[0mW_O\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m128\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m128\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
              "\u001b[2;32m│   │   \u001b[0m\u001b[1m(\u001b[0mattention\u001b[1m)\u001b[0m: \u001b[1;35mScaledDotProductAttention\u001b[0m\u001b[1m(\u001b[0m\n",
              "\u001b[2;32m│   │     \u001b[0m\u001b[1m(\u001b[0mdropout\u001b[1m)\u001b[0m: \u001b[1;35mDropout\u001b[0m\u001b[1m(\u001b[0m\u001b[33mp\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.0\u001b[0m, \u001b[33minplace\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
              "\u001b[2;32m│   │   \u001b[0m\u001b[1m)\u001b[0m\n",
              "\u001b[2;32m│   │   \u001b[0m\u001b[1m(\u001b[0mdropout\u001b[1m)\u001b[0m: \u001b[1;35mDropout\u001b[0m\u001b[1m(\u001b[0m\u001b[33mp\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.1\u001b[0m, \u001b[33minplace\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
              "\u001b[2;32m│     \u001b[0m\u001b[1m)\u001b[0m\n",
              "\u001b[2;32m│     \u001b[0m\u001b[1m(\u001b[0mfeed_forward\u001b[1m)\u001b[0m: \u001b[1;35mPositionwiseFeedForward\u001b[0m\u001b[1m(\u001b[0m\n",
              "\u001b[2;32m│   │   \u001b[0m\u001b[1m(\u001b[0mffn\u001b[1m)\u001b[0m: \u001b[1;35mModuleDict\u001b[0m\u001b[1m(\u001b[0m\n",
              "\u001b[2;32m│   │     \u001b[0m\u001b[1m(\u001b[0mcontext_fc\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m128\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m256\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "\u001b[2;32m│   │     \u001b[0m\u001b[1m(\u001b[0mactivation\u001b[1m)\u001b[0m: \u001b[1;35mGELU\u001b[0m\u001b[1m(\u001b[0m\u001b[33mapproximate\u001b[0m=\u001b[32m'tanh'\u001b[0m\u001b[1m)\u001b[0m\n",
              "\u001b[2;32m│   │     \u001b[0m\u001b[1m(\u001b[0mcontext_projection\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m256\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m128\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "\u001b[2;32m│   │     \u001b[0m\u001b[1m(\u001b[0mdropout\u001b[1m)\u001b[0m: \u001b[1;35mDropout\u001b[0m\u001b[1m(\u001b[0m\u001b[33mp\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.1\u001b[0m, \u001b[33minplace\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
              "\u001b[2;32m│   │   \u001b[0m\u001b[1m)\u001b[0m\n",
              "\u001b[2;32m│     \u001b[0m\u001b[1m)\u001b[0m\n",
              "\u001b[2;32m│     \u001b[0m\u001b[1m(\u001b[0madd_norm_1\u001b[1m)\u001b[0m: \u001b[1;35mAddNorm\u001b[0m\u001b[1m(\u001b[0m\n",
              "\u001b[2;32m│   │   \u001b[0m\u001b[1m(\u001b[0mdropout\u001b[1m)\u001b[0m: \u001b[1;35mDropout\u001b[0m\u001b[1m(\u001b[0m\u001b[33mp\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.1\u001b[0m, \u001b[33minplace\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
              "\u001b[2;32m│   │   \u001b[0m\u001b[1m(\u001b[0mlayer_norm\u001b[1m)\u001b[0m: \u001b[1;35mLayerNorm\u001b[0m\u001b[1m(\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m128\u001b[0m,\u001b[1m)\u001b[0m, \u001b[33meps\u001b[0m=\u001b[1;36m1e\u001b[0m\u001b[1;36m-05\u001b[0m, \u001b[33melementwise_affine\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "\u001b[2;32m│     \u001b[0m\u001b[1m)\u001b[0m\n",
              "\u001b[2;32m│     \u001b[0m\u001b[1m(\u001b[0madd_norm_2\u001b[1m)\u001b[0m: \u001b[1;35mAddNorm\u001b[0m\u001b[1m(\u001b[0m\n",
              "\u001b[2;32m│   │   \u001b[0m\u001b[1m(\u001b[0mdropout\u001b[1m)\u001b[0m: \u001b[1;35mDropout\u001b[0m\u001b[1m(\u001b[0m\u001b[33mp\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.1\u001b[0m, \u001b[33minplace\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
              "\u001b[2;32m│   │   \u001b[0m\u001b[1m(\u001b[0mlayer_norm\u001b[1m)\u001b[0m: \u001b[1;35mLayerNorm\u001b[0m\u001b[1m(\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m128\u001b[0m,\u001b[1m)\u001b[0m, \u001b[33meps\u001b[0m=\u001b[1;36m1e\u001b[0m\u001b[1;36m-05\u001b[0m, \u001b[33melementwise_affine\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "\u001b[2;32m│     \u001b[0m\u001b[1m)\u001b[0m\n",
              "\u001b[2;32m│   \u001b[0m\u001b[1m)\u001b[0m\n",
              "\u001b[2;32m  \u001b[0m\u001b[1m)\u001b[0m\n",
              "\u001b[2;32m  \u001b[0m\u001b[1m(\u001b[0mdropout\u001b[1m)\u001b[0m: \u001b[1;35mDropout\u001b[0m\u001b[1m(\u001b[0m\u001b[33mp\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.1\u001b[0m, \u001b[33minplace\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m\n",
              "\u001b[2;32m  \u001b[0m\u001b[1m(\u001b[0mlayer_norm\u001b[1m)\u001b[0m: \u001b[1;35mLayerNorm\u001b[0m\u001b[1m(\u001b[0m\u001b[1m(\u001b[0m\u001b[1;36m128\u001b[0m,\u001b[1m)\u001b[0m, \u001b[33meps\u001b[0m=\u001b[1;36m1e\u001b[0m\u001b[1;36m-05\u001b[0m, \u001b[33melementwise_affine\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "\u001b[2;32m  \u001b[0m\u001b[1m(\u001b[0mhead\u001b[1m)\u001b[0m: \u001b[1;35mLinear\u001b[0m\u001b[1m(\u001b[0m\u001b[33min_features\u001b[0m=\u001b[1;36m128\u001b[0m, \u001b[33mout_features\u001b[0m=\u001b[1;36m18\u001b[0m, \u001b[33mbias\u001b[0m=\u001b[3;92mTrue\u001b[0m\u001b[1m)\u001b[0m\n",
              "\u001b[1m)\u001b[0m,\n",
              "\u001b[2;32m│   \u001b[0m\u001b[33mcriterion\u001b[0m=\u001b[1;35mCrossEntropyLoss\u001b[0m\u001b[1m(\u001b[0m\u001b[1m)\u001b[0m,\n",
              "\u001b[2;32m│   \u001b[0m\u001b[33moptimizer\u001b[0m=\u001b[35mAdam\u001b[0m \u001b[1m(\u001b[0m\n",
              "Parameter Group \u001b[1;36m0\u001b[0m\n",
              "\u001b[2;32m│   \u001b[0mamsgrad: \u001b[3;91mFalse\u001b[0m\n",
              "\u001b[2;32m│   \u001b[0mbetas: \u001b[1m(\u001b[0m\u001b[1;36m0.9\u001b[0m, \u001b[1;36m0.98\u001b[0m\u001b[1m)\u001b[0m\n",
              "\u001b[2;32m│   \u001b[0mcapturable: \u001b[3;91mFalse\u001b[0m\n",
              "\u001b[2;32m│   \u001b[0mdifferentiable: \u001b[3;91mFalse\u001b[0m\n",
              "\u001b[2;32m│   \u001b[0meps: \u001b[1;36m1e-09\u001b[0m\n",
              "\u001b[2;32m│   \u001b[0mforeach: \u001b[3;35mNone\u001b[0m\n",
              "\u001b[2;32m│   \u001b[0mfused: \u001b[3;35mNone\u001b[0m\n",
              "\u001b[2;32m│   \u001b[0minitial_lr: \u001b[1;36m0.2\u001b[0m\n",
              "\u001b[2;32m│   \u001b[0mlr: \u001b[1;36m2.2961808030073203e-05\u001b[0m\n",
              "\u001b[2;32m│   \u001b[0mmaximize: \u001b[3;91mFalse\u001b[0m\n",
              "\u001b[2;32m│   \u001b[0mweight_decay: \u001b[1;36m0.0\u001b[0m\n",
              "\u001b[1m)\u001b[0m,\n",
              "\u001b[2;32m│   \u001b[0m\u001b[33mscheduler\u001b[0m=\u001b[1m<\u001b[0m\u001b[1;95mtorch.optim.lr_scheduler.LambdaLR\u001b[0m\u001b[39m object at \u001b[0m\u001b[1;36m0x1657a0730\u001b[0m\u001b[39m>,\u001b[0m\n",
              "\u001b[2;32m│   \u001b[0m\u001b[33mepoch_index\u001b[0m\u001b[39m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[39m,\u001b[0m\n",
              "\u001b[2;32m│   \u001b[0m\u001b[33mtrain_batch_index\u001b[0m\u001b[39m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[39m,\u001b[0m\n",
              "\u001b[2;32m│   \u001b[0m\u001b[33mstep_index\u001b[0m\u001b[39m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[39m,\u001b[0m\n",
              "\u001b[2;32m│   \u001b[0m\u001b[33mhistory\u001b[0m\u001b[39m=\u001b[0m\u001b[1;39m{\u001b[0m\u001b[1;39m}\u001b[0m\u001b[39m,\u001b[0m\n",
              "\u001b[2;32m│   \u001b[0m\u001b[33mvocabulary\u001b[0m\u001b[39m=<omnivault.transformer.core.vocabulary.AdderVocabulary object at \u001b[0m\u001b[1;36m0x1659237f0\u001b[0m\u001b[39m>,\u001b[0m\n",
              "\u001b[2;32m│   \u001b[0m\u001b[33mtokenizer\u001b[0m\u001b[39m=<omnivault.transformer.core.tokenizer.AdderTokenizer object at \u001b[0m\u001b[1;36m0x1659233d0\u001b[0m\u001b[1m>\u001b[0m\n",
              "\u001b[1m)\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from omnivault.transformer.core.state import State\n",
        "\n",
        "state = State(\n",
        "    model=model,\n",
        "    criterion=criterion,\n",
        "    optimizer=optimizer,\n",
        "    scheduler=scheduler,\n",
        "    vocabulary=vocabulary,\n",
        "    tokenizer=tokenizer,\n",
        ")\n",
        "state.pretty_print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">TrainerConfig</span><span style=\"font-weight: bold\">(</span>\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #808000; text-decoration-color: #808000\">device</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">device</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">type</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'cpu'</span><span style=\"font-weight: bold\">)</span>,\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #808000; text-decoration-color: #808000\">max_epochs</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>,\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #808000; text-decoration-color: #808000\">log_every_n_steps</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>,\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #808000; text-decoration-color: #808000\">eval_every_n_steps</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>,\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #808000; text-decoration-color: #808000\">step_scheduler_on_batch_or_epoch</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'epoch'</span>,\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #808000; text-decoration-color: #808000\">use_amp</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>,\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #808000; text-decoration-color: #808000\">autocast_config</span>=<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'enabled'</span>: <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'dtype'</span>: torch.bfloat16, <span style=\"color: #008000; text-decoration-color: #008000\">'cache_enabled'</span>: <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span><span style=\"font-weight: bold\">}</span>,\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #808000; text-decoration-color: #808000\">scaler_config</span>=<span style=\"font-weight: bold\">{</span>\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"color: #008000; text-decoration-color: #008000\">'enabled'</span>: <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>,\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"color: #008000; text-decoration-color: #008000\">'init_scale'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">65536.0</span>,\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"color: #008000; text-decoration-color: #008000\">'growth_factor'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2.0</span>,\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"color: #008000; text-decoration-color: #008000\">'backoff_factor'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.5</span>,\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"color: #008000; text-decoration-color: #008000\">'growth_interval'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2000</span>\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"font-weight: bold\">}</span>,\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #808000; text-decoration-color: #808000\">gradient_accumulation_steps</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>,\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #808000; text-decoration-color: #808000\">clip_grad_norm</span>=<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'max_norm'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.0</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'norm_type'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2.0</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'error_if_nonfinite'</span>: <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'foreach'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span><span style=\"font-weight: bold\">}</span>,\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #808000; text-decoration-color: #808000\">apply_weight_decay_to_different_param_groups</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>,\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #808000; text-decoration-color: #808000\">save_dir</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'checkpoints'</span>,\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #808000; text-decoration-color: #808000\">save_every_epoch</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>,\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #808000; text-decoration-color: #808000\">save_best_only</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #808000; text-decoration-color: #808000\">monitor</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'valid_this_epoch_average_loss'</span>,\n",
              "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #808000; text-decoration-color: #808000\">mode</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'min'</span>\n",
              "<span style=\"font-weight: bold\">)</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1;35mTrainerConfig\u001b[0m\u001b[1m(\u001b[0m\n",
              "\u001b[2;32m│   \u001b[0m\u001b[33mdevice\u001b[0m=\u001b[1;35mdevice\u001b[0m\u001b[1m(\u001b[0m\u001b[33mtype\u001b[0m=\u001b[32m'cpu'\u001b[0m\u001b[1m)\u001b[0m,\n",
              "\u001b[2;32m│   \u001b[0m\u001b[33mmax_epochs\u001b[0m=\u001b[1;36m2\u001b[0m,\n",
              "\u001b[2;32m│   \u001b[0m\u001b[33mlog_every_n_steps\u001b[0m=\u001b[1;36m1\u001b[0m,\n",
              "\u001b[2;32m│   \u001b[0m\u001b[33meval_every_n_steps\u001b[0m=\u001b[1;36m1\u001b[0m,\n",
              "\u001b[2;32m│   \u001b[0m\u001b[33mstep_scheduler_on_batch_or_epoch\u001b[0m=\u001b[32m'epoch'\u001b[0m,\n",
              "\u001b[2;32m│   \u001b[0m\u001b[33muse_amp\u001b[0m=\u001b[3;91mFalse\u001b[0m,\n",
              "\u001b[2;32m│   \u001b[0m\u001b[33mautocast_config\u001b[0m=\u001b[1m{\u001b[0m\u001b[32m'enabled'\u001b[0m: \u001b[3;91mFalse\u001b[0m, \u001b[32m'dtype'\u001b[0m: torch.bfloat16, \u001b[32m'cache_enabled'\u001b[0m: \u001b[3;92mTrue\u001b[0m\u001b[1m}\u001b[0m,\n",
              "\u001b[2;32m│   \u001b[0m\u001b[33mscaler_config\u001b[0m=\u001b[1m{\u001b[0m\n",
              "\u001b[2;32m│   │   \u001b[0m\u001b[32m'enabled'\u001b[0m: \u001b[3;91mFalse\u001b[0m,\n",
              "\u001b[2;32m│   │   \u001b[0m\u001b[32m'init_scale'\u001b[0m: \u001b[1;36m65536.0\u001b[0m,\n",
              "\u001b[2;32m│   │   \u001b[0m\u001b[32m'growth_factor'\u001b[0m: \u001b[1;36m2.0\u001b[0m,\n",
              "\u001b[2;32m│   │   \u001b[0m\u001b[32m'backoff_factor'\u001b[0m: \u001b[1;36m0.5\u001b[0m,\n",
              "\u001b[2;32m│   │   \u001b[0m\u001b[32m'growth_interval'\u001b[0m: \u001b[1;36m2000\u001b[0m\n",
              "\u001b[2;32m│   \u001b[0m\u001b[1m}\u001b[0m,\n",
              "\u001b[2;32m│   \u001b[0m\u001b[33mgradient_accumulation_steps\u001b[0m=\u001b[1;36m1\u001b[0m,\n",
              "\u001b[2;32m│   \u001b[0m\u001b[33mclip_grad_norm\u001b[0m=\u001b[1m{\u001b[0m\u001b[32m'max_norm'\u001b[0m: \u001b[1;36m1.0\u001b[0m, \u001b[32m'norm_type'\u001b[0m: \u001b[1;36m2.0\u001b[0m, \u001b[32m'error_if_nonfinite'\u001b[0m: \u001b[3;91mFalse\u001b[0m, \u001b[32m'foreach'\u001b[0m: \u001b[3;35mNone\u001b[0m\u001b[1m}\u001b[0m,\n",
              "\u001b[2;32m│   \u001b[0m\u001b[33mapply_weight_decay_to_different_param_groups\u001b[0m=\u001b[3;91mFalse\u001b[0m,\n",
              "\u001b[2;32m│   \u001b[0m\u001b[33msave_dir\u001b[0m=\u001b[32m'checkpoints'\u001b[0m,\n",
              "\u001b[2;32m│   \u001b[0m\u001b[33msave_every_epoch\u001b[0m=\u001b[3;91mFalse\u001b[0m,\n",
              "\u001b[2;32m│   \u001b[0m\u001b[33msave_best_only\u001b[0m=\u001b[3;92mTrue\u001b[0m,\n",
              "\u001b[2;32m│   \u001b[0m\u001b[33mmonitor\u001b[0m=\u001b[32m'valid_this_epoch_average_loss'\u001b[0m,\n",
              "\u001b[2;32m│   \u001b[0m\u001b[33mmode\u001b[0m=\u001b[32m'min'\u001b[0m\n",
              "\u001b[1m)\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "pprint(composer.trainer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "talk about state fromr eadme"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "│   │   use_amp=False,\n",
        "│   │   autocast_config={'enabled': False},\n",
        "│   │   scaler_config={'enabled': False, 'init_scale': 65536.0, 'growth_factor': 2.0, 'backoff_factor': 0.5, 'growth_interval': 2000},"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {},
      "outputs": [],
      "source": [
        "# pprint(composer)\n",
        "\n",
        "composer.trainer.use_amp=False\n",
        "composer.trainer.autocast_config = {'enabled': False, 'dtype': torch.bfloat16, 'cache_enabled': True}\n",
        "composer.trainer.scaler_config[\"enabled\"]=False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 154,
      "metadata": {},
      "outputs": [],
      "source": [
        "from omnivault.transformer.core.trainer import Trainer, TrainerEvent\n",
        "from omnivault.transformer.core.callbacks import save_state\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 155,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/gaohn/miniconda3/envs/omniverse/lib/python3.9/site-packages/torch/amp/autocast_mode.py:266: UserWarning: In CPU autocast, but the target dtype is not supported. Disabling autocast.\n",
            "CPU Autocast only supports dtype of torch.bfloat16 currently.\n",
            "  warnings.warn(error_message)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[2024-03-21 23:01:22] </span><span style=\"color: #008000; text-decoration-color: #008000\">INFO    </span> Initial learning rate: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0019174124721184262</span>                         <a href=\"file:///Users/gaohn/omniverse/omniverse/omnivault/transformer/core/callbacks.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">callbacks.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/gaohn/omniverse/omniverse/omnivault/transformer/core/callbacks.py#63\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">63</span></a>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[2;36m[2024-03-21 23:01:22]\u001b[0m\u001b[2;36m \u001b[0m\u001b[32mINFO    \u001b[0m Initial learning rate: \u001b[1;36m0.0019174124721184262\u001b[0m                         \u001b]8;id=844962;file:///Users/gaohn/omniverse/omniverse/omnivault/transformer/core/callbacks.py\u001b\\\u001b[2mcallbacks.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=167414;file:///Users/gaohn/omniverse/omniverse/omnivault/transformer/core/callbacks.py#63\u001b\\\u001b[2m63\u001b[0m\u001b]8;;\u001b\\\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[2024-03-21 23:01:22] </span><span style=\"color: #008000; text-decoration-color: #008000\">INFO    </span> Initial learning rate: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0019174124721184262</span>                         <a href=\"file:///Users/gaohn/omniverse/omniverse/omnivault/transformer/core/callbacks.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">callbacks.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/gaohn/omniverse/omniverse/omnivault/transformer/core/callbacks.py#63\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">63</span></a>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[2;36m[2024-03-21 23:01:22]\u001b[0m\u001b[2;36m \u001b[0m\u001b[32mINFO    \u001b[0m Initial learning rate: \u001b[1;36m0.0019174124721184262\u001b[0m                         \u001b]8;id=163032;file:///Users/gaohn/omniverse/omniverse/omnivault/transformer/core/callbacks.py\u001b\\\u001b[2mcallbacks.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=225772;file:///Users/gaohn/omniverse/omniverse/omnivault/transformer/core/callbacks.py#63\u001b\\\u001b[2m63\u001b[0m\u001b]8;;\u001b\\\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[2024-03-21 23:01:22] </span><span style=\"color: #008000; text-decoration-color: #008000\">INFO    </span> Initial learning rate: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0019174124721184262</span>                         <a href=\"file:///Users/gaohn/omniverse/omniverse/omnivault/transformer/core/callbacks.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">callbacks.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/gaohn/omniverse/omniverse/omnivault/transformer/core/callbacks.py#63\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">63</span></a>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[2;36m[2024-03-21 23:01:22]\u001b[0m\u001b[2;36m \u001b[0m\u001b[32mINFO    \u001b[0m Initial learning rate: \u001b[1;36m0.0019174124721184262\u001b[0m                         \u001b]8;id=398382;file:///Users/gaohn/omniverse/omniverse/omnivault/transformer/core/callbacks.py\u001b\\\u001b[2mcallbacks.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=101414;file:///Users/gaohn/omniverse/omniverse/omnivault/transformer/core/callbacks.py#63\u001b\\\u001b[2m63\u001b[0m\u001b]8;;\u001b\\\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                      </span><span style=\"color: #008000; text-decoration-color: #008000\">INFO    </span> Total Parameters: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">270226</span>, Trainable Parameters: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">270226</span>              <a href=\"file:///Users/gaohn/omniverse/omniverse/omnivault/transformer/core/callbacks.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">callbacks.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/gaohn/omniverse/omniverse/omnivault/transformer/core/callbacks.py#120\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">120</span></a>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[2;36m                     \u001b[0m\u001b[2;36m \u001b[0m\u001b[32mINFO    \u001b[0m Total Parameters: \u001b[1;36m270226\u001b[0m, Trainable Parameters: \u001b[1;36m270226\u001b[0m              \u001b]8;id=277370;file:///Users/gaohn/omniverse/omniverse/omnivault/transformer/core/callbacks.py\u001b\\\u001b[2mcallbacks.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=846335;file:///Users/gaohn/omniverse/omniverse/omnivault/transformer/core/callbacks.py#120\u001b\\\u001b[2m120\u001b[0m\u001b]8;;\u001b\\\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                      </span><span style=\"color: #008000; text-decoration-color: #008000\">INFO    </span> Total Parameters: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">270226</span>, Trainable Parameters: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">270226</span>              <a href=\"file:///Users/gaohn/omniverse/omniverse/omnivault/transformer/core/callbacks.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">callbacks.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/gaohn/omniverse/omniverse/omnivault/transformer/core/callbacks.py#120\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">120</span></a>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[2;36m                     \u001b[0m\u001b[2;36m \u001b[0m\u001b[32mINFO    \u001b[0m Total Parameters: \u001b[1;36m270226\u001b[0m, Trainable Parameters: \u001b[1;36m270226\u001b[0m              \u001b]8;id=130889;file:///Users/gaohn/omniverse/omniverse/omnivault/transformer/core/callbacks.py\u001b\\\u001b[2mcallbacks.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=967096;file:///Users/gaohn/omniverse/omniverse/omnivault/transformer/core/callbacks.py#120\u001b\\\u001b[2m120\u001b[0m\u001b]8;;\u001b\\\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                      </span><span style=\"color: #008000; text-decoration-color: #008000\">INFO    </span> Total Parameters: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">270226</span>, Trainable Parameters: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">270226</span>              <a href=\"file:///Users/gaohn/omniverse/omniverse/omnivault/transformer/core/callbacks.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">callbacks.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/gaohn/omniverse/omniverse/omnivault/transformer/core/callbacks.py#120\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">120</span></a>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[2;36m                     \u001b[0m\u001b[2;36m \u001b[0m\u001b[32mINFO    \u001b[0m Total Parameters: \u001b[1;36m270226\u001b[0m, Trainable Parameters: \u001b[1;36m270226\u001b[0m              \u001b]8;id=869693;file:///Users/gaohn/omniverse/omniverse/omnivault/transformer/core/callbacks.py\u001b\\\u001b[2mcallbacks.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=659176;file:///Users/gaohn/omniverse/omniverse/omnivault/transformer/core/callbacks.py#120\u001b\\\u001b[2m120\u001b[0m\u001b]8;;\u001b\\\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                      </span><span style=\"color: #008000; text-decoration-color: #008000\">INFO    </span> ====================================================== Starting      <a href=\"file:///Users/gaohn/omniverse/omniverse/omnivault/transformer/core/callbacks.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">callbacks.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/gaohn/omniverse/omniverse/omnivault/transformer/core/callbacks.py#68\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">68</span></a>\n",
              "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                      </span>         Train Epoch: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>                                                     <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
              "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                      </span>         ======================================================               <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[2;36m                     \u001b[0m\u001b[2;36m \u001b[0m\u001b[32mINFO    \u001b[0m ====================================================== Starting      \u001b]8;id=605397;file:///Users/gaohn/omniverse/omniverse/omnivault/transformer/core/callbacks.py\u001b\\\u001b[2mcallbacks.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=201629;file:///Users/gaohn/omniverse/omniverse/omnivault/transformer/core/callbacks.py#68\u001b\\\u001b[2m68\u001b[0m\u001b]8;;\u001b\\\n",
              "\u001b[2;36m                      \u001b[0m         Train Epoch: \u001b[1;36m1\u001b[0m/\u001b[1;36m2\u001b[0m                                                     \u001b[2m               \u001b[0m\n",
              "\u001b[2;36m                      \u001b[0m         ======================================================               \u001b[2m               \u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                      </span><span style=\"color: #008000; text-decoration-color: #008000\">INFO    </span> ====================================================== Starting      <a href=\"file:///Users/gaohn/omniverse/omniverse/omnivault/transformer/core/callbacks.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">callbacks.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/gaohn/omniverse/omniverse/omnivault/transformer/core/callbacks.py#68\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">68</span></a>\n",
              "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                      </span>         Train Epoch: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>                                                     <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
              "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                      </span>         ======================================================               <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[2;36m                     \u001b[0m\u001b[2;36m \u001b[0m\u001b[32mINFO    \u001b[0m ====================================================== Starting      \u001b]8;id=238968;file:///Users/gaohn/omniverse/omniverse/omnivault/transformer/core/callbacks.py\u001b\\\u001b[2mcallbacks.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=810620;file:///Users/gaohn/omniverse/omniverse/omnivault/transformer/core/callbacks.py#68\u001b\\\u001b[2m68\u001b[0m\u001b]8;;\u001b\\\n",
              "\u001b[2;36m                      \u001b[0m         Train Epoch: \u001b[1;36m1\u001b[0m/\u001b[1;36m2\u001b[0m                                                     \u001b[2m               \u001b[0m\n",
              "\u001b[2;36m                      \u001b[0m         ======================================================               \u001b[2m               \u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                      </span><span style=\"color: #008000; text-decoration-color: #008000\">INFO    </span> ====================================================== Starting      <a href=\"file:///Users/gaohn/omniverse/omniverse/omnivault/transformer/core/callbacks.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">callbacks.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///Users/gaohn/omniverse/omniverse/omnivault/transformer/core/callbacks.py#68\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">68</span></a>\n",
              "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                      </span>         Train Epoch: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>/<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>                                                     <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
              "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                      </span>         ======================================================               <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[2;36m                     \u001b[0m\u001b[2;36m \u001b[0m\u001b[32mINFO    \u001b[0m ====================================================== Starting      \u001b]8;id=908573;file:///Users/gaohn/omniverse/omniverse/omnivault/transformer/core/callbacks.py\u001b\\\u001b[2mcallbacks.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=105907;file:///Users/gaohn/omniverse/omniverse/omnivault/transformer/core/callbacks.py#68\u001b\\\u001b[2m68\u001b[0m\u001b]8;;\u001b\\\n",
              "\u001b[2;36m                      \u001b[0m         Train Epoch: \u001b[1;36m1\u001b[0m/\u001b[1;36m2\u001b[0m                                                     \u001b[2m               \u001b[0m\n",
              "\u001b[2;36m                      \u001b[0m         ======================================================               \u001b[2m               \u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                      \r"
          ]
        },
        {
          "ename": "RuntimeError",
          "evalue": "Currently, AutocastCPU only support Bfloat16 as the autocast_cpu_dtype",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[155], line 12\u001b[0m\n\u001b[1;32m      7\u001b[0m trainer\u001b[38;5;241m.\u001b[39mremove_callback(event\u001b[38;5;241m=\u001b[39mTrainerEvent\u001b[38;5;241m.\u001b[39mON_VALID_EPOCH_END\u001b[38;5;241m.\u001b[39mvalue, callback\u001b[38;5;241m=\u001b[39msave_state)\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# trainer.add_callback(\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m#     TrainerEvent.ON_VALID_EPOCH_END.value,\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m#     lambda trainer: evaluate_and_generate_on_valid_epoch_end(trainer, num_batches_to_eval=None),\u001b[39;00m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# )\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m _trained_state \u001b[38;5;241m=\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalid_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalid_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_loader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m _trained_state\u001b[38;5;241m.\u001b[39mpretty_print()\n\u001b[1;32m     14\u001b[0m history \u001b[38;5;241m=\u001b[39m _trained_state\u001b[38;5;241m.\u001b[39mhistory\n",
            "File \u001b[0;32m~/omniverse/omniverse/omnivault/transformer/core/trainer.py:455\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[0;34m(self, train_loader, valid_loader, test_loader)\u001b[0m\n\u001b[1;32m    453\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_epochs \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m    454\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mepoch_index \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m--> 455\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_one_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataloader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_loader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    457\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m valid_loader:\n\u001b[1;32m    458\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalid_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalid_one_epoch(dataloader\u001b[38;5;241m=\u001b[39mvalid_loader)\n",
            "File \u001b[0;32m~/omniverse/omniverse/omnivault/transformer/core/trainer.py:317\u001b[0m, in \u001b[0;36mTrainer.train_one_epoch\u001b[0;34m(self, dataloader)\u001b[0m\n\u001b[1;32m    314\u001b[0m batch_size \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    315\u001b[0m total_samples \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m batch_size\n\u001b[0;32m--> 317\u001b[0m this_batch_average_loss, this_batch_total_loss, this_batch_average_perplexity \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_train_one_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    318\u001b[0m this_epoch_total_running_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m this_batch_total_loss\n\u001b[1;32m    320\u001b[0m progress_bar\u001b[38;5;241m.\u001b[39mset_description(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mepoch_index\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Step: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m_batch_index\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
            "File \u001b[0;32m~/omniverse/omniverse/omnivault/transformer/core/trainer.py:222\u001b[0m, in \u001b[0;36mTrainer._train_one_batch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    219\u001b[0m inputs, targets, target_padding_masks, future_masks \u001b[38;5;241m=\u001b[39m move_to_device(batch, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m    220\u001b[0m batch_size \u001b[38;5;241m=\u001b[39m inputs\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m--> 222\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontext_manager:  \u001b[38;5;66;03m# no ops if not enabled\u001b[39;00m\n\u001b[1;32m    223\u001b[0m     logits: torch\u001b[38;5;241m.\u001b[39mFloatTensor \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel(\n\u001b[1;32m    224\u001b[0m         inputs, target_padding_masks\u001b[38;5;241m=\u001b[39mtarget_padding_masks, future_masks\u001b[38;5;241m=\u001b[39mfuture_masks\n\u001b[1;32m    225\u001b[0m     )\n\u001b[1;32m    226\u001b[0m     loss: torch\u001b[38;5;241m.\u001b[39mTensor \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcriterion(logits\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mcontiguous(), targets\u001b[38;5;241m.\u001b[39mcontiguous())\n",
            "File \u001b[0;32m~/miniconda3/envs/omniverse/lib/python3.9/site-packages/torch/amp/autocast_mode.py:329\u001b[0m, in \u001b[0;36mautocast.__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    327\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprev_fastdtype \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mget_autocast_cpu_dtype()\n\u001b[1;32m    328\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_autocast_cpu_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_enabled)\n\u001b[0;32m--> 329\u001b[0m     \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_autocast_cpu_dtype\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfast_dtype\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m    330\u001b[0m     torch\u001b[38;5;241m.\u001b[39mautocast_increment_nesting()\n\u001b[1;32m    331\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxpu\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Currently, AutocastCPU only support Bfloat16 as the autocast_cpu_dtype"
          ]
        }
      ],
      "source": [
        "trainer = Trainer(\n",
        "    state=state,\n",
        "    composer=composer,\n",
        "    logger=LOGGER,\n",
        "    device=composer.trainer.device,  # type: ignore[arg-type]\n",
        ")\n",
        "trainer.remove_callback(event=TrainerEvent.ON_VALID_EPOCH_END.value, callback=save_state)\n",
        "# trainer.add_callback(\n",
        "#     TrainerEvent.ON_VALID_EPOCH_END.value,\n",
        "#     lambda trainer: evaluate_and_generate_on_valid_epoch_end(trainer, num_batches_to_eval=None),\n",
        "# )\n",
        "_trained_state = trainer.fit(train_loader=train_loader, valid_loader=valid_loader, test_loader=test_loader)\n",
        "_trained_state.pretty_print()\n",
        "history = _trained_state.history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "id": "M5TwyxE5rdzd",
        "outputId": "3310e8c6-328e-41e5-acc8-7a4b63ed5845"
      },
      "outputs": [
        {
          "ename": "TypeError",
          "evalue": "__init__() got an unexpected keyword argument 'model'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[91], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m trainer \u001b[38;5;241m=\u001b[39m \u001b[43mTrainer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dataloader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscheduler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_norm_clip\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1.0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcomposer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalid_dataloader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalid_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# test_dataloader=test_loader,\u001b[39;49;00m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# NOTE: uncomment the above line to enable testing after each epoch\u001b[39;49;00m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# but seeding will affect.\u001b[39;49;00m\n\u001b[1;32m     13\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m DEBUG:\n\u001b[1;32m     16\u001b[0m     trained_model \u001b[38;5;241m=\u001b[39m trainer\u001b[38;5;241m.\u001b[39mfit(max_epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m) \u001b[38;5;66;03m# or 15\u001b[39;00m\n",
            "\u001b[0;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'model'"
          ]
        }
      ],
      "source": [
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    train_dataloader=train_loader,\n",
        "    criterion=criterion,\n",
        "    optimizer=optimizer,\n",
        "    scheduler=scheduler,\n",
        "    grad_norm_clip=1.0,\n",
        "    device=composer.trainer.device,\n",
        "    valid_dataloader=valid_loader,\n",
        "    # test_dataloader=test_loader,\n",
        "    # NOTE: uncomment the above line to enable testing after each epoch\n",
        "    # but seeding will affect.\n",
        ")\n",
        "\n",
        "if DEBUG:\n",
        "    trained_model = trainer.fit(max_epochs=2) # or 15\n",
        "    # torch.save(model.state_dict(), 'model_debug.pt')\n",
        "    # model_debug = torch.load('./model_debug.pt')\n",
        "    # if are_both_models_same(model.state_dict(), model_debug):\n",
        "    #     print(\"Pass\")\n",
        "    # else:\n",
        "    #     print(\"Fail\")\n",
        "\n",
        "else:\n",
        "    trained_model = trainer.fit(max_epochs=30)\n",
        "\n",
        "    # torch.save(model.state_dict(), 'model_non_debug.pt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "```\n",
        "Epoch 1/2\n",
        "----------\n",
        "100%|██████████| 28/28 [00:04<00:00,  5.60it/s]\n",
        "Average Epoch Training Loss   : 2.41188\n",
        "100%|██████████| 8/8 [00:00<00:00, 20.18it/s]\n",
        "Average Epoch Validation Loss : 1.66422\n",
        "Epoch 2/2\n",
        "----------\n",
        "100%|██████████| 28/28 [00:03<00:00,  9.07it/s]\n",
        "Average Epoch Training Loss   : 1.36899\n",
        "100%|██████████| 8/8 [00:00<00:00, 20.31it/s]\n",
        "Average Epoch Validation Loss : 1.16084\n",
        "Training complete\n",
        "```\n",
        "\n",
        "```\n",
        "Epoch 1/2\n",
        "----------\n",
        "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:03<00:00,  8.95it/s]\n",
        "Average Epoch Training Loss   : 2.40482\n",
        "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 15.67it/s]\n",
        "Average Epoch Validation Loss : 1.72585\n",
        "Epoch 2/2\n",
        "----------\n",
        "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 28/28 [00:02<00:00, 12.24it/s]\n",
        "Average Epoch Training Loss   : 1.37748\n",
        "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:00<00:00, 29.34it/s]\n",
        "Average Epoch Validation Loss : 1.15630\n",
        "Training complete\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "trained_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "batch = next(iter(train_loader))\n",
        "pprint(batch)\n",
        "\n",
        "inputs, targets, target_padding_masks, future_masks = batch\n",
        "\n",
        "\n",
        "# Step 2: Pass the sample through the model\n",
        "trained_model.eval()  # Set the model to evaluation mode\n",
        "\n",
        "with torch.no_grad():\n",
        "    # Assuming your model and sample require specific formatting, adjust as necessary\n",
        "    logits = model(inputs, target_padding_masks=target_padding_masks, future_masks=future_masks)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "last_decoder_block = trained_model.decoder_blocks[-1] # take last decoder block? more feature?\n",
        "# pprint(last_decoder_block)\n",
        "\n",
        "masked_self_attention_mha = last_decoder_block.masked_self_attention_mha\n",
        "pprint(masked_self_attention_mha)\n",
        "\n",
        "context_vector, attention_weights = masked_self_attention_mha.context_vector, masked_self_attention_mha.attention_weights\n",
        "pprint(attention_weights.shape)\n",
        "# but has H=4 heads so do we take 1 head and check the heatmap?\n",
        "# torch.Size([208, 4, 10, 10])\n",
        "\n",
        "last_batch_last_sample_first_head_attention_weights = attention_weights[-1, 0:1, :, :].squeeze(0)\n",
        "pprint(last_batch_last_sample_first_head_attention_weights.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "the xy axis is keys and queries, which is correct `Q @ K.T`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Your existing setup\n",
        "last_decoder_block = trained_model.decoder_blocks[-1]\n",
        "masked_self_attention_mha = last_decoder_block.masked_self_attention_mha\n",
        "context_vector, attention_weights = masked_self_attention_mha.context_vector, masked_self_attention_mha.attention_weights\n",
        "\n",
        "# Number of heads\n",
        "num_heads = attention_weights.size(1)\n",
        "\n",
        "# Labels for each character in the sequence, including BOS\n",
        "labels = ['<BOS>'] + list('59+14=073')\n",
        "\n",
        "# Loop over each head and plot its heatmap\n",
        "for head in range(num_heads):\n",
        "    plt.figure(figsize=(10, 10))\n",
        "\n",
        "    # Extract attention weights for the last sample in the last batch for this head\n",
        "    attention_matrix = attention_weights[-1, head, :, :].detach().numpy()\n",
        "\n",
        "    sns.heatmap(attention_matrix, annot=True, cmap='viridis', xticklabels=labels, yticklabels=labels)\n",
        "    plt.title(f\"Attention Weights Heatmap for '<BOS>59+14=073' - Head {head+1}\")\n",
        "    plt.xlabel(\"Keys\")\n",
        "    plt.ylabel(\"Queries\")\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XT_Nf9O4rdzd"
      },
      "source": [
        "## DEBUG\n",
        "\n",
        "### W\n",
        "\n",
        "\n",
        "```\n",
        "Epoch 1/2\n",
        "----------\n",
        "100%|██████████| 28/28 [00:04<00:00,  5.91it/s]\n",
        "100%|██████████| 8/8 [00:00<00:00, 14.21it/s]\n",
        "Training Loss   : 2.08882\n",
        "Validation Loss : 1.27368\n",
        "Epoch 2/2\n",
        "----------\n",
        "  7%|▋         | 2/28 [00:00<00:04,  5.68it/s]\n",
        "100%|██████████| 28/28 [00:04<00:00,  6.42it/s]\n",
        "100%|██████████| 8/8 [00:00<00:00, 21.24it/s]\n",
        "Training Loss   : 1.23194\n",
        "Validation Loss : 1.10291\n",
        "Training complete\n",
        "```\n",
        "\n",
        "CHANGED EOS and BOS SWAP POSITION\n",
        "\n",
        "```\n",
        "Epoch 1/2\n",
        "----------\n",
        " 32%|███▏      | 9/28 [00:01<00:02,  6.90it/s]\n",
        "100%|██████████| 28/28 [00:03<00:00,  8.22it/s]\n",
        "100%|██████████| 8/8 [00:00<00:00, 26.60it/s]\n",
        "Training Loss   : 2.10450\n",
        "Validation Loss : 1.28284\n",
        "Epoch 2/2\n",
        "----------\n",
        "100%|██████████| 28/28 [00:02<00:00,  9.82it/s]\n",
        "100%|██████████| 8/8 [00:00<00:00, 25.31it/s]\n",
        "Training Loss   : 1.23119\n",
        "Validation Loss : 1.09374\n",
        "```\n",
        "\n",
        "### M \n",
        "\n",
        "```\n",
        "Epoch 1/2\n",
        "----------\n",
        "100%|██████████| 28/28 [00:02<00:00, 13.63it/s]\n",
        "100%|██████████| 8/8 [00:00<00:00, 34.32it/s]\n",
        "Training Loss   : 2.08863\n",
        "Validation Loss : 1.26961\n",
        "Epoch 2/2\n",
        "----------\n",
        "100%|██████████| 28/28 [00:01<00:00, 14.40it/s]\n",
        "100%|██████████| 8/8 [00:00<00:00, 44.49it/s]\n",
        "Training Loss   : 1.23620\n",
        "Validation Loss : 1.11484\n",
        "Training complete\n",
        "\n",
        "---\n",
        "\n",
        "Epoch 29/30\n",
        "----------\n",
        "100%|██████████| 28/28 [00:01<00:00, 15.37it/s]\n",
        "100%|██████████| 8/8 [00:00<00:00, 41.86it/s]\n",
        "Training Loss   : 0.01514\n",
        "Validation Loss : 0.00067\n",
        "Epoch 30/30\n",
        "----------\n",
        "100%|██████████| 28/28 [00:01<00:00, 15.38it/s]\n",
        "100%|██████████| 8/8 [00:00<00:00, 42.62it/s]\n",
        "Training Loss   : 0.01448\n",
        "Validation Loss : 0.00057\n",
        "Training complete\n",
        "```\n",
        "\n",
        "```\n",
        "Epoch 1/30\n",
        "----------\n",
        "100%|██████████| 28/28 [00:02<00:00, 12.22it/s]\n",
        "100%|██████████| 8/8 [00:00<00:00, 29.15it/s]\n",
        "Training Loss   : 2.10712\n",
        "Validation Loss : 1.27872\n",
        "Epoch 2/30\n",
        "----------\n",
        "100%|██████████| 28/28 [00:02<00:00, 12.78it/s]\n",
        "100%|██████████| 8/8 [00:00<00:00, 29.36it/s]\n",
        "Training Loss   : 1.23133\n",
        "Validation Loss : 1.09508\n",
        "Epoch 3/30\n",
        "----------\n",
        "100%|██████████| 28/28 [00:02<00:00, 12.91it/s]\n",
        "100%|██████████| 8/8 [00:00<00:00, 29.92it/s]\n",
        "Training Loss   : 1.03519\n",
        "Validation Loss : 0.87629\n",
        "Epoch 4/30\n",
        "----------\n",
        "100%|██████████| 28/28 [00:02<00:00, 13.41it/s]\n",
        "100%|██████████| 8/8 [00:00<00:00, 28.30it/s]\n",
        "Training Loss   : 0.87725\n",
        "Validation Loss : 0.78361\n",
        "Epoch 5/30\n",
        "----------\n",
        "100%|██████████| 28/28 [00:02<00:00, 12.86it/s]\n",
        "100%|██████████| 8/8 [00:00<00:00, 30.18it/s]\n",
        "Training Loss   : 0.79957\n",
        "Validation Loss : 0.73302\n",
        "Epoch 6/30\n",
        "----------\n",
        "100%|██████████| 28/28 [00:02<00:00, 13.35it/s]\n",
        "100%|██████████| 8/8 [00:00<00:00, 28.31it/s]\n",
        "Training Loss   : 0.76029\n",
        "Validation Loss : 0.69880\n",
        "Epoch 7/30\n",
        "----------\n",
        "100%|██████████| 28/28 [00:02<00:00, 13.45it/s]\n",
        "100%|██████████| 8/8 [00:00<00:00, 30.39it/s]\n",
        "Training Loss   : 0.72721\n",
        "Validation Loss : 0.68126\n",
        "Epoch 8/30\n",
        "----------\n",
        "100%|██████████| 28/28 [00:02<00:00, 13.53it/s]\n",
        "100%|██████████| 8/8 [00:00<00:00, 27.81it/s]\n",
        "Training Loss   : 0.70416\n",
        "Validation Loss : 0.63668\n",
        "Epoch 9/30\n",
        "----------\n",
        "100%|██████████| 28/28 [00:02<00:00, 13.25it/s]\n",
        "100%|██████████| 8/8 [00:00<00:00, 29.87it/s]\n",
        "Training Loss   : 0.64809\n",
        "Validation Loss : 0.48974\n",
        "Epoch 10/30\n",
        "----------\n",
        "100%|██████████| 28/28 [00:02<00:00, 12.47it/s]\n",
        "100%|██████████| 8/8 [00:00<00:00, 22.07it/s]\n",
        "Training Loss   : 0.39999\n",
        "Validation Loss : 0.16127\n",
        "Epoch 11/30\n",
        "----------\n",
        "100%|██████████| 28/28 [00:02<00:00, 12.28it/s]\n",
        "100%|██████████| 8/8 [00:00<00:00, 29.57it/s]\n",
        "Training Loss   : 0.20621\n",
        "Validation Loss : 0.08199\n",
        "Epoch 12/30\n",
        "----------\n",
        "100%|██████████| 28/28 [00:02<00:00, 12.71it/s]\n",
        "100%|██████████| 8/8 [00:00<00:00, 15.80it/s]\n",
        "Training Loss   : 0.13922\n",
        "Validation Loss : 0.05043\n",
        "Epoch 13/30\n",
        "----------\n",
        "100%|██████████| 28/28 [00:02<00:00, 12.76it/s]\n",
        "100%|██████████| 8/8 [00:00<00:00, 29.94it/s]\n",
        "Training Loss   : 0.11169\n",
        "Validation Loss : 0.03682\n",
        "Epoch 14/30\n",
        "----------\n",
        "100%|██████████| 28/28 [00:02<00:00, 13.03it/s]\n",
        "100%|██████████| 8/8 [00:00<00:00, 30.37it/s]\n",
        "Training Loss   : 0.08848\n",
        "Validation Loss : 0.02700\n",
        "Epoch 15/30\n",
        "----------\n",
        "100%|██████████| 28/28 [00:02<00:00, 13.33it/s]\n",
        "100%|██████████| 8/8 [00:00<00:00, 30.22it/s]\n",
        "Training Loss   : 0.07917\n",
        "Validation Loss : 0.02183\n",
        "Epoch 16/30\n",
        "----------\n",
        "100%|██████████| 28/28 [00:02<00:00, 13.20it/s]\n",
        "100%|██████████| 8/8 [00:00<00:00, 27.96it/s]\n",
        "Training Loss   : 0.06974\n",
        "Validation Loss : 0.01599\n",
        "Epoch 17/30\n",
        "----------\n",
        "100%|██████████| 28/28 [00:02<00:00, 11.07it/s]\n",
        "100%|██████████| 8/8 [00:00<00:00, 30.04it/s]\n",
        "Training Loss   : 0.05679\n",
        "Validation Loss : 0.01285\n",
        "Epoch 18/30\n",
        "----------\n",
        "100%|██████████| 28/28 [00:02<00:00, 11.82it/s]\n",
        "100%|██████████| 8/8 [00:00<00:00, 18.65it/s]\n",
        "Training Loss   : 0.04896\n",
        "Validation Loss : 0.00878\n",
        "Epoch 19/30\n",
        "----------\n",
        "100%|██████████| 28/28 [00:03<00:00,  9.00it/s]\n",
        "100%|██████████| 8/8 [00:00<00:00, 26.38it/s]\n",
        "Training Loss   : 0.04387\n",
        "Validation Loss : 0.00921\n",
        "Epoch 20/30\n",
        "----------\n",
        "100%|██████████| 28/28 [00:02<00:00,  9.98it/s]\n",
        "100%|██████████| 8/8 [00:00<00:00, 28.77it/s]\n",
        "Training Loss   : 0.04160\n",
        "Validation Loss : 0.00447\n",
        "Epoch 21/30\n",
        "----------\n",
        "100%|██████████| 28/28 [00:02<00:00, 12.33it/s]\n",
        "100%|██████████| 8/8 [00:00<00:00, 28.80it/s]\n",
        "Training Loss   : 0.03468\n",
        "Validation Loss : 0.00423\n",
        "Epoch 22/30\n",
        "----------\n",
        "100%|██████████| 28/28 [00:02<00:00, 12.97it/s]\n",
        "100%|██████████| 8/8 [00:00<00:00, 29.11it/s]\n",
        "Training Loss   : 0.03085\n",
        "Validation Loss : 0.00279\n",
        "Epoch 23/30\n",
        "----------\n",
        "100%|██████████| 28/28 [00:02<00:00, 12.41it/s]\n",
        "100%|██████████| 8/8 [00:00<00:00, 27.02it/s]\n",
        "Training Loss   : 0.02741\n",
        "Validation Loss : 0.00197\n",
        "Epoch 24/30\n",
        "----------\n",
        "100%|██████████| 28/28 [00:02<00:00, 13.09it/s]\n",
        "100%|██████████| 8/8 [00:00<00:00, 29.83it/s]\n",
        "Training Loss   : 0.02015\n",
        "Validation Loss : 0.00132\n",
        "Epoch 25/30\n",
        "----------\n",
        "100%|██████████| 28/28 [00:02<00:00, 13.08it/s]\n",
        "100%|██████████| 8/8 [00:00<00:00, 29.30it/s]\n",
        "Training Loss   : 0.01844\n",
        "Validation Loss : 0.00229\n",
        "Epoch 26/30\n",
        "----------\n",
        "100%|██████████| 28/28 [00:02<00:00, 13.23it/s]\n",
        "100%|██████████| 8/8 [00:00<00:00, 29.35it/s]\n",
        "Training Loss   : 0.01913\n",
        "Validation Loss : 0.00103\n",
        "Epoch 27/30\n",
        "----------\n",
        "100%|██████████| 28/28 [00:02<00:00, 12.50it/s]\n",
        "100%|██████████| 8/8 [00:00<00:00, 27.89it/s]\n",
        "Training Loss   : 0.01545\n",
        "Validation Loss : 0.00076\n",
        "Epoch 28/30\n",
        "----------\n",
        "100%|██████████| 28/28 [00:02<00:00, 12.30it/s]\n",
        "100%|██████████| 8/8 [00:00<00:00, 26.09it/s]\n",
        "Training Loss   : 0.01616\n",
        "Validation Loss : 0.00104\n",
        "Epoch 29/30\n",
        "----------\n",
        "100%|██████████| 28/28 [00:02<00:00, 12.28it/s]\n",
        "100%|██████████| 8/8 [00:00<00:00, 25.84it/s]\n",
        "Training Loss   : 0.01504\n",
        "Validation Loss : 0.00092\n",
        "Epoch 30/30\n",
        "----------\n",
        "100%|██████████| 28/28 [00:02<00:00, 12.59it/s]\n",
        "100%|██████████| 8/8 [00:00<00:00, 25.87it/s]\n",
        "Training Loss   : 0.01006\n",
        "Validation Loss : 0.00047\n",
        "Training complete\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hDQqBukYrdze",
        "outputId": "89e6a5ed-c5f1-4b53-fac1-6528f8157c67"
      },
      "outputs": [],
      "source": [
        "break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "```\n",
        "x -> tensor([[15,  9,  8, 10,  3,  5, 13]])\n",
        "future_mask -> 7x7\n",
        "tensor([[ True, False, False, False, False, False, False],\n",
        "│   │   [ True,  True, False, False, False, False, False],\n",
        "│   │   [ True,  True,  True, False, False, False, False],\n",
        "│   │   [ True,  True,  True,  True, False, False, False],\n",
        "│   │   [ True,  True,  True,  True,  True, False, False],\n",
        "│   │   [ True,  True,  True,  True,  True,  True, False],\n",
        "│   │   [ True,  True,  True,  True,  True,  True,  True]])\n",
        "\n",
        "logits--> 1x7x18 because 1 sample\n",
        "tensor([[[  7.8,  -0.2,  -2.3,  -1.1,  -0.1,  -3.2,  -4.4,\n",
        "          -2.4,   3.7,  -0.9,  -5.1,  -4.5,  -5.6,  -2.2,\n",
        "          -0.5,  -4.2,  -2.9,  -4.9],\n",
        "        [  0.3,   3.7,   0.9,   1.7,   0.4,  -4.0,  -6.0,\n",
        "          -2.3,   8.5,   7.3,  -6.0,  -5.1,  -6.2,  -3.0,\n",
        "         -10.9,  -3.8,  -5.3,  -5.9],\n",
        "        [-10.5,  -0.4,   4.3,   2.4,  -6.3,  -8.9,  -0.1,\n",
        "           8.2,   8.6,   0.4,   1.2,   0.9,   0.7,   0.6,\n",
        "           6.9,   0.0,   0.4,   1.2],\n",
        "        [ -2.8,   9.6,   2.0,  -6.2,  -8.2,  -2.3,   5.7,\n",
        "           6.6,  -0.3,  -4.7,  -0.5,  -0.9,  -0.9,   1.2,\n",
        "           2.3,  -0.4,   0.1,  -1.5],\n",
        "        [ -2.9,   1.6,  -1.0,  -5.8,  -0.2,   6.2,  14.1,\n",
        "           8.0,  -4.0,  -9.7,  -2.1,  -3.4,  -3.2,  -1.4,\n",
        "           0.0,  -1.7,   0.0,  -3.0],\n",
        "        [ -9.4,   1.7,   5.4,  -1.3,  -6.6,  -4.7,   6.7,\n",
        "          10.2,   1.9,  -9.6,   0.8,   0.6,   0.7,   1.2,\n",
        "          10.2,   0.4,   1.3,   1.2],\n",
        "        [  0.3,  16.1,   3.2,  -4.4,  -5.7,  -2.9,  -3.7,\n",
        "          -6.1,  -2.1,   4.0,  -0.4,   0.1,  -0.4,   0.0,\n",
        "           0.6,  -0.6,  -1.2,  -0.7]]])\n",
        "\n",
        "logits.argmax(dim=-1) -> 1x7\n",
        "tensor([[0,  8,  8,  1,  6, 14,  1]])\n",
        "```\n",
        "\n",
        "`logits.argmax(dim=-1)` basically compress 1x7x18 to 1x7 where for each row of the\n",
        "7 rows, find the index that is maximum for example, first row 7.8 is max of all\n",
        "18 elements, so index 0 is returned. `tensor([[0,  8,  8,  1,  6, 14,  1]])`\n",
        "\n",
        "There is some meaning here too, remember our input `[15, 9, 8, 10, 3, 5, 13]`\n",
        "this is basically the BOS (15) up till the equal sign, then\n",
        "`[ 0, 8, 8, 1, 6, 14, 1]` is basically the prediction of each token what comes\n",
        "next.\n",
        "\n",
        "1. **Input Sequence**: Your input sequence is `[15, 9, 8, 10, 3, 5, 13]`. In\n",
        "   this context, `15` could be a special token like BOS (Beginning of Sentence)\n",
        "   or something else depending on your encoding scheme.\n",
        "\n",
        "2. **Output Tensor Interpretation**: The output tensor\n",
        "   `tensor([[ 0, 8, 8, 1, 6, 14, 1]])` represents the model's sequential\n",
        "   predictions for each step of the input:\n",
        "\n",
        "   - The first element `0` is the prediction following the first element `15` of\n",
        "     the input.\n",
        "   - The second element `8` is the prediction after seeing the first two\n",
        "     elements `15, 9` of the input.\n",
        "   - The third element `8` is predicted after seeing `15, 9, 8`.\n",
        "   - The fourth element `1` follows after `15, 9, 8, 10`.\n",
        "   - The sequence continues in this manner, with each new prediction based on an\n",
        "     increasingly longer prefix of the input sequence.\n",
        "\n",
        "3. **Sequential Predictions**: This output suggests that the model is working in\n",
        "   an autoregressive manner. It generates predictions one token at a time, and\n",
        "   each prediction is based on the sequence of tokens it has seen up to that\n",
        "   point.\n",
        "\n",
        "4. **Specific Meanings of Output Tokens**: The actual meaning of each token in\n",
        "   your output tensor (`0`, `8`, `1`, `6`, `14`, etc.) depends on your specific\n",
        "   encoding and task. In a language model, these would correspond to specific\n",
        "   words or characters. In a numerical context, they could represent numbers or\n",
        "   operations.\n",
        "\n",
        "In summary, the output tensor reflects the model's predictions for what comes\n",
        "next in the sequence, based on the current and all previous input tokens. Each\n",
        "element in the output is the model's guess for the next token, considering the\n",
        "sequence of tokens it has seen up to that point.\n",
        "\n",
        "> Then we move on to the concat operation:\n",
        "\n",
        "\n",
        "- In our model, after processing the input `[15, 9, 8, 10, 3, 5, 13]`, it\n",
        "  predicts the next token to be `1`. This prediction is based on the entire\n",
        "  sequence seen so far.\n",
        "\n",
        "- The process of extending the input sequence with this new token (`1`) and then\n",
        "  feeding this extended sequence back into the model for further predictions is\n",
        "  indeed an example of greedy decoding. The model is iteratively building a\n",
        "  longer sequence, one token at a time, always choosing the most likely next\n",
        "  token at each step.\n",
        "\n",
        "- This process would continue until a stopping condition is met, which might be\n",
        "  the prediction of an EOS (End of Sentence) token or reaching a maximum\n",
        "  sequence length.\n",
        "\n",
        "\n",
        "> for i in range(num_digits + 2):\n",
        "> now you know why loop over 4 times in total if num digits is 2.\n",
        "> This is because, after equal sign, we will have answer of 3 digits (xyz)\n",
        "> and an EOS token, our stop condition!\n",
        "\n",
        "Lastly: `tensor([[15,  9,  8, 10,  3,  5, 13,  1,  3,  3, 14]])` is the full predicted\n",
        "after EOS is met. \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "config.global_config.seed = 42"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def construct_future_mask(seq_len: int) -> torch.BoolTensor:\n",
        "    future_mask = torch.triu(torch.ones((seq_len, seq_len), dtype=torch.bool), diagonal=1).to(torch.bool)\n",
        "    future_mask = future_mask.contiguous()\n",
        "    future_mask = future_mask == 0\n",
        "    return torch.BoolTensor(future_mask)\n",
        "\n",
        "def construct_padding_mask(input_sequence: torch.Tensor, pad_token_id: int) -> torch.BoolTensor:\n",
        "    padding_mask = input_sequence != pad_token_id\n",
        "    return torch.BoolTensor(padding_mask)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "@torch.no_grad()\n",
        "def compute_sum(model, x) -> List[int]:\n",
        "    \"Function for computing the sum of two numbers.\"\n",
        "    # x=[[15,  9,  8, 10,  3,  5, 13]]\n",
        "    for _ in range(num_digits + 2):\n",
        "        # pprint(x)\n",
        "        pad_mask = (x != PAD).view(1, 1, 1, x.size(-1)).to(DEVICE)\n",
        "        future_mask = construct_future_mask(seq_len=x.size(1))\n",
        "        batch_size, seq_len = x.size()\n",
        "        future_mask = future_mask.view(1, seq_len, seq_len).expand(size=(batch_size, -1, -1)).unsqueeze(1)\n",
        "        #print(pad_mask.shape, future_mask.shape)\n",
        "        #inputs, targets, target_padding_masks, future_masks = construct_batches(x)\n",
        "        #print(target_padding_masks.shape, future_masks.shape)\n",
        "        logits = model(input_tokens=x, target_padding_masks=pad_mask, future_masks=future_mask)\n",
        "        pprint(logits.shape)\n",
        "        time.sleep(100)\n",
        "        #logits = model(inputs, target_padding_masks=target_padding_masks, future_masks=future_masks)\n",
        "\n",
        "        last_output = logits.argmax(-1)[:, -1].view(1, 1)\n",
        "        x = torch.cat((x, last_output), 1).to(DEVICE)\n",
        "        # STOPPING CONDITION!\n",
        "        if last_output.item() == EOS:\n",
        "            break\n",
        "        #return\n",
        "    return x[0]\n",
        "\n",
        "\n",
        "def evaluate(model, dataloader, num_batch=None):\n",
        "    \"\"\"\n",
        "    Function for evaluation the model.\n",
        "\n",
        "    This function take equations, and truncate them up to the equal-sign, and feed\n",
        "    them to the model to get the predictions, compare them with the correct answers,\n",
        "    and output the accuracy.\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    acc, count = 0, 0\n",
        "    num_wrong_to_display = 5\n",
        "    for idx, batch in enumerate(dataloader):\n",
        "        (\n",
        "            inputs,\n",
        "            targets,\n",
        "            target_padding_masks,\n",
        "            future_masks,\n",
        "        ) = batch  # construct_batches(batch)\n",
        "        for equation in inputs:\n",
        "            # pprint(equation)\n",
        "            # add EOS behind equation\n",
        "            equation = torch.cat((equation, torch.tensor([EOS])), 0) # TODO: PLEASE DO NOT DO THIS - DO NOT MODIFY LIKE THIS.\n",
        "            # fmt: off\n",
        "            loc_equal_sign = equation.tolist().index(EQUAL)\n",
        "            loc_EOS        = equation.tolist().index(EOS)\n",
        "            input          = equation[0 : loc_equal_sign + 1].view(1, -1).to(DEVICE)\n",
        "            ans            = equation[: loc_EOS + 1].tolist()\n",
        "            ans_pred       = compute_sum(model, input)\n",
        "            count += 1\n",
        "            # fmt: on\n",
        "\n",
        "            if ans == ans_pred.tolist():\n",
        "                acc += 1\n",
        "            else:\n",
        "                if num_wrong_to_display > 0:\n",
        "                    print(\n",
        "                        f'correct equation: {decode_equation(vocab=vocab, equation=equation).replace(\"<PAD>\",\"\")}'\n",
        "                    )\n",
        "                    print(f\"wrongly predicted as:        {decode_equation(vocab=vocab, equation=ans_pred)}\")\n",
        "                    num_wrong_to_display -= 1\n",
        "        if num_batch and idx > num_batch:\n",
        "            break\n",
        "    return acc / count\n",
        "\n",
        "\n",
        "def what_is(question: str) -> str:\n",
        "    \"function for computing the sum of two numbers with input in literal string format\"\n",
        "    pred = compute_sum(model, encode_equation(question, num_digits).view(1, -1))\n",
        "    pred = decode_equation(pred)\n",
        "    pred = pred[pred.index(\"=\") + 1 :]\n",
        "    return question + pred\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The provided code implements a form of greedy decoding for sequence generation.\n",
        "Let's break down how it aligns with the principles of greedy decoding:\n",
        "\n",
        "1. **Greedy Decoding Principle**: Greedy decoding in sequence generation models\n",
        "   involves choosing the most probable next token at each step of the sequence\n",
        "   generation. This is done iteratively until a stopping condition is met (like\n",
        "   reaching an EOS token or a maximum length).\n",
        "\n",
        "2. **Implementation in Your Code**:\n",
        "\n",
        "   - The `compute_sum` function generates a sequence by repeatedly predicting\n",
        "     the next token and appending it to the input.\n",
        "   - For each iteration in `compute_sum`:\n",
        "     - The model (`model(x, pad_mask, future_mask)`) generates logits for the\n",
        "       next token based on the current sequence (`x`).\n",
        "     - `last_output = logits.argmax(-1)[:, -1].view(1, 1)` picks the most\n",
        "       probable next token (the token with the highest logit value) from the\n",
        "       logits. This is the essence of greedy decoding.\n",
        "     - This token is then appended to the sequence:\n",
        "       `x = torch.cat((x, last_output), 1)`.\n",
        "   - The process continues until the model generates an EOS token, as indicated\n",
        "     by `if last_output.item() == EOS: break`.\n",
        "\n",
        "3. **Evaluation Function**:\n",
        "\n",
        "   - The `evaluate` function further confirms this approach by feeding truncated\n",
        "     sequences (up to the equal sign) from the dataloader to the `compute_sum`\n",
        "     function and comparing the model's predictions to the correct answers.\n",
        "\n",
        "4. **Characteristics of Greedy Decoding**:\n",
        "   - Greedy decoding is computationally efficient and straightforward but may\n",
        "     not always produce the best possible sequence. It does not reconsider past\n",
        "     decisions; it always picks the most likely next token at each step without\n",
        "     considering the global context of the sequence.\n",
        "\n",
        "In summary, the provided code, especially the `compute_sum` function, implements\n",
        "a typical greedy decoding approach. It iteratively generates a sequence by\n",
        "choosing the most probable next token at each step, which is characteristic of\n",
        "greedy decoding in sequence generation tasks.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ujaa9mSNrdze"
      },
      "outputs": [],
      "source": [
        "print('training set examples the model gives an incorrect result:')\n",
        "# rng = torch.Generator().manual_seed(config.global_config.seed)\n",
        "seed_all(1992, seed_torch=True)\n",
        "\n",
        "train_acc = evaluate(model, train_loader, 2)\n",
        "pprint(train_acc) #\n",
        "# print('validataion set examples the model gives an incorrect result:')\n",
        "val_acc = evaluate(model, valid_loader)\n",
        "pprint(val_acc)\n",
        "# print('test set examples the model gives an incorrect result:')\n",
        "test_acc = evaluate(model, test_loader)\n",
        "pprint(test_acc)\n",
        "# result = f'''train_size: {train_size}, test_acc: {test_acc}, val_acc: {val_acc}, train_acc: {train_acc}\n",
        "#                 '''\n",
        "# print(result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "QUESTION:\n",
        "\n",
        "another not so smart question of the day: For an input sequence x1,x2,...,x_L, when it forward pass all the way through the decoder model, up till before the pre-logits/head/linear layer, and assuming for simplicity that we squeeze out the first batch dimension (only 1 sample), the the shape of the pre-logits is [L, D] where L is seq len and D the hidden embedding dimension. Am I right to say that the last row of [L, D] being the last token's representation, holds info of the full context of all previous tokens.\n",
        "\n",
        "1. This means the last token in the input sequence (the last row in [L, D]) is a function of all previous tokens, so it is not surprising why the tutorial will just use the last row/token's corresponding prediction as the next predicted token/word, given all previous tokens.\n",
        "\n",
        "> Important to know the last token or last row of [L, D] is actually a function of all previous tokens, here it is unmasked already.\n",
        "> So if confused, just remember the pre logits last row, corresponding to the last token in the input sequence, is a function of all previous tokens.\n",
        "> It just means that row holds all information, context, of all previous tokens so we can say its conditioned on all previous tokens."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CbLTWPIRrdze"
      },
      "source": [
        "train acc: 0.021484375 , 0.0185546875\n",
        "\n",
        "non debug\n",
        "\n",
        "```\n",
        "correct equation: 24+86=110\n",
        "predicted:        24+86=100\n",
        "correct equation: 84+26=110\n",
        "predicted:        84+26=100\n",
        "validataion set examples the model gives an incorrect result:\n",
        "test set examples the model gives an incorrect result:\n",
        "train_size: 7000, train_loss: 0.013642309483007662,\n",
        "                val_loss: 0.0008140208410623018, test_loss: 0.00040599027124699205,\n",
        "                test_acc: 1.0, val_acc: 1.0, train_acc: 0.9996448863636364\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### <a id='toc1_10_5_'></a>[MultiHeadAttention](#toc0_)\n",
        "\n",
        "We start off by understanding the rationale of the following block:\n",
        "\n",
        "```python\n",
        "Q = self.W_Q(query).contiguous() # Z @ W_Q -> BxLxD @ DxD = BxLxD\n",
        "K = self.W_K(key).contiguous()   # Z @ W_K\n",
        "V = self.W_V(value).contiguous() # Z @ W_V\n",
        "```\n",
        "\n",
        "#### <a id='toc1_10_5_1_'></a>[A Primer](#toc0_)\n",
        "\n",
        "In the context of the Transformer architecture and self-attention mechanism, the\n",
        "matrices $\\mathbf{W}^{Q}, \\mathbf{W}^{K},$ and $\\mathbf{W}^{V}$ are learnable\n",
        "parameters designed to project the input embeddings $\\mathbf{Z}$ into distinct\n",
        "subspaces tailored for attention calculations. Let's explore their purpose and\n",
        "their resulting transformations:\n",
        "\n",
        "1. **The Role of Weights**:\n",
        "\n",
        "   - $\\mathbf{W}^{Q}$: Projects input embeddings into a query subspace,\n",
        "     determining the type of information each token seeks from others.\n",
        "   - $\\mathbf{W}^{K}$: Positions the embeddings in a key subspace, highlighting\n",
        "     the token features that others would search for.\n",
        "   - $\\mathbf{W}^{V}$: Transforms embeddings into a value subspace, showcasing\n",
        "     the actual token content to be aggregated by the attention scores.\n",
        "\n",
        "2. **Intuitive & Mathematical Interpretations**:\n",
        "\n",
        "   - **Query Transformation** ($\\mathbf{Z} \\mathbf{W}^{Q}$): Intuitively, it\n",
        "     tailors the raw embeddings to optimally question the rest of the sequence.\n",
        "     Mathematically, it's a linear transformation of the embedding space into\n",
        "     the query space, akin to a high-dimensional rotation and scaling,\n",
        "     emphasizing aspects relevant to querying.\n",
        "\n",
        "   - **Key Transformation** ($\\mathbf{Z} \\mathbf{W}^{K}$): Intuitively, it\n",
        "     accentuates token features that other tokens might seek. Mathematically,\n",
        "     it's another linear transformation emphasizing aspects that make tokens\n",
        "     searchable.\n",
        "\n",
        "   - **Value Transformation** ($\\mathbf{Z} \\mathbf{W}^{V}$): Intuitively, it\n",
        "     prepares tokens to share their intrinsic content when beckoned by the\n",
        "     attention mechanism. Mathematically, it's a linear transformation\n",
        "     accentuating token content aspects.\n",
        "\n",
        "3. **Creating Q, K, V**:\n",
        "\n",
        "   - $\\mathbf{Q} = \\mathbf{Z} \\mathbf{W}^{Q}$\n",
        "   - $\\mathbf{K} = \\mathbf{Z} \\mathbf{W}^{K}$\n",
        "   - $\\mathbf{V} = \\mathbf{Z} \\mathbf{W}^{V}$\n",
        "\n",
        "   These operations recast the embedded tokens into roles for the attention\n",
        "   mechanism:\n",
        "\n",
        "   - $\\mathbf{Q}$: Information seekers. The queries are seeking information, and\n",
        "     the computation $Q @ K^T$ finds how much each part of the input (holder)\n",
        "     should be attended to.\n",
        "   - $\\mathbf{K}$: Information gatekeepers. The keys hold the information being\n",
        "     sought, and their arrangement in space defines the subspace that the\n",
        "     queries are projected onto to find these relevance scores.\n",
        "   - $\\mathbf{V}$: Information providers. The values contain the content that\n",
        "     needs to be retrieved, and once we have the attention weights, we know how\n",
        "     much of each value to retrieve and combine to form the output.\n",
        "\n",
        "   Mathematically, the resulting matrices ($\\mathbf{Q}, \\mathbf{K}, \\mathbf{V}$)\n",
        "   have rows that represent different aspects (querying, key, value) of the\n",
        "   original tokens.\n",
        "\n",
        "4. **Relevance to Self-Attention**:\n",
        "\n",
        "   The transformations set the stage for attention score calculations. In this\n",
        "   step, each query vector in $\\mathbf{Q}$ computes its similarity (via dot\n",
        "   product) against all key vectors in $\\mathbf{K}$. This score matrix reveals\n",
        "   the attention weightage for each token regarding every other token in the\n",
        "   sequence.\n",
        "\n",
        "   Specifically, $\\mathbf{Q} @ \\mathbf{K}^T$ calculates how each token (query)\n",
        "   aligns with every other token (key). It's akin to measuring the relevance of\n",
        "   each word to every other word in the sequence.\n",
        "\n",
        "   After normalizing these scores (typically with softmax), we get the attention\n",
        "   weights. These weights guide how the value vectors in $\\mathbf{V}$ are\n",
        "   aggregated. The outcome is a new matrix where each row aggregates\n",
        "   contextually relevant information from the entire sequence. This enriched\n",
        "   output feeds into subsequent transformer layers for further processing.\n",
        "\n",
        "Overall, by using the $\\mathbf{W}^{Q}, \\mathbf{W}^{K},$ and $\\mathbf{W}^{V}$\n",
        "matrices, the transformer fine-tunes its focus on inter-token relationships,\n",
        "enabling the model to capture intricate contextual nuances within a given\n",
        "sequence."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<img src=\"transformer.png\" width=\"600\">\n",
        "\n",
        "\n",
        "### <a id='toc1_10_6_'></a>[AddNorm (Residual Connection + Layer Normalization)](#toc0_)\n",
        "\n",
        "- https://www.d2l.ai/chapter_attention-mechanisms-and-transformers/transformer.html#residual-connection-and-layer-normalization\n",
        "- https://nlp.seas.harvard.edu/annotated-transformer\n",
        "\n",
        "#### <a id='toc1_10_6_1_'></a>[Residual Block](#toc0_)\n",
        "\n",
        "A residual block takes an input $X$ and a sub-layer (or function) $f$, and computes $X + f(X)$.\n",
        "\n",
        "```python\n",
        "class ResidualBlock(nn.Module):\n",
        "    def __init__(self) -> None:\n",
        "        super().__init__()\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        x: torch.Tensor,\n",
        "        sublayer: Callable[[torch.Tensor], torch.Tensor],\n",
        "    ) -> torch.Tensor:\n",
        "        return x + sublayer(x)\n",
        "```\n",
        "\n",
        "The intuition behind a residual block is to facilitate the training of deeper networks by providing a \"shortcut\" or \"skip connection\" that allows the gradient to be directly backpropagated to earlier layers. Essentially, in a standard deep learning model, each layer transforms its input. As the network depth increases, these transformations can degrade the network's performance, mainly due to the vanishing or exploding gradient problems. This makes it challenging to train very deep networks.\n",
        "\n",
        "The residual block aims to address this problem. It adds the original input back to the output of the network layer, forming $F(x) + x$ instead of just $F(x)$. Mathematically, if $x$ is the input and $F(x)$ is the transformed version, then the residual block computes $F(x) + x$.\n",
        "\n",
        "This architecture has a few advantages:\n",
        "\n",
        "1. **Easier Learning**: During training, if the best transformation is an identity map (i.e., the output should be the same as the input), the residual block can easily learn this. The layers in $F(x)$ only need to learn to approximate zero in this case, which is generally easier than learning an identity map in a traditional stack of layers.\n",
        "\n",
        "2. **Mitigating Vanishing/Exploding Gradients**: The skip connections provide an unobstructed path for the gradients to flow, which can help mitigate the vanishing or exploding gradient problems in very deep networks.\n",
        "\n",
        "3. **Enabling Deeper Networks**: Because of the above advantages, residual blocks make it possible to train very deep networks effectively. Deep networks can represent very complex functions, which can be advantageous for many tasks.\n",
        "\n",
        "4. **Parameter Efficiency**: Residual blocks often require fewer parameters to achieve similar performance compared to traditional deep networks, making them more parameter-efficient.\n",
        "\n",
        "In summary, the residual block is a simple yet effective idea that has enabled the training of much deeper networks, thereby pushing the boundaries of what is achievable in various machine learning tasks.\n",
        "\n",
        "#### <a id='toc1_10_6_2_'></a>[Layer Normalization](#toc0_)\n",
        "\n",
        "Layer normalization normalizes the features across the feature dimension. Given the feature $X$ with shape $[B, L, D]$ (where $B$ is the batch size, $L$ is the sequence length, and $D$ is the feature dimension), layer normalization computes:\n",
        "\n",
        "$$\n",
        "\\text{Norm}(X) = \\frac{X - \\text{mean}(X)}{\\sqrt{\\text{var}(X) + \\epsilon}} \\times \\gamma + \\beta\n",
        "$$\n",
        "\n",
        "Where $\\gamma$ and $\\beta$ are learnable parameters and $\\epsilon$ is a small constant for numerical stability.\n",
        "\n",
        "```python\n",
        "class LayerNorm(nn.Module):\n",
        "    def __init__(self, feature_dim: int, eps: float = 1e-6) -> None:\n",
        "        super().__init__()\n",
        "        # fmt: off\n",
        "        self.gamma = nn.Parameter(torch.ones(feature_dim))\n",
        "        self.beta  = nn.Parameter(torch.zeros(feature_dim))\n",
        "        self.eps   = eps\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        mean = x.mean(dim=-1, keepdim=True)\n",
        "        std  = x.std(dim=-1, keepdim=True)\n",
        "        # fmt: on\n",
        "        return self.gamma * (x - mean) / (std + self.eps) + self.beta\n",
        "```\n",
        "\n",
        "#### <a id='toc1_10_6_3_'></a>[Combining Both](#toc0_)\n",
        "\n",
        "Finally, you can combine these into a single block, much like the `ResidualConnection` or `AddNorm` classes you mentioned earlier.\n",
        "\n",
        "```python\n",
        "class AddNorm(nn.Module):\n",
        "    def __init__(self, feature_dim, dropout_rate):\n",
        "        super(AddNorm, self).__init__()\n",
        "        self.dropout = nn.Dropout(dropout_rate)\n",
        "        self.layer_norm = LayerNorm(feature_dim)\n",
        "\n",
        "    def forward(self, x, sublayer_output):\n",
        "        return self.layer_norm(x + self.dropout(sublayer_output))\n",
        "```\n",
        "\n",
        "This `AddNorm` class applies dropout to the output of the sub-layer, adds it to the original input, and then applies layer normalization. Note that this version doesn't include an embedded layer normalization operation in the residual block; instead, it utilizes a separate layer normalization class, which is then used in the `AddNorm` class."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### <a id='toc1_10_7_'></a>[How Loss is Computed?](#toc0_)\n",
        "\n",
        "The unreduced loss for the Cross Entropy calculation is given by:\n",
        "\n",
        "$$\n",
        "\\mathcal{L}(\\mathcal{X}, \\mathcal{Y}) = \\{l_1, \\ldots, l_N\\}^\\top, \\quad l_n = -\\mathcal{W}_{\\mathcal{Y}_n} \\cdot \\log \\left( \\frac{\\exp(\\mathcal{X}_{n, \\mathcal{Y}_n})}{\\sum_{c=1}^\\mathcal{C} \\exp(\\mathcal{X}_{n, c})} \\right) \\cdot \\mathbb{1}\\{\\mathcal{Y}_n \\neq \\text{ignore\\_index}\\}\n",
        "$$\n",
        "\n",
        "where:\n",
        "\n",
        "- $\\mathcal{X}$ is the input tensor of logits, with shape \\([B, d_1, \\ldots,\n",
        "  d_K, \\mathcal{C}]\\) where $\\mathcal{C}$ is the number of classes and\n",
        "  $[d_1, \\ldots, d_K]$ represent any additional dimensions.\n",
        "- $\\mathcal{Y}$ is the target tensor of class indices, with shape \\([B, d_1,\n",
        "  \\ldots, d_K]\\).\n",
        "- $\\mathcal{W}$ is a tensor of weights corresponding to class indices.\n",
        "- $N$ is the product of the batch size and any additional dimensions, i.e.,\n",
        "  $N = B \\times d_1 \\times \\ldots \\times d_K$. It spans all elements in the\n",
        "  batch and across the additional dimensions, effectively flattening these into\n",
        "  a single dimension for the loss calculation.\n",
        "\n",
        "For the reduced loss, the calculation depends on the reduction method ('mean' or\n",
        "'sum'). The mean reduction averages the loss over all $N$ elements, while the\n",
        "sum reduction simply sums over them:\n",
        "\n",
        "$$\n",
        "\\mathcal{L}(\\mathcal{X}, \\mathcal{Y}) =\n",
        "\\begin{cases}\n",
        "\\sum_{n=1}^N \\left( \\frac{l_n}{\\sum_{n=1}^N \\mathcal{W}_{\\mathcal{Y}_n} \\cdot \\mathbb{1}\\{\\mathcal{Y}_n \\neq \\text{ignore\\_index}\\}} \\right), & \\text{if reduction = 'mean'}\\\\\n",
        "\\sum_{n=1}^N l_n, & \\text{if reduction = 'sum'}\n",
        "\\end{cases}\n",
        "$$\n",
        "\n",
        "This formulation emphasizes that the loss is computed element-wise for each\n",
        "class index in the target tensor $\\mathcal{Y}$, and then either summed or\n",
        "averaged depending on the chosen reduction method. The indicator function\n",
        "$\\mathbb{1}\\{\\}$ ensures that the ignore_index is not considered in the loss\n",
        "computation.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zFbzkjE0zKJe"
      },
      "source": [
        "1. **Define the Loss Function**: The `nn.CrossEntropyLoss` function:\n",
        "    - `nn.CrossEntropyLoss` in PyTorch expects the input logits to be of shape\n",
        "    `[N, C, d1, d2, ..., dK]` (where `N` is the batch size, `C` is the number of\n",
        "    classes, and `d1` to `dK` are optional additional dimensions) and the target\n",
        "    to be of shape `[N, d1, d2, ..., dK]`.\n",
        "    - Let's look a simplified example in image classification. The target is a\n",
        "    single integer representing the class label, and the input logits are a\n",
        "    vector of length `C` (the number of classes)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "25BMnAW5zKJe"
      },
      "outputs": [],
      "source": [
        "rng = torch.Generator().manual_seed(config.global_config.seed)\n",
        "criterion = nn.CrossEntropyLoss(reduction=\"mean\")\n",
        "targets = torch.tensor([1, 0, 0, 0]) # indicating sample 1 is class 1 and sample 2 is class 0\n",
        "logits  = torch.tensor([[0.1, 0.9], [0.9, 0.1], [0.8, 0.2], [0.3, 0.7]])\n",
        "loss   = criterion(logits, targets)\n",
        "pprint(loss)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bFIW_XfMzKJe"
      },
      "source": [
        "Here things are simple, because the target is a single integer representing the class label, and the input logits are a vector of length `C` (the number of classes).\n",
        "\n",
        "The confusion arises when the target is a sequence of integers, as in the case of sequence-to-sequence prediction. In this case, the target is a sequence of integers representing the class labels, and the input logits are a sequence of vectors of length `C` (the number of classes).\n",
        "\n",
        "Let's walk through an example for concrete understanding.\n",
        "\n",
        "Consider the following example:\n",
        "\n",
        "- Batch size: 2\n",
        "- Sequence length: 3\n",
        "- Number of classes/Vocab size: 4\n",
        "- Targets is of shape: `[B, L] = [2, 3]`\n",
        "- Logits is of shape: `[B, L, V] = [2, 3, 4]` where `V` is `C` in the above definition."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ASUDASA_zKJe"
      },
      "outputs": [],
      "source": [
        "# fmt: off\n",
        "rng        = torch.Generator().manual_seed(config.global_config.seed)\n",
        "\n",
        "B, L, V    = 2, 3, 4                                                   # Assuming we have B = batch size, L = sequence length, V = vocab size\n",
        "\n",
        "logits     = torch.randn(B, L, V, generator=rng)                       # logits from the head\n",
        "targets    = torch.randint(low=0, high=V, size=(B, L), generator=rng)  # targets are the labels\n",
        "# fmt: on\n",
        "\n",
        "pprint(logits)\n",
        "pprint(targets)\n",
        "pprint(logits[0]) # logits for the first sequence [L=10, V=18]\n",
        "pprint(targets[0]) # target for the first sequence [L=10]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jTPmANxxzKJe"
      },
      "source": [
        "We establish some conceptual understanding first:\n",
        "\n",
        "- Each sample in the batch has the following characteristics:\n",
        "    - Denote `target` and `logit` as the target and logits for a particular sample in the batch.\n",
        "    - The `target` is of shape `[L] = [3]` and each element is the class/vocab label for each token in the sequence.\n",
        "    - The `logit` is of shape `[L, V] = [3, 4]` and each row is the logits for each token in the sequence.\n",
        "    - Therefore, we want to compare each row in `logit` with each element in `target` to compute the loss.\n",
        "    - We can think of each row in `logit` as the prediction for each token in the sequence, and each element in `target` as the ground truth for each token in the sequence.\n",
        "    - Intuitively this means that within each sample, there are many \"sub-samples\" where each sub-sample is a token in the sequence. If you can visualize this, then there should be no confusion.\n",
        "- In code, we can do so with the following manner:\n",
        "    - Calculate loss for each token in each sample individually and then sum them up.\n",
        "    - Reduction by mean will mean we need to divide our `total_loss` by the total number\n",
        "        of samples in the batch. But remember that even though technically we have\n",
        "        2 samples in the batch, we are actually treating each token in each sample\n",
        "        as a sub-sample, so the total samples is `B * L` where `B` is the batch size\n",
        "        and `L` is the sequence length."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GHWXzJ59zKJe"
      },
      "outputs": [],
      "source": [
        "criterion  = nn.CrossEntropyLoss(reduction=\"mean\")\n",
        "\n",
        "total_loss = 0\n",
        "for b in range(B):\n",
        "    for l in range(L):\n",
        "        logit      = logits[b, l].unsqueeze(0)\n",
        "        target     = targets[b, l].unsqueeze(0)\n",
        "        total_loss += criterion(logit, target)\n",
        "\n",
        "pprint(total_loss)\n",
        "total_loss  = total_loss / (B * L)\n",
        "pprint(total_loss)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LhQrjELfzKJf"
      },
      "source": [
        "In PyTorch however, if you have a logits tensor of shape `[B, S, V]`, you need to permute it to\n",
        "  `[B, V, S]` to align with the format that `CrossEntropyLoss` wants, so that `V` (vocab size) is\n",
        "  treated as `C` (number of classes), and `S` (sequence length) is treated as\n",
        "  one of the additional dimensions `d1, d2, ..., dK`.\n",
        "\n",
        "But all in all, if you understood the previous loop to calculate the loss for each token in each sample individually and then sum them up, then dividing to fulfill reduction of mean, then you should be fine."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lwkq0QDOzKJf"
      },
      "outputs": [],
      "source": [
        "# Permute logits to shape [B, V, S]\n",
        "logits_permuted = logits.permute(0, 2, 1)\n",
        "\n",
        "# Instantiate the CrossEntropyLoss\n",
        "# By default, it reduces by averaging the losses over each observation in the input\n",
        "criterion = nn.CrossEntropyLoss(reduction=\"mean\")\n",
        "\n",
        "loss = criterion(logits_permuted, targets)\n",
        "pprint(loss)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Masking and Ignore Index"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# fmt: off\n",
        "rng        = torch.Generator().manual_seed(config.global_config.seed)\n",
        "\n",
        "B, L, V    = 2, 3, 4                                                   # Assuming we have B = batch size, L = sequence length, V = vocab size\n",
        "\n",
        "logits     = torch.randn(B, L, V, generator=rng)                       # logits from the head\n",
        "targets    = torch.randint(low=0, high=V, size=(B, L), generator=rng)  # targets are the labels\n",
        "# fmt: on\n",
        "\n",
        "pprint(logits)\n",
        "pprint(targets)\n",
        "pprint(logits[0]) # logits for the first sequence [L=10, V=18]\n",
        "pprint(targets[0]) # target for the first sequence [L=10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "targets[:, 0] = -123"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "targets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "PAD_ = -123"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "criterion  = nn.CrossEntropyLoss(reduction=\"mean\", ignore_index=PAD_)\n",
        "\n",
        "NON_IGNORE_COUNT = 0\n",
        "\n",
        "total_loss = 0\n",
        "for b in range(B):\n",
        "    for l in range(L):\n",
        "        logit      = logits[b, l].unsqueeze(0)\n",
        "        target     = targets[b, l].unsqueeze(0)\n",
        "        if target == torch.tensor([PAD_]):\n",
        "            continue\n",
        "        total_loss += criterion(logit, target)\n",
        "        NON_IGNORE_COUNT += 1\n",
        "\n",
        "pprint(total_loss)\n",
        "total_loss  = total_loss / NON_IGNORE_COUNT\n",
        "pprint(total_loss)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "NOTE: `NON_IGNORE_COUNT` is used instead of `BxL`, why? Cause we are averaging over\n",
        "all non-ignored guys!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Permute logits to shape [B, V, S]\n",
        "logits_permuted = logits.permute(0, 2, 1)\n",
        "\n",
        "# Instantiate the CrossEntropyLoss\n",
        "# By default, it reduces by averaging the losses over each observation in the input\n",
        "criterion  = nn.CrossEntropyLoss(reduction=\"mean\", ignore_index=PAD_)\n",
        "\n",
        "loss = criterion(logits_permuted, targets)\n",
        "pprint(loss)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Why mask our target in Adder?\n",
        "\n",
        "Well simply put, we do not care what the model predict for anything before the equal sign.\n",
        "\n",
        "For example\n",
        "\n",
        "```\n",
        "12+97=109\n",
        "```\n",
        "\n",
        "and still the \n",
        "\n",
        "```\n",
        "x = [BOS,1,2,+,9,7,=,1,0,9]\n",
        "y = [1  ,2,+,9,7,=,1,0,9,EOS]\n",
        "```\n",
        "\n",
        "requires us to predict tokens given say, BOS, given say, 1,2,+,9, 7. What we want is\n",
        "for it to predict what is next after `=`, so earlier guys all ignore.\n",
        "\n",
        "By masking out (or ignoring) the tokens before the =, you are guiding the model to focus on learning to predict the result of the addition operation, starting from the = sign.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## <a id='toc1_11_'></a>[Potential to use Module Dict?](#toc0_)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "taBKOEM1rdzm"
      },
      "outputs": [],
      "source": [
        "class ModelModuleDict(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.layers = nn.ModuleDict({\n",
        "            'fc1': nn.Linear(2, 5),\n",
        "            'relu': nn.ReLU(),\n",
        "            'fc2': nn.Linear(5, 1)\n",
        "        })\n",
        "\n",
        "    def forward(self, x):\n",
        "        for layer in self.layers.values():\n",
        "            x = layer(x)\n",
        "        return x\n",
        "\n",
        "# Initialize a random tensor as input\n",
        "input_tensor = torch.randn(1, 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KpkfNuQMrdzm"
      },
      "outputs": [],
      "source": [
        "seed_all(1, seed_torch=True)\n",
        "model_sequential = nn.Sequential(\n",
        "    nn.Linear(2, 5),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(5, 1)\n",
        ")\n",
        "# Forward pass using nn.Sequential model\n",
        "model_sequential(input_tensor)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N_HGZqyDrdzm"
      },
      "outputs": [],
      "source": [
        "seed_all(1, seed_torch=True)\n",
        "model_moduledict   = ModelModuleDict()\n",
        "model_moduledict(input_tensor)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## <a id='toc1_12_'></a>[Training with GPT-like Model](#toc0_)\n",
        "\n",
        "If you're working with a GPT-like model, which is a decoder-only architecture, the training mechanics differ slightly compared to the encoder-decoder models like seq2seq. In a GPT-style model, the entire sequence (input and output) is provided to the model at once, and each token is predicted based on the tokens that came before it. The model is still autoregressive, but there's no separate encoder to produce an intermediate representation; the \"encoding\" is effectively built into the ongoing autoregressive decoding process.\n",
        "\n",
        "In your case, if the equations are like `90+38=128`, during training you'd provide `90+38=` as the input and then use the remaining part `128` as the expected output, potentially along with special tokens to demarcate sequence boundaries or to flag the equation/result parts. However, unlike an encoder-decoder model where the decoder gets to \"peek\" at the correct output during training (also known as \"teacher forcing\"), here every token in the output is predicted one by one, based solely on the preceding tokens.\n",
        "\n",
        "In such a setup, you can definitely feed the entire equation to the model and try to predict each subsequent token based on the preceding tokens. For example, given `90+38=`, the model should predict `1`, `2`, `8` in succession.\n",
        "\n",
        "### <a id='toc1_12_1_'></a>[Loss Computation](#toc0_)\n",
        "\n",
        "For training a GPT-like model, you'd usually use a standard loss function like cross-entropy loss for each token's prediction. You'd compare the token predicted by the model to the actual token in the target sequence to compute the loss. This is calculated for each token and then averaged over the sequence or batch, depending on your implementation.\n",
        "\n",
        "### <a id='toc1_12_2_'></a>[Example](#toc0_)\n",
        "\n",
        "In a GPT-like model, each token in the sequence is used to predict the next token. The model takes a sequence of tokens and produces a new sequence of the same length where each new token is predicted based on all the preceding tokens in the input sequence. The loss is then computed between the predicted sequence and the target sequence.\n",
        "\n",
        "Let's take a closer look at an example:\n",
        "\n",
        "- The original tensor: `[15, 9, 0, 10, 3, 8, 13, 1, 2, 8, 14]` which corresponds to `<SOS>90+38=128<EOS>`\n",
        "- Input tensor:  `[15, 9,  0,  10, 3,  8,  13, 1,  2, 8]`, which corresponds to `<SOS>90+38=128` without `EOS`\n",
        "- Target tensor:     `[9,  0,  10, 3,  8,  13, 1,  2,  8, 14]`\n",
        "                     `[16, 16, 16, 16, 16, 16, 1,  2,  8, 14]`\n",
        "\n",
        "During training:\n",
        "\n",
        "1. **First Timestep**: The model takes `[15]` (or `[<BOS>]` if 15 is your BOS token) and tries to predict the next token. Ideally, it should predict `9`. But here, your target sequence starts with masked tokens (`16`, if 16 is your masking token). So the loss is computed between the predicted token and the masked token `16`. But since `CrossEntropyLoss` has an `ignore_index` (now you know what they are right!), you can set it to say `16` or (default `-1` but you would need to change padding number) and tell the model that whenever the ground truth is `16`, the loss\n",
        "is zeroed out so it is not counted? This allows the model to focus on learning from the relevant parts of the sequence while ignoring the masked portions.\n",
        "\n",
        "2. **Second Timestep**: The model takes `[15, 9]` and predicts the next token, which should be `0`. Again, the target is a masked token `16`.\n",
        "\n",
        "3. **...**\n",
        "\n",
        "4. **Eighth Timestep**: The model takes `[15, 9,  0,  10, 3,  8,  13]` (which is `90+38=`) and predicts the next token. Now the target is `1`, so the loss is computed between the predicted token and `1`. There is no mask anymore here, so the loss will be computed.\n",
        "5. **Ninth Timestep**: The model takes `[15, 9,  0,  10, 3,  8,  13, 1]` (which is `90+38=1`) and predicts the next token. Now the target is `2`, so the loss is computed between the predicted token and `2`.\n",
        "   1. Here's an important thing for beginners (me), In a typical GPT-like architecture used for sequence-to-sequence tasks like this one, the model doesn't use its own predictions as input during training. Instead, it uses the original, ground-truth input sequence. This is known as \"teacher forcing.\" In teacher forcing, even if the model predicts a wrong token at some timestep, it doesn't affect the input sequence for subsequent timesteps. The model continues to get the original input sequence for the entire training epoch.\n",
        "   2. So if model predicts a `3` during the eighth timestep, where the ground trut is `1`, the model would simply incur a higher loss for that prediction. However, the input for the ninth timestep would still be the ground truth sequence up to that point, regardless of what the model predicted at the eighth timestep.\n",
        "   3. But it is noted that this behaviour is still autoregressive.\n",
        "6. **Tenth**: The model takes `[15, 9,  0,  10, 3,  8,  13, 1, 2]` and predicts the next token which is `8`.\n",
        "7. **Last**: The model takes `[15, 9,  0,  10, 3,  8,  13, 1, 2, 8]` and predicts the next token which is `14` the `EOS`.\n",
        "   1. The reason you need to predict `EOS` is simple intuitively, consider the case where there's no need for `EOS`, then the model will not know when to stop.\n",
        "\n",
        "This goes on until the entire sequence is processed. Note that the model never actually \"sees\" the target tokens during the prediction. It is solely relying on the tokens that came before the current token in the input sequence. After the model makes its prediction, then the predicted tokens are compared to the target tokens to compute the loss, which is then backpropagated to update the model weights.\n",
        "\n",
        "### <a id='toc1_12_3_'></a>[Confusion: Training versus Inference](#toc0_)\n",
        "\n",
        "The statement \"it generates one token at a time and uses its own previously generated tokens as context for generating subsequent tokens\" is generally true for GPT-like models during the inference stage, not during training. During inference (or generation), the model does indeed use its own previously generated tokens to produce the next token, since there is no ground truth sequence to rely on. In that case, if the model makes an incorrect prediction at a certain timestep, that incorrect token is used as part of the context for the following timestep.\n",
        "\n",
        "During training, however, the model typically uses the ground truth tokens for the preceding sequence as context for predicting each next token, as described in your example. This resembles teacher forcing, in that the ground truth, rather than the model's own predictions, is used to guide training.\n",
        "\n",
        "So there's no contradiction, but the behavior is context-dependent:\n",
        "\n",
        "- During training, the ground truth sequence is used for context.\n",
        "- During inference, the model's own previously generated tokens are used for context.\n",
        "\n",
        "Both approaches are consistent with the autoregressive nature of the model: in both cases, the token at each position is generated based on the tokens at all previous positions. The difference lies in whether those preceding tokens come from the ground truth (during training) or from the model's own previous outputs (during inference).\n",
        "\n",
        "### <a id='toc1_12_4_'></a>[Training vs Inference](#toc0_)\n",
        "\n",
        "In an autoregressive model like a Transformer decoder, the concept of \"learning\n",
        "the representation of the sequence as it goes\" does not refer to the model\n",
        "processing one token at a time during actual forward passes. Instead, it refers\n",
        "to the model's ability to generate or predict one token at a time during\n",
        "inference, while training on a full sequence in a batched manner.\n",
        "\n",
        "During training:\n",
        "\n",
        "- All tokens are processed in parallel for efficiency. This is possible because\n",
        "  the entire sequence is known beforehand (it's the training data).\n",
        "- The \"autoregressive\" property is enforced by using masks in the self-attention\n",
        "  mechanism. This masking ensures that the prediction for each token can only\n",
        "  depend on previously generated tokens, not on future tokens which the model\n",
        "  has no access to during inference. This is how the model learns the\n",
        "  conditional probability distribution of each token given the previous tokens,\n",
        "  despite the parallel processing of tokens.\n",
        "\n",
        "During inference:\n",
        "\n",
        "- The model starts with an initial token (such as a start-of-sequence token) and\n",
        "  generates the next token based on this single input.\n",
        "- Then, the model uses both the initial token and the newly generated token to\n",
        "  predict the third token, and so on.\n",
        "- This process is sequential and each new token is predicted based on the\n",
        "  previously generated tokens, creating a sequence one token at a time.\n",
        "\n",
        "So, when we say that the model learns the representation of the sequence as it\n",
        "goes, we mean that the model is trained to handle sequences in such a way that\n",
        "it can generate them one piece at a time, respecting the causal order inherent\n",
        "to the task (e.g., language modeling). The parallel processing during training\n",
        "does not contradict the autoregressive nature of the model; it is simply a\n",
        "computational efficiency that is enabled by knowing the full sequence in\n",
        "advance.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## <a id='toc1_13_'></a>[Questions](#toc0_)\n",
        "\n",
        "### <a id='toc1_13_1_'></a>[Why Masked == 0 in some?](#toc0_)\n",
        "\n",
        "The use of `mask == 0` in the `masked_fill` operation is a result of how the mask is constructed. Essentially, different implementations may represent masks differently:\n",
        "\n",
        "1. **Boolean Masking with True/False**: In some implementations, the mask might be a Boolean tensor where `True` denotes the positions to mask (set to negative infinity) and `False` for the positions to keep. In such cases, you can directly use the mask in `masked_fill` as in your provided code:\n",
        "\n",
        "    ```python\n",
        "    attention_scores = attention_scores.masked_fill(mask, float(\"-inf\"))\n",
        "    ```\n",
        "\n",
        "    Here, if `mask[i][j]` is `True`, `attention_scores[i][j]` would be set to `-inf`.\n",
        "\n",
        "2. **Integer Masking with 1/0**: In other implementations, the mask might be an integer tensor where `1` denotes the positions to keep and `0` denotes the positions to mask. In such cases, you'll often find the mask is inverted (`mask == 0`) before using `masked_fill`:\n",
        "\n",
        "    ```python\n",
        "    attention_scores = attention_scores.masked_fill(mask == 0, float(\"-inf\"))\n",
        "    ```\n",
        "\n",
        "    Here, if `mask[i][j]` is `0`, `attention_scores[i][j]` would be set to `-inf`.\n",
        "\n",
        "The core functionality—masking certain positions in the attention scores—is the same in both cases. The difference lies in how the mask tensor is constructed and interpreted. So, if you find an implementation using `mask == 0`, it's likely using an integer mask where `0` signifies positions to mask, whereas if it's directly using `mask`, it's probably a Boolean mask where `True` signifies positions to mask.\n",
        "\n",
        "### <a id='toc1_13_2_'></a>[what is the reason of setting the attention scores's mask indexes to negative infinity](#toc0_)\n",
        "\n",
        "\n",
        "In the attention mechanism, particularly in the Scaled Dot-Product Attention, attention scores are computed for each query-key pair and then passed through a softmax function to obtain attention weights. These weights are used to take a weighted sum of the value vectors, resulting in the final output or the context vectors. The purpose of the mask is to prevent certain tokens (like padding tokens) from being attended to.\n",
        "\n",
        "The reason for setting masked attention scores to negative infinity (`-inf`) lies in the properties of the softmax function:\n",
        "\n",
        "1. **Softmax Behavior**: The softmax function transforms its input (the attention scores in this case) into a probability distribution. Mathematically, the softmax function for a given vector $x$ is defined as:\n",
        "\n",
        "$$\n",
        "\\text{Softmax}(x)_i = \\frac{e^{x_i}}{\\sum_{j=1}^{N} e^{x_j}}\n",
        "$$\n",
        "\n",
        "2. **Impact of Negative Infinity**: When you pass negative infinity through the softmax function, $e^{-\\infty}$ approaches zero. As a result, the masked positions get a near-zero weight in the attention mechanism.\n",
        "\n",
        "$$\n",
        "\\text{Softmax}(-\\infty) = \\frac{e^{-\\infty}}{\\sum_{j=1}^{N} e^{x_j}} \\approx 0\n",
        "$$\n",
        "\n",
        "3. **Avoiding Unwanted Attention**: The point of setting these specific positions to `-inf` is to ensure that when softmax is applied, these positions get zero attention weights. This is a way of making sure that the model does not attend to the positions we've masked (like padding tokens or future tokens in the sequence, depending on the mask).\n",
        "\n",
        "In summary, setting the masked attention scores to `-inf` and then passing them through a softmax effectively nullifies the contribution of the masked positions in the resulting attention-weighted sum of the value vectors. This is a commonly used trick to impose a certain structure (like masking out future information in the decoder) or to handle variable-length sequences with padding.\n",
        "\n",
        "### <a id='toc1_13_3_'></a>[Why do we need both ignore index in Loss and also negative infinity mask](#toc0_)\n",
        "\n",
        "Using an \"ignore index\" in the `CrossEntropyLoss` function in PyTorch can ignore the effect of certain tokens (like padding tokens) during the loss computation. However, the purpose of the mask in the attention mechanism and the \"ignore index\" in the loss function serve different roles in the model, and they operate at different stages of the computational graph.\n",
        "\n",
        "1. **Ignore Index in Loss Function**: The \"ignore index\" in the loss function ensures that the model's output at certain positions (typically corresponding to padding tokens) does not contribute to the loss. This happens at the very end of the forward pass, just before backpropagation begins.\n",
        "\n",
        "2. **Mask in Attention Mechanism**: The mask in the attention mechanism, on the other hand, operates during the forward pass at the time when attention scores are computed. This is a more \"internal\" operation and ensures that certain positions do not contribute to the output at all, not just during the loss computation but actually in the intermediate representations (i.e., context vectors) that the model computes.\n",
        "\n",
        "To put it another way, even if you're ignoring certain tokens in your loss calculation, those tokens can still influence the model's output unless they're masked out in the attention mechanism itself.\n",
        "\n",
        "For example, consider a decoder in a sequence-to-sequence model:\n",
        "- If you don't use a mask in the attention mechanism, future tokens could influence the output at the current timestep, which is not desirable.\n",
        "- Even if you use an \"ignore index\" in your loss function, it doesn't prevent the model from \"cheating\" by peeking at the future tokens if they are not masked in the attention mechanism.\n",
        "\n",
        "So in summary, using an \"ignore index\" in `CrossEntropyLoss` is not a replacement for using attention masks. Both have specific roles in the model, and they are often used together to ensure both that the model attends to the right tokens and that it is trained properly.\n",
        "\n",
        "### <a id='toc1_13_4_'></a>[Target and Preds/Logits Shape](#toc0_)\n",
        "\n",
        "The target tensor for the cross-entropy loss function should typically have a shape of `[batch_size, sequence_length]` where each entry in the tensor is an integer representing the index of the true class (i.e., the actual word/token from the vocabulary) for that position in the sequence. Here `batch_size` refers to the number of sequences in each batch, and `sequence_length` is the length of each sequence.\n",
        "\n",
        "Let's break it down step-by-step:\n",
        "\n",
        "1. **Last Linear Layer of Decoder**: When you say that the last linear layer of your decoder has shape `[bs, vocab_size]`, it means that for each example in the batch, you're outputting a distribution over the vocabulary. The values can be logit scores that represent the likelihood of each word in your vocabulary being the next word in the sequence.\n",
        "\n",
        "2. **Target Shape**: In comparison, your target tensor should contain the actual words (as integers) that appear at each position in your sequence for each example in the batch. The target tensor does not need to have a `vocab_size` dimension because it is not a distribution; it contains the indices of the actual next words. Thus, it should have a shape `[bs, sequence_length]`.\n",
        "\n",
        "3. **Cross-Entropy Loss**: When using the cross-entropy loss, the logits (i.e., the output from your linear layer) should have a shape `[bs, sequence_length, vocab_size]`, while the target should have a shape `[bs, sequence_length]`. The cross-entropy loss function will internally apply a softmax to the logits, and then compute the log-likelihood between the predicted distribution and the target class.\n",
        "\n",
        "To sum up, if your decoder's last linear layer has shape `[bs, vocab_size]` for each time step, make sure that your target tensor has the shape `[bs, sequence_length]`, and your logits should be `[bs, sequence_length, vocab_size]` when you feed them into the cross-entropy loss function.\n",
        "\n",
        "### <a id='toc1_13_5_'></a>[Why do we flatten prediction and target (logits)?](#toc0_)\n",
        "\n",
        "Flattening both the predicted logits and the target labels serves a specific purpose when using the cross-entropy loss function for sequence data. Let's dig into each component to understand why this is done:\n",
        "\n",
        "#### <a id='toc1_13_5_1_'></a>[Background](#toc0_)\n",
        "\n",
        "1. **Logits Tensor**: In a sequence-to-sequence model, you usually generate a sequence of logits for each item in your batch. The logits for each position in the sequence form a vector of size `vocab_size`, which gives you a probability distribution across all possible tokens.\n",
        "  \n",
        "   Shape: `[batch_size, sequence_length, vocab_size]`\n",
        "\n",
        "2. **Targets Tensor**: Your ground truth data, the `targets`, are integers representing the correct class labels (or tokens) at each sequence position.\n",
        "\n",
        "   Shape: `[batch_size, sequence_length]`\n",
        "\n",
        "#### <a id='toc1_13_5_2_'></a>[Traditional Loss Computation](#toc0_)\n",
        "\n",
        "Typically, the cross-entropy loss between predicted probabilities and target labels for one data point is computed, and then you average over all data points. In sequence-to-sequence models, you can think of each position in the sequence as a separate data point.\n",
        "\n",
        "#### <a id='toc1_13_5_3_'></a>[Why Flatten?](#toc0_)\n",
        "1. **Batch and Sequence Unification**: The idea of flattening both logits and targets is to treat each `(batch, sequence_position)` pair as an independent data point. Instead of having a batch of sequences, you have a \"flattened\" batch of tokens. This simplifies the application of the loss function by converting the 3D logits tensor and 2D targets tensor into 2D and 1D tensors, respectively.\n",
        "\n",
        "2. **Efficiency**: Loss computations often benefit from vectorization for computational efficiency. By flattening the tensors, you enable a more efficient matrix operation, which is generally faster than using nested loops over each sequence and batch.\n",
        "\n",
        "3. **Alignment**: The key is to ensure that each row in the flattened logits corresponds to the same position in the flattened targets. This alignment is crucial for the correct computation of the loss.\n",
        "\n",
        "#### <a id='toc1_13_5_4_'></a>[Step-by-step Flattening](#toc0_)\n",
        "\n",
        "1. **Logits Flattening**: `logits.view(-1, logits.size(-1))` will take the 3D tensor `[batch_size, seq_length, vocab_size]` and reshape it into a 2D tensor of shape `[batch_size * seq_length, vocab_size]`.\n",
        "\n",
        "2. **Targets Flattening**: `targets.view(-1)` will take the 2D tensor `[batch_size, seq_length]` and convert it into a 1D tensor of shape `[batch_size * seq_length]`.\n",
        "\n",
        "3. **Loss Calculation**: Both flattened tensors are then used in the cross-entropy loss function. The loss between each row in the flattened logits and the corresponding element in the flattened targets is computed.\n",
        "\n",
        "By flattening the tensors this way, you maintain the correspondence between each logit and its corresponding target, enabling you to correctly compute the loss for each token across all sequences and batches.\n",
        "\n",
        "### <a id='toc1_13_6_'></a>[Why sometimes unsqueeze masks?](#toc0_)\n",
        "\n",
        "The `unsqueeze` operation is used to add an additional dimension to the tensor. In attention mechanisms, particularly the scaled dot-product attention used in models like the Transformer, the masks usually need to have the same number of dimensions as the attention logits for proper broadcasting.\n",
        "\n",
        "For instance, let's say your source tensor (`src`) has a shape of $B \\times L$ where $B$ is the batch size and $L$ is the sequence length. The attention logit tensor resulting from the query-key dot product would then have shape $B \\times N \\times L \\times L$, where $N$ is the number of attention heads.\n",
        "\n",
        "The mask needs to align with the $L \\times L$ dimensions of this 4D tensor. In order to accomplish that, you add singleton dimensions to make it compatible with the attention logit tensor. By unsqueezing the mask tensor from $B \\times L$ to $B \\times 1 \\times 1 \\times L$, you enable broadcasting such that the mask effectively gets expanded to $B \\times N \\times L \\times L$ during the attention calculation, perfectly aligning with the attention logits.\n",
        "\n",
        "That's why the line:\n",
        "```python\n",
        "self.src_mask = (src != pad).unsqueeze(-2)\n",
        "```\n",
        "adds a singleton dimension, converting the shape from $B \\times L$ to $B \\times 1 \\times 1 \\times L$ for proper broadcasting during the attention computations.\n",
        "\n",
        "### <a id='toc1_13_7_'></a>[Why does sequence length differ for source and target, usually I thought it is just all L, same.](#toc0_)\n",
        "\n",
        "...\n",
        "\n",
        "### <a id='toc1_13_8_'></a>[Am i right to assume that the core idea of autoregressive model like decoder only (GPT like) is that for a given sample, there will eventually be L rows where L is the seq length, and therefore I can intuitively view it as 1 sample having L samples, since for each row, we will compute the loss. Am I right in my understanding? Do not hesistate to correct me.](#toc0_)\n",
        "\n",
        "\n",
        "Your description captures an important aspect of autoregressive models like decoder-only Transformers (e.g., GPT). Specifically, you're talking about how the model treats a sequence during training. Let's break down your understanding step by step.\n",
        "\n",
        "1. **Sequence Length**: When you mention \"L rows,\" where \"L\" is the sequence length, you're essentially pointing out that each sequence is divided into \"L\" time steps (or tokens). Each time step becomes an input-output pair for training the model.\n",
        "\n",
        "2. **One Sequence as Multiple Samples**: You're correct to intuit that a single sequence of length \"L\" can be treated like \"L\" samples, at least in the context of loss calculation. This is because, during training, the model computes the loss at each time step by comparing the predicted token with the actual next token in the sequence.\n",
        "\n",
        "3. **Loss Computation**: The loss is often computed at each position and then averaged over the sequence length or summed up, depending on the specific loss function or training regime.\n",
        "\n",
        "However, it's crucial to clarify that although a single sequence may contribute \"L\" terms to the loss function, this is not equivalent to having \"L\" independent samples. The key difference lies in the autoregressive property: the prediction at each time step is conditioned on the preceding tokens. This introduces a temporal dependency across the \"L\" positions, making them not entirely independent samples.\n",
        "\n",
        "In other words, while it's accurate to say that a single sequence contributes multiple terms to the loss function, these terms are correlated because they come from the same sequence and are generated in an autoregressive manner.\n",
        "\n",
        "To summarize, you're mostly correct in your understanding that a single sequence is broken down into multiple steps for the purpose of loss computation, but it's important to remember that these steps are not independent samples due to the autoregressive nature of the model.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Some Implementation Details\n",
        "\n",
        "```\n",
        "Performs one decoder forward pass given encoder hidden states, the decoder input tokens and attention masks.\n",
        "B = batch size\n",
        "S = source sequence length\n",
        "T = target sequence length\n",
        "E = embedding dimensionality\n",
        "V = vocabulary size\n",
        "```\n",
        "\n",
        "### Input\n",
        "\n",
        "Let's view input's first two samples:\n",
        "\n",
        "```\n",
        "tensor([[15,  4,  9, 10,  1,  3, 13,  0,  6,  2],\n",
        "│   │   [15,  3,  5, 10,  4,  6, 13,  0,  8,  1]])\n",
        "```\n",
        "\n",
        "which is\n",
        "\n",
        "-   shape is `[2, 10]` which is `BxL`.\n",
        "-   `49+13=62` but no `EOS` as we truncated last token.\n",
        "-   `35+46=81` but no `EOS` as we truncated last token.\n",
        "\n",
        "### Positional Encodings\n",
        "\n",
        "#### Why do we hardcode batch size of 1 when creating P?\n",
        "\n",
        "The tensor $P$ for positional encoding is initialized with a batch size of 1.\n",
        "This makes it easy to add to the actual input sequences later, during the\n",
        "forward pass. Positional encodings are not dependent on the specific input\n",
        "sequence but are a function of the position within the sequence. Therefore, they\n",
        "can be precomputed and stored. When you look at the forward pass:\n",
        "\n",
        "```python\n",
        "def forward(self, Z: torch.Tensor) -> torch.Tensor:\n",
        "    Z = self._add_positional_encoding(Z)\n",
        "    return self.dropout(Z)\n",
        "```\n",
        "\n",
        "and the `_add_positional_encoding` method:\n",
        "\n",
        "```python\n",
        "def _add_positional_encoding(self, Z: torch.Tensor) -> torch.Tensor:\n",
        "    \"\"\"Add the positional encoding tensor to the input tensor.\"\"\"\n",
        "    return Z + self.P[:, : Z.shape[1], :].to(Z.device)\n",
        "```\n",
        "\n",
        "You'll see that $P$ is sliced to match the sequence length of $Z$ and then added\n",
        "to $Z$. Because of broadcasting rules in PyTorch, $P$ will automatically be\n",
        "broadcasted to the batch size of $Z$ during this addition. This is why $P$ is\n",
        "initialized with a batch size of 1; it keeps the implementation flexible while\n",
        "making the broadcasting implicit.\n",
        "\n",
        "#### Why do we register P as a buffer in PyTorch?\n",
        "\n",
        "In your `PositionalEncoding` class, the tensor `self.P` holds the pre-computed\n",
        "positional encodings. If you intend for this tensor to be automatically moved to\n",
        "the correct device when the module is moved, and if it should not be a learnable\n",
        "parameter, then registering it as a buffer would be a good idea. This ensures\n",
        "that `self.P` is part of the module's state but is not updated during\n",
        "backpropagation.\n",
        "\n",
        "You could register `self.P` as a buffer right after you initialize it in the\n",
        "`_init_positional_encoding` method:\n",
        "\n",
        "```python\n",
        "def _init_positional_encoding(self) -> torch.Tensor:\n",
        "    \"\"\"Initialize the positional encoding tensor.\"\"\"\n",
        "    P = torch.zeros((1, self.max_seq_len, self.d_model))\n",
        "    position = self._get_position_vector()\n",
        "    div_term = self._get_div_term_vector()\n",
        "    P[:, :, 0::2] = torch.sin(position / div_term)\n",
        "    P[:, :, 1::2] = torch.cos(position / div_term)\n",
        "    self.register_buffer(\"P\", P, persistent=True)\n",
        "    return P\n",
        "```\n",
        "\n",
        "Using `register_buffer` ensures that:\n",
        "\n",
        "1. `self.P` is automatically moved to the device the model is moved to (e.g.,\n",
        "   from CPU to GPU).\n",
        "2. `self.P` is saved when you save the model using `torch.save` or `torch.load`.\n",
        "\n",
        "The `persistent=False` argument indicates that the buffer should not be part of\n",
        "the model's `state_dict`, meaning it won't be saved or loaded with the model. If\n",
        "you do want it to be part of the `state_dict`, you can simply omit this\n",
        "argument.\n",
        "\n",
        "### Attention\n",
        "\n",
        "#### Why do we call contiguous on Q, K and V?\n",
        "\n",
        "D2L's code uses `reshape` to reshape the `Q`, `K` and `V`, where other code such\n",
        "as from the Annotated Transformer uses `view`. When you use `view`, this assumes\n",
        "the tensor is `contiguous`, so it is better to call `contiguous` first.\n",
        "\n",
        "#### Why do we want to transpose Q, K, and V?\n",
        "\n",
        "The transposition of $Q$, $K$, and $V$ in multi-head attention serves a specific\n",
        "purpose: to allow for parallel computation across multiple attention heads. In\n",
        "the original shape, the \"heads\" dimension does not exist; the tensor is simply\n",
        "$B \\times L \\times D$, where $B$ is the batch size, $L$ is the sequence length,\n",
        "and $D$ is the model dimension. By transposing, we create a new shape\n",
        "$B \\times H \\times L \\times (D/H)$, where $H$ is the number of heads. This\n",
        "enables the following:\n",
        "\n",
        "1. **Parallelization**: Each head can now be computed in parallel since each\n",
        "   head operates independently of the others.\n",
        "2. **Optimization**: Modern hardware accelerators like GPUs are optimized for\n",
        "   certain tensor operations, and having a shape that aligns well with these\n",
        "   optimizations can result in faster computation.\n",
        "3. **Readability and Maintainability**: It's easier to understand and debug the\n",
        "   operations for each head when they're isolated like this.\n",
        "\n",
        "#### Why do we want to reverse transpose Q, K, and V?\n",
        "\n",
        "After the attention scores are computed and used to weight $V$, we get a new\n",
        "tensor for each head. However, these tensors are still in the transposed shape\n",
        "$B \\times H \\times L \\times (D/H)$, and they need to be concatenated and\n",
        "linearly transformed to continue through the network. The reverse transposition\n",
        "essentially does the following:\n",
        "\n",
        "1. **Concatenation**: Converts the multiple heads back into a single tensor.\n",
        "   This is required because subsequent layers (like feed-forward neural\n",
        "   networks) expect input in the original $D$-dimensional space.\n",
        "\n",
        "2. **Compatibility**: The rest of the neural network architecture often expects\n",
        "   input tensors to have a specific shape (usually $B \\times L \\times D$).\n",
        "   Reverse transposing ensures that the output of the multi-head attention block\n",
        "   can be fed into subsequent layers without issue.\n",
        "\n",
        "3. **Resource Efficiency**: By reducing the tensor back to its original\n",
        "   dimensions, we can save memory and computational resources, which is\n",
        "   beneficial when you're training large models or operating under hardware\n",
        "   constraints.\n",
        "\n",
        "In summary, the initial transposition is done to facilitate parallel computation\n",
        "across heads, and the reverse transposition is done to concatenate these heads\n",
        "and prepare the tensor for subsequent layers.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Why we need Positional Vector\n",
        "\n",
        "Positional encoding is critical cause the cat ate the mouse is the same as the\n",
        "mouse ate the cat without it\n",
        "\n",
        "Without it the attention Q and K matmul would result in a permutation invariant\n",
        "matrix. So adding position info makes the last token in the attention matrix\n",
        "(say mouse from the cat ate the mouse) would allow the word mouse to hold info\n",
        "for every other word in the sentence as well as knowing every other token\n",
        "position (including knowing it's the last token)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## <a id='toc1_14_'></a>[TODO](#toc0_)\n",
        "\n",
        "1. Add Positional Encoding\n",
        "2. Add LR Scheduler\n",
        "3. Check why need to use `torch.nn.utils.clip_grad_norm_` to clip gradients\n",
        "4. Why unsqueeze mask?\n",
        "5. Can you init weights inside Encoder instead of outside?\n",
        "6. Add Epoch and Batch State see my old code.\n",
        "7. Important use `Vocab` class like in https://github.com/jsbaan/transformer-from-scratch/blob/main/vocabulary.py.\n",
        "\n",
        "https://uvadlc-notebooks.readthedocs.io/en/latest/tutorial_notebooks/tutorial6/Transformers_and_MHAttention.html\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## <a id='toc1_15_'></a>[References and Further Readings](#toc0_)\n",
        "\n",
        "- https://slds-lmu.github.io/seminar_nlp_ss20/"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
