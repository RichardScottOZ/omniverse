{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Table of contents**<a id='toc0_'></a>    \n",
    "- [Shakespeare](#toc1_)    \n",
    "  - [Vocabulary and Tokenization](#toc1_1_)    \n",
    "  - [Dataset and Dataloader](#toc1_2_)    \n",
    "    - [Why is the length of the dataset defined as `len(self.corpus) - self.context_length`?](#toc1_2_1_)    \n",
    "    - [Understanding the Dataset Length in the Context of Language Models:](#toc1_2_2_)    \n",
    "\n",
    "<!-- vscode-jupyter-toc-config\n",
    "\tnumbering=false\n",
    "\tanchor=true\n",
    "\tflat=false\n",
    "\tminLevel=1\n",
    "\tmaxLevel=6\n",
    "\t/vscode-jupyter-toc-config -->\n",
    "<!-- THIS CELL WILL BE REPLACED ON TOC UPDATE. DO NOT WRITE YOUR TEXT IN THIS CELL -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <a id='toc1_'></a>[Shakespeare](#toc0_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import os\n",
    "import torch\n",
    "from rich.pretty import pprint\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "from torch import nn\n",
    "import requests\n",
    "from typing import List, Tuple, Dict, Any, Union\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "def find_root_dir(current_path: Path = Path.cwd(), marker: str = '.git') -> Path | None:\n",
    "    \"\"\"\n",
    "    Find the root directory by searching for a directory or file that serves as a\n",
    "    marker.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    current_path : Path\n",
    "        The starting path to search from.\n",
    "    marker : str\n",
    "        The name of the file or directory that signifies the root.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    Path or None\n",
    "        The path to the root directory. Returns None if the marker is not found.\n",
    "    \"\"\"\n",
    "    current_path = current_path.resolve()\n",
    "    for parent in current_path.parents:\n",
    "        if (parent / marker).exists():\n",
    "            return parent\n",
    "    return None\n",
    "\n",
    "current_file_path = Path(os.getcwd())\n",
    "root_dir          = find_root_dir(current_file_path, marker='omnivault')\n",
    "\n",
    "if root_dir is not None:\n",
    "    sys.path.append(str(root_dir))\n",
    "    from omnivault.transformer.utils.reproducibility import seed_all\n",
    "    from omnivault.transformer.core.vocabulary import TextCharacterVocabulary\n",
    "    from omnivault.transformer.core.dataset import TextCharacterDataset\n",
    "    from omnivault.transformer.core.tokenizer import TextCharacterTokenizer\n",
    "    from omnivault.transformer.config.composer import Composer, DataConfig\n",
    "    from omnivault.transformer.config.optim import OptimizerConfig, AdamConfig\n",
    "    from omnivault.transformer.config.constants import MaybeConstant\n",
    "    from omnivault.transformer.config.global_ import MaybeGlobal\n",
    "    from omnivault.transformer.decoder.core import GPTDecoder, GPTDecoderBlock\n",
    "    from omnivault.transformer.config.decoder import *\n",
    "    from omnivault.transformer.modules.attention.core import ScaledDotProductAttention, MultiHeadedAttention\n",
    "    from omnivault.transformer.core.trainer import Trainer\n",
    "\n",
    "else:\n",
    "    raise ImportError(\"Root directory not found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc1_1_'></a>[Vocabulary and Tokenization](#toc0_)\n",
    "\n",
    "See https://huggingface.co/learn/nlp-course/chapter2/4?fw=pt.\n",
    "\n",
    "Especially:\n",
    "\n",
    "> The second step is to convert those tokens into numbers, so we can build a tensor out of them and feed them to the model. To do this, the tokenizer has a vocabulary, which is the part we download when we instantiate it with the from_pretrained() method. Again, we need to use the same vocabulary used when the model was pretrained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import AutoTokenizer\n",
    "\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")\n",
    "\n",
    "# sequence = \"Using a Transformer network is simple\"\n",
    "# tokens = tokenizer.tokenize(sequence)\n",
    "\n",
    "# print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = open('../../../data/tinyshakespeare/input.txt', 'r').read() # don't worry we won't run out of file handles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data has 1115394 characters, 65 unique.\n"
     ]
    }
   ],
   "source": [
    "chars = sorted(list(set(data)))\n",
    "data_size, vocab_size = len(data), len(chars)\n",
    "print('data has %d characters, %d unique.' % (data_size, vocab_size))\n",
    "\n",
    "stoi = { ch:i for i,ch in enumerate(chars) }\n",
    "itos = { i:ch for i,ch in enumerate(chars) }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt'\n",
    "vocabulary = TextCharacterVocabulary.from_file('../../../data/tinyshakespeare/input.txt')\n",
    "vocabulary_2 = TextCharacterVocabulary.from_url(url)\n",
    "assert vocabulary.index_to_token == vocabulary_2.index_to_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(65, 46)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary.vocab_size, vocabulary.token_to_index['h']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = TextCharacterTokenizer(vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['h', 'e', 'l', 'l', 'o'], [46, 43, 50, 50, 53], 'hello')"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.tokenize('hello'), tokenizer.encode('hello'), tokenizer.decode(tokenizer.encode('hello'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='toc1_2_'></a>[Dataset and Dataloader](#toc0_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43, 44,\n",
       "          53, 56, 43,  1, 61, 43,  1, 54, 56, 53, 41, 43, 43, 42,  1, 39, 52, 63,\n",
       "           1, 44, 59, 56, 58, 46, 43, 56,  6,  1, 46, 43, 39, 56,  1, 51, 43,  1,\n",
       "          57, 54, 43, 39, 49,  8,  0,  0, 13, 50]),\n",
       "  tensor([47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43, 44, 53,\n",
       "          56, 43,  1, 61, 43,  1, 54, 56, 53, 41, 43, 43, 42,  1, 39, 52, 63,  1,\n",
       "          44, 59, 56, 58, 46, 43, 56,  6,  1, 46, 43, 39, 56,  1, 51, 43,  1, 57,\n",
       "          54, 43, 39, 49,  8,  0,  0, 13, 50, 50])),\n",
       " 'First Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAl',\n",
       " 'irst Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll')"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = open('../../../data/tinyshakespeare/input.txt', 'r').read()\n",
    "dataset = TextCharacterDataset(corpus=corpus, context_length=64, tokenizer=tokenizer)\n",
    "\n",
    "dataset[0], tokenizer.decode(dataset[0][0].tolist()), tokenizer.decode(dataset[0][1].tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <a id='toc1_2_1_'></a>[Why is the length of the dataset defined as `len(self.corpus) - self.context_length`?](#toc0_)\n",
    "\n",
    "Why the length of the dataset is defined as\n",
    "`len(self.corpus) - self.context_length`. This design is common in datasets used\n",
    "for training language models, particularly autoregressive models like GPT. Let\n",
    "me elaborate further:\n",
    "\n",
    "### <a id='toc1_2_2_'></a>[Understanding the Dataset Length in the Context of Language Models:](#toc0_)\n",
    "\n",
    "1. **Training Samples Formation**:\n",
    "\n",
    "    - In an autoregressive model, each training sample typically consists of a\n",
    "      sequence of tokens used as input and a subsequent token (or tokens) used\n",
    "      as the target for prediction.\n",
    "    - If `context_length` is the size of the input sequence, then for any\n",
    "      starting point in the corpus, you need enough tokens following it to form\n",
    "      a complete input sequence.\n",
    "\n",
    "2. **Avoiding Out-of-Bounds Access**:\n",
    "\n",
    "    - As you approach the end of the corpus, there are fewer tokens available to\n",
    "      form a complete input sequence of `context_length`.\n",
    "    - For example, if the corpus length is 1000 tokens and `context_length` is\n",
    "      128, trying to form a sequence starting at token 900 would result in an\n",
    "      out-of-bounds access, as you would need tokens up to index 1027 (which\n",
    "      doesn't exist in the corpus).\n",
    "\n",
    "3. **Dataset Length Calculation**:\n",
    "\n",
    "    - To prevent this out-of-bounds issue, the length of the dataset is\n",
    "      restricted to `len(self.corpus) - self.context_length`. This ensures that\n",
    "      for any index `i` in the dataset, you can safely access the sequence\n",
    "      `self.corpus[i:i + context_length]` without exceeding the bounds of the\n",
    "      corpus.\n",
    "    - This adjustment means the dataset will not generate sequences that extend\n",
    "      beyond the end of the corpus.\n",
    "\n",
    "4. **Practical Example**:\n",
    "    - If `self.corpus` has 1000 characters and `self.context_length` is 128, the\n",
    "      last index accessed by the dataset (for the start of a sequence) will be\n",
    "      `1000 - 128 = 872`. The corresponding sequence will run from index 872 to\n",
    "      999, which is precisely 128 characters.\n",
    "\n",
    "In summary, the length of the dataset is calculated as\n",
    "`len(self.corpus) - self.context_length` to ensure that every training sample\n",
    "has a complete input sequence of the desired context length, without attempting\n",
    "to access data beyond the end of the corpus. This approach is a standard\n",
    "practice in preparing datasets for training language models.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Composer</span><span style=\"font-weight: bold\">(</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #808000; text-decoration-color: #808000\">constants</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">MaybeConstant</span><span style=\"font-weight: bold\">(</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">NUM_DIGITS</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">TOKENS</span>=<span style=\"font-weight: bold\">[</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   │   </span><span style=\"color: #008000; text-decoration-color: #008000\">'0'</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   │   </span><span style=\"color: #008000; text-decoration-color: #008000\">'1'</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   │   </span><span style=\"color: #008000; text-decoration-color: #008000\">'2'</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   │   </span><span style=\"color: #008000; text-decoration-color: #008000\">'3'</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   │   </span><span style=\"color: #008000; text-decoration-color: #008000\">'4'</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   │   </span><span style=\"color: #008000; text-decoration-color: #008000\">'5'</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   │   </span><span style=\"color: #008000; text-decoration-color: #008000\">'6'</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   │   </span><span style=\"color: #008000; text-decoration-color: #008000\">'7'</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   │   </span><span style=\"color: #008000; text-decoration-color: #008000\">'8'</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   │   </span><span style=\"color: #008000; text-decoration-color: #008000\">'9'</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   │   </span><span style=\"color: #008000; text-decoration-color: #008000\">'+'</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   │   </span><span style=\"color: #008000; text-decoration-color: #008000\">'*'</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   │   </span><span style=\"color: #008000; text-decoration-color: #008000\">'-'</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   │   </span><span style=\"color: #008000; text-decoration-color: #008000\">'='</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   │   </span><span style=\"color: #008000; text-decoration-color: #008000\">'&lt;BOS&gt;'</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   │   </span><span style=\"color: #008000; text-decoration-color: #008000\">'&lt;EOS&gt;'</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   │   </span><span style=\"color: #008000; text-decoration-color: #008000\">'&lt;PAD&gt;'</span><span style=\"color: #000000; text-decoration-color: #000000\">,</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   │   </span><span style=\"color: #008000; text-decoration-color: #008000\">'&lt;UNK&gt;'</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"font-weight: bold\">]</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"font-weight: bold\">)</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #808000; text-decoration-color: #808000\">global_</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">MaybeGlobal</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">seed</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">42</span>, <span style=\"color: #808000; text-decoration-color: #808000\">debug</span>=<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span><span style=\"font-weight: bold\">)</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #808000; text-decoration-color: #808000\">data</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">DataConfig</span><span style=\"font-weight: bold\">(</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">dataset_size</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">split</span>=<span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.7</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.2</span><span style=\"font-weight: bold\">]</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">collate_fn</span>=<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'batch_first'</span>: <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'pad_token_id'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">16</span><span style=\"font-weight: bold\">}</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">train_loader</span>=<span style=\"font-weight: bold\">{</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   │   </span><span style=\"color: #008000; text-decoration-color: #008000\">'batch_size'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">32</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   │   </span><span style=\"color: #008000; text-decoration-color: #008000\">'shuffle'</span>: <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   │   </span><span style=\"color: #008000; text-decoration-color: #008000\">'num_workers'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   │   </span><span style=\"color: #008000; text-decoration-color: #008000\">'pin_memory'</span>: <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   │   </span><span style=\"color: #008000; text-decoration-color: #008000\">'drop_last'</span>: <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"font-weight: bold\">}</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">val_loader</span>=<span style=\"font-weight: bold\">{</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   │   </span><span style=\"color: #008000; text-decoration-color: #008000\">'batch_size'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">32</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   │   </span><span style=\"color: #008000; text-decoration-color: #008000\">'shuffle'</span>: <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   │   </span><span style=\"color: #008000; text-decoration-color: #008000\">'num_workers'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   │   </span><span style=\"color: #008000; text-decoration-color: #008000\">'pin_memory'</span>: <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   │   </span><span style=\"color: #008000; text-decoration-color: #008000\">'drop_last'</span>: <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"font-weight: bold\">}</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">test_loader</span>=<span style=\"font-weight: bold\">{</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   │   </span><span style=\"color: #008000; text-decoration-color: #008000\">'batch_size'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">32</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   │   </span><span style=\"color: #008000; text-decoration-color: #008000\">'shuffle'</span>: <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   │   </span><span style=\"color: #008000; text-decoration-color: #008000\">'num_workers'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   │   </span><span style=\"color: #008000; text-decoration-color: #008000\">'pin_memory'</span>: <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   │   </span><span style=\"color: #008000; text-decoration-color: #008000\">'drop_last'</span>: <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"font-weight: bold\">}</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"font-weight: bold\">)</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #808000; text-decoration-color: #808000\">optimizer</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">AdamConfig</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">name</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'torch.optim.Adam'</span>, <span style=\"color: #808000; text-decoration-color: #808000\">lr</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0005</span>, <span style=\"color: #808000; text-decoration-color: #808000\">betas</span>=<span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.9</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.98</span><span style=\"font-weight: bold\">)</span>, <span style=\"color: #808000; text-decoration-color: #808000\">eps</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1e-09</span><span style=\"font-weight: bold\">)</span>\n",
       "<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mComposer\u001b[0m\u001b[1m(\u001b[0m\n",
       "\u001b[2;32m│   \u001b[0m\u001b[33mconstants\u001b[0m=\u001b[1;35mMaybeConstant\u001b[0m\u001b[1m(\u001b[0m\n",
       "\u001b[2;32m│   │   \u001b[0m\u001b[33mNUM_DIGITS\u001b[0m=\u001b[1;36m2\u001b[0m,\n",
       "\u001b[2;32m│   │   \u001b[0m\u001b[33mTOKENS\u001b[0m=\u001b[1m[\u001b[0m\n",
       "\u001b[2;32m│   │   │   \u001b[0m\u001b[32m'0'\u001b[0m,\n",
       "\u001b[2;32m│   │   │   \u001b[0m\u001b[32m'1'\u001b[0m,\n",
       "\u001b[2;32m│   │   │   \u001b[0m\u001b[32m'2'\u001b[0m,\n",
       "\u001b[2;32m│   │   │   \u001b[0m\u001b[32m'3'\u001b[0m,\n",
       "\u001b[2;32m│   │   │   \u001b[0m\u001b[32m'4'\u001b[0m,\n",
       "\u001b[2;32m│   │   │   \u001b[0m\u001b[32m'5'\u001b[0m,\n",
       "\u001b[2;32m│   │   │   \u001b[0m\u001b[32m'6'\u001b[0m,\n",
       "\u001b[2;32m│   │   │   \u001b[0m\u001b[32m'7'\u001b[0m,\n",
       "\u001b[2;32m│   │   │   \u001b[0m\u001b[32m'8'\u001b[0m,\n",
       "\u001b[2;32m│   │   │   \u001b[0m\u001b[32m'9'\u001b[0m,\n",
       "\u001b[2;32m│   │   │   \u001b[0m\u001b[32m'+'\u001b[0m,\n",
       "\u001b[2;32m│   │   │   \u001b[0m\u001b[32m'*'\u001b[0m,\n",
       "\u001b[2;32m│   │   │   \u001b[0m\u001b[32m'-'\u001b[0m,\n",
       "\u001b[2;32m│   │   │   \u001b[0m\u001b[32m'='\u001b[0m,\n",
       "\u001b[2;32m│   │   │   \u001b[0m\u001b[32m'\u001b[0m\u001b[32m<\u001b[0m\u001b[32mBOS\u001b[0m\u001b[32m>'\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[2;32m│   │   │   \u001b[0m\u001b[32m'<EOS>'\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[2;32m│   │   │   \u001b[0m\u001b[32m'<PAD>'\u001b[0m\u001b[39m,\u001b[0m\n",
       "\u001b[2;32m│   │   │   \u001b[0m\u001b[32m'<UNK\u001b[0m\u001b[32m>\u001b[0m\u001b[32m'\u001b[0m\n",
       "\u001b[2;32m│   │   \u001b[0m\u001b[1m]\u001b[0m\n",
       "\u001b[2;32m│   \u001b[0m\u001b[1m)\u001b[0m,\n",
       "\u001b[2;32m│   \u001b[0m\u001b[33mglobal_\u001b[0m=\u001b[1;35mMaybeGlobal\u001b[0m\u001b[1m(\u001b[0m\u001b[33mseed\u001b[0m=\u001b[1;36m42\u001b[0m, \u001b[33mdebug\u001b[0m=\u001b[3;91mFalse\u001b[0m\u001b[1m)\u001b[0m,\n",
       "\u001b[2;32m│   \u001b[0m\u001b[33mdata\u001b[0m=\u001b[1;35mDataConfig\u001b[0m\u001b[1m(\u001b[0m\n",
       "\u001b[2;32m│   │   \u001b[0m\u001b[33mdataset_size\u001b[0m=\u001b[1;36m2\u001b[0m,\n",
       "\u001b[2;32m│   │   \u001b[0m\u001b[33msplit\u001b[0m=\u001b[1m[\u001b[0m\u001b[1;36m0.7\u001b[0m, \u001b[1;36m0.1\u001b[0m, \u001b[1;36m0.2\u001b[0m\u001b[1m]\u001b[0m,\n",
       "\u001b[2;32m│   │   \u001b[0m\u001b[33mcollate_fn\u001b[0m=\u001b[1m{\u001b[0m\u001b[32m'batch_first'\u001b[0m: \u001b[3;92mTrue\u001b[0m, \u001b[32m'pad_token_id'\u001b[0m: \u001b[1;36m16\u001b[0m\u001b[1m}\u001b[0m,\n",
       "\u001b[2;32m│   │   \u001b[0m\u001b[33mtrain_loader\u001b[0m=\u001b[1m{\u001b[0m\n",
       "\u001b[2;32m│   │   │   \u001b[0m\u001b[32m'batch_size'\u001b[0m: \u001b[1;36m32\u001b[0m,\n",
       "\u001b[2;32m│   │   │   \u001b[0m\u001b[32m'shuffle'\u001b[0m: \u001b[3;92mTrue\u001b[0m,\n",
       "\u001b[2;32m│   │   │   \u001b[0m\u001b[32m'num_workers'\u001b[0m: \u001b[1;36m0\u001b[0m,\n",
       "\u001b[2;32m│   │   │   \u001b[0m\u001b[32m'pin_memory'\u001b[0m: \u001b[3;91mFalse\u001b[0m,\n",
       "\u001b[2;32m│   │   │   \u001b[0m\u001b[32m'drop_last'\u001b[0m: \u001b[3;91mFalse\u001b[0m\n",
       "\u001b[2;32m│   │   \u001b[0m\u001b[1m}\u001b[0m,\n",
       "\u001b[2;32m│   │   \u001b[0m\u001b[33mval_loader\u001b[0m=\u001b[1m{\u001b[0m\n",
       "\u001b[2;32m│   │   │   \u001b[0m\u001b[32m'batch_size'\u001b[0m: \u001b[1;36m32\u001b[0m,\n",
       "\u001b[2;32m│   │   │   \u001b[0m\u001b[32m'shuffle'\u001b[0m: \u001b[3;91mFalse\u001b[0m,\n",
       "\u001b[2;32m│   │   │   \u001b[0m\u001b[32m'num_workers'\u001b[0m: \u001b[1;36m0\u001b[0m,\n",
       "\u001b[2;32m│   │   │   \u001b[0m\u001b[32m'pin_memory'\u001b[0m: \u001b[3;91mFalse\u001b[0m,\n",
       "\u001b[2;32m│   │   │   \u001b[0m\u001b[32m'drop_last'\u001b[0m: \u001b[3;91mFalse\u001b[0m\n",
       "\u001b[2;32m│   │   \u001b[0m\u001b[1m}\u001b[0m,\n",
       "\u001b[2;32m│   │   \u001b[0m\u001b[33mtest_loader\u001b[0m=\u001b[1m{\u001b[0m\n",
       "\u001b[2;32m│   │   │   \u001b[0m\u001b[32m'batch_size'\u001b[0m: \u001b[1;36m32\u001b[0m,\n",
       "\u001b[2;32m│   │   │   \u001b[0m\u001b[32m'shuffle'\u001b[0m: \u001b[3;91mFalse\u001b[0m,\n",
       "\u001b[2;32m│   │   │   \u001b[0m\u001b[32m'num_workers'\u001b[0m: \u001b[1;36m0\u001b[0m,\n",
       "\u001b[2;32m│   │   │   \u001b[0m\u001b[32m'pin_memory'\u001b[0m: \u001b[3;91mFalse\u001b[0m,\n",
       "\u001b[2;32m│   │   │   \u001b[0m\u001b[32m'drop_last'\u001b[0m: \u001b[3;91mFalse\u001b[0m\n",
       "\u001b[2;32m│   │   \u001b[0m\u001b[1m}\u001b[0m\n",
       "\u001b[2;32m│   \u001b[0m\u001b[1m)\u001b[0m,\n",
       "\u001b[2;32m│   \u001b[0m\u001b[33moptimizer\u001b[0m=\u001b[1;35mAdamConfig\u001b[0m\u001b[1m(\u001b[0m\u001b[33mname\u001b[0m=\u001b[32m'torch.optim.Adam'\u001b[0m, \u001b[33mlr\u001b[0m=\u001b[1;36m0\u001b[0m\u001b[1;36m.0005\u001b[0m, \u001b[33mbetas\u001b[0m=\u001b[1m(\u001b[0m\u001b[1;36m0.9\u001b[0m, \u001b[1;36m0.98\u001b[0m\u001b[1m)\u001b[0m, \u001b[33meps\u001b[0m=\u001b[1;36m1e\u001b[0m\u001b[1;36m-09\u001b[0m\u001b[1m)\u001b[0m\n",
       "\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "constants: MaybeConstant = MaybeConstant()\n",
    "global_: MaybeGlobal = MaybeGlobal(seed=42, dataset_size=2)\n",
    "data_config: DataConfig = DataConfig()\n",
    "optimizer_config = AdamConfig(name=\"torch.optim.Adam\", lr=5e-4, betas=(0.9, 0.98), eps=1e-9)\n",
    "\n",
    "config = Composer(constants=constants, global_=global_, data=data_config, optimizer=optimizer_config)\n",
    "pprint(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/gaohn/omniverse/omniverse/omnivault/transformer/utils/reproducibility.py:69: UserWarning: Deterministic mode is activated. This will negatively impact performance.\n",
      "  configure_deterministic_mode()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DEBUG  = True\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "seed_all(config.global_.seed, seed_torch=True, set_torch_deterministic=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(dataset=dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create individual component configurations\n",
    "masked_self_attention_mha_config = MultiHeadedAttentionConfig(\n",
    "     attention=ScaledDotProductAttention(),\n",
    "    d_model=128, H=4, dropout=0.1\n",
    ")\n",
    "\n",
    "feed_forward_config = PositionwiseFeedForwardConfig(\n",
    "    d_model=128, d_ff=256, activation=nn.GELU(approximate=\"tanh\"), dropout=0.1, bias=True\n",
    ")\n",
    "\n",
    "add_norm_config_1 = AddNormConfig(feature_dim=128, dropout=0.1)\n",
    "add_norm_config_2 = AddNormConfig(feature_dim=128, dropout=0.1)\n",
    "\n",
    "# Create DecoderBlockConfig\n",
    "decoder_block_config = DecoderBlockConfig(\n",
    "    masked_self_attention_mha=masked_self_attention_mha_config,\n",
    "    feed_forward=feed_forward_config,\n",
    "    add_norm_1=add_norm_config_1,\n",
    "    add_norm_2=add_norm_config_2,\n",
    ")\n",
    "\n",
    "# Create the overall DecoderConfig\n",
    "model_config = DecoderConfig(\n",
    "    d_model=128,\n",
    "    vocab_size=vocab_size,\n",
    "    context_length=64,\n",
    "    num_decoder_blocks=2,\n",
    "    dropout=0.1,\n",
    "    decoder_block=decoder_block_config,\n",
    ")\n",
    "\n",
    "model = GPTDecoder(model_config).to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# warmup_steps = 3*len(dataloaders.train_loader)\n",
    "warmup_steps = 3 * len(train_loader)\n",
    "\n",
    "\n",
    "# lr first increases in the warmup steps, and then descreases\n",
    "lr_fn        = lambda step: model_config.d_model**(-0.5) * min([(step+1)**(-0.5), (step+1)*warmup_steps**(-1.5)])\n",
    "# optimizer    = torch.optim.Adam(model.parameters(), lr=0.2, betas=(0.9, 0.98), eps=1e-9)\n",
    "\n",
    "# optimizer_config = OptimizerConfig(name=\"torch.optim.Adam\", lr=0.2, betas=(0.9, 0.98), eps=1e-9)\n",
    "# optimizer   = optimizer_config.build(params=model.parameters())\n",
    "\n",
    "# optimizer_config = OptimizerConfig(name=\"torch.optim.Adam\", lr=0.2)\n",
    "# optimizer   = optimizer_config.build(params=model.parameters(), betas=(0.9, 0.98), eps=1e-9)\n",
    "\n",
    "optimizer   = config.optimizer.build(params=model.parameters())\n",
    "\n",
    "scheduler    = torch.optim.lr_scheduler.LambdaLR(optimizer, lr_lambda=lr_fn)\n",
    "criterion    = nn.CrossEntropyLoss(ignore_index=-1, reduction=\"mean\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/34855 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 4, got 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[87], line 16\u001b[0m\n\u001b[1;32m      1\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(\n\u001b[1;32m      2\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m      3\u001b[0m     train_dataloader\u001b[38;5;241m=\u001b[39mtrain_loader,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;66;03m# but seeding will affect.\u001b[39;00m\n\u001b[1;32m     13\u001b[0m )\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m DEBUG:\n\u001b[0;32m---> 16\u001b[0m     trained_model \u001b[38;5;241m=\u001b[39m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# or 15\u001b[39;00m\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;66;03m# torch.save(model.state_dict(), 'model_debug.pt')\u001b[39;00m\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;66;03m# model_debug = torch.load('./model_debug.pt')\u001b[39;00m\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;66;03m# if are_both_models_same(model.state_dict(), model_debug):\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     23\u001b[0m \n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     25\u001b[0m     trained_model \u001b[38;5;241m=\u001b[39m trainer\u001b[38;5;241m.\u001b[39mfit(num_epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m30\u001b[39m)\n",
      "File \u001b[0;32m~/omniverse/omniverse/omnivault/transformer/core/trainer.py:278\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[0;34m(self, num_epochs)\u001b[0m\n\u001b[1;32m    275\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_epochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    276\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m10\u001b[39m)\n\u001b[0;32m--> 278\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    279\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalid_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvalid_epoch()\n\u001b[1;32m    281\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining Loss   : \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_loss\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.5f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/omniverse/omniverse/omnivault/transformer/core/trainer.py:243\u001b[0m, in \u001b[0;36mTrainer.train_epoch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    242\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain_epoch\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Loss:\n\u001b[0;32m--> 243\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrain_one_epoch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    244\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    245\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdataloader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_dataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    246\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    247\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    248\u001b[0m \u001b[43m        \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscheduler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    249\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrad_norm_clip\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgrad_norm_clip\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    250\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    251\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/omniverse/omniverse/omnivault/transformer/core/trainer.py:74\u001b[0m, in \u001b[0;36mtrain_one_epoch\u001b[0;34m(model, dataloader, criterion, optimizer, scheduler, grad_norm_clip, device)\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;66;03m# fmt: on\u001b[39;00m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _batch_index, batch \u001b[38;5;129;01min\u001b[39;00m progress_bar:\n\u001b[0;32m---> 74\u001b[0m     (\n\u001b[1;32m     75\u001b[0m         inputs,\n\u001b[1;32m     76\u001b[0m         targets,\n\u001b[1;32m     77\u001b[0m         target_padding_masks,\n\u001b[1;32m     78\u001b[0m         future_masks,\n\u001b[1;32m     79\u001b[0m     ) \u001b[38;5;241m=\u001b[39m batch  \u001b[38;5;66;03m# construct_batches(batch)\u001b[39;00m\n\u001b[1;32m     80\u001b[0m     inputs, targets, target_padding_masks, future_masks \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     81\u001b[0m         inputs\u001b[38;5;241m.\u001b[39mto(device),\n\u001b[1;32m     82\u001b[0m         targets\u001b[38;5;241m.\u001b[39mto(device),\n\u001b[1;32m     83\u001b[0m         target_padding_masks\u001b[38;5;241m.\u001b[39mto(device),\n\u001b[1;32m     84\u001b[0m         future_masks\u001b[38;5;241m.\u001b[39mto(device),\n\u001b[1;32m     85\u001b[0m     )\n\u001b[1;32m     86\u001b[0m     batch_size \u001b[38;5;241m=\u001b[39m inputs\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 4, got 2)"
     ]
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    train_dataloader=train_loader,\n",
    "    valid_dataloader=train_loader,\n",
    "    criterion=criterion,\n",
    "    optimizer=optimizer,\n",
    "    scheduler=scheduler,\n",
    "    grad_norm_clip=1.0,\n",
    "    device=DEVICE,\n",
    "    # test_dataloader=test_loader,\n",
    "    # NOTE: uncomment the above line to enable testing after each epoch\n",
    "    # but seeding will affect.\n",
    ")\n",
    "\n",
    "if DEBUG:\n",
    "    trained_model = trainer.fit(num_epochs=2) # or 15\n",
    "    # torch.save(model.state_dict(), 'model_debug.pt')\n",
    "    # model_debug = torch.load('./model_debug.pt')\n",
    "    # if are_both_models_same(model.state_dict(), model_debug):\n",
    "    #     print(\"Pass\")\n",
    "    # else:\n",
    "    #     print(\"Fail\")\n",
    "\n",
    "else:\n",
    "    trained_model = trainer.fit(num_epochs=30)\n",
    "\n",
    "    # torch.save(model.state_dict(), 'model_non_debug.pt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "omniverse",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
