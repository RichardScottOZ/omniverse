constants: null
global_:
  seed: 42
  debug: false
data:
  context_length: 128
  dataset_size: null
  dataset_path: ./data/tinyshakespeare/input.txt
  dataset_url: https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt
  split: null
  collate_fn: null
  train_loader:
    batch_size: 128
    shuffle: true
    num_workers: 0
    pin_memory: false
    drop_last: false
  val_loader: null
  test_loader: null
optimizer:
  name: "torch.optim.Adam"
  lr: 0.2
  betas:
    - 0.9
    - 0.98
  eps: 1e-9
criterion:
  name: "torch.nn.CrossEntropyLoss"
  reduction: "mean"
model:
  d_model: 128
  vocab_size: ??? # MISSING so need fill up later
  context_length: ${data.context_length}
  num_decoder_blocks: 2
  dropout: 0.1
  decoder_block:
    masked_self_attention_mha:
      attention:
        _target_: omnivault.transformer.modules.attention.core.ScaledDotProductAttention
      d_model: ${model.d_model}
      H: 4
      dropout: 0.1
    feed_forward:
      d_model: ${model.d_model}
      d_ff: 256
      activation:
        _target_: torch.nn.GELU
        approximate: "tanh"
      dropout: 0.1
      bias: true
    add_norm_1:
      feature_dim: ${model.d_model}
      dropout: 0.1
    add_norm_2:
      feature_dim: ${model.d_model}
      dropout: 0.1
trainer:
  device: "auto"
  num_epochs: 5