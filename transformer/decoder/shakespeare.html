

<!DOCTYPE html>


<html lang="en" data-content_root="" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

    <title>Shakespeare &#8212; Omniverse</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../../_static/styles/theme.css?digest=8d27b9dea8ad943066ae" rel="stylesheet" />
<link href="../../_static/styles/bootstrap.css?digest=8d27b9dea8ad943066ae" rel="stylesheet" />
<link href="../../_static/styles/pydata-sphinx-theme.css?digest=8d27b9dea8ad943066ae" rel="stylesheet" />

  
  <link href="../../_static/vendor/fontawesome/6.5.1/css/all.min.css?digest=8d27b9dea8ad943066ae" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.5.1/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.5.1/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../_static/vendor/fontawesome/6.5.1/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css" />
    <link rel="stylesheet" href="../../_static/styles/sphinx-book-theme.css?digest=14f4ca6b54d191a8c7657f6c759bf11a5fb86285" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/proof.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/custom.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/design-style.4045f2051d55cab465a707391d5b2007.min.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../_static/scripts/bootstrap.js?digest=8d27b9dea8ad943066ae" />
<link rel="preload" as="script" href="../../_static/scripts/pydata-sphinx-theme.js?digest=8d27b9dea8ad943066ae" />
  <script src="../../_static/vendor/fontawesome/6.5.1/js/all.min.js?digest=8d27b9dea8ad943066ae"></script>

    <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/clipboard.min.js"></script>
    <script src="../../_static/copybutton.js"></script>
    <script src="../../_static/scripts/sphinx-book-theme.js?digest=5a5c038af52cf7bc1a1ec88eea08e6366ee68824"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../../_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../../_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../../_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'transformer/decoder/shakespeare';</script>
    <link rel="canonical" href="https://www.gaohongnan.com/transformer/decoder/shakespeare.html" />
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="Training Chronicles" href="../../deep_learning/training_chronicles/intro.html" />
    <link rel="prev" title="Concept" href="../concept.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a id="pst-skip-link" class="skip-link" href="#main-content">Skip to main content</a>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>
    Back to top
  </button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search..."
         aria-label="Search..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <header class="bd-header navbar navbar-expand-lg bd-navbar">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  

<a class="navbar-brand logo" href="../../intro.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../../_static/logo.png" class="logo__image only-light" alt="Omniverse - Home"/>
    <script>document.write(`<img src="../../_static/logo.png" class="logo__image only-dark" alt="Omniverse - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item"><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">Transformers - Attention is All You Need</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../intro.html">Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="../notations.html">Notations</a></li>
<li class="toctree-l1"><a class="reference internal" href="../concept.html">Concept</a></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#">Shakespeare</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Deep Learning</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../../deep_learning/training_chronicles/intro.html">Training Chronicles</a><input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-1"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../deep_learning/training_chronicles/loss.html">The Loss Landscape</a></li>
</ul>
</li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Software Engineering</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../software_engineering/devops/continuous-integration/styling.html">Styling, Formatting, and Linting</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../software_engineering/design_patterns/dependency-inversion-principle.html">Dependency Inversion Principle</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../software_engineering/concurrency_parallelism_asynchronous/intro.html">Concurrency, Parallelism and Asynchronous Programming</a><input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-2"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../software_engineering/concurrency_parallelism_asynchronous/generator_yield.html">A Rudimentary Introduction to Generator and Yield in Python</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../software_engineering/serving/restful_api/intro.html">RESTful API</a><input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-3"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../software_engineering/serving/restful_api/application_banking.html">Application: Designing a RESTful Banking API with FastAPI and SQLAlchemy</a></li>
</ul>
</li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Computer Science</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../../computer_science/type_theory/intro.html">Type Theory, A Very Rudimentary Introduction</a><input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-4"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../computer_science/type_theory/01-subtypes.html">Subtypes</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../computer_science/type_theory/02-type-safety.html">Type Safety</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../computer_science/type_theory/03-subsumption.html">Subsumption</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../computer_science/type_theory/04-generics.html">Generics and Type Variables</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../computer_science/type_theory/05-typevar-bound-constraints.html">Bound and Constraint in Generics and Type Variables</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../computer_science/type_theory/06-invariance-covariance-contravariance.html">Invariance, Covariance and Contravariance</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../computer_science/type_theory/07-pep-3124-overloading.html">Function Overloading</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../computer_science/type_theory/08-pep-661-sentinel-values.html">Sentinel Types</a></li>
</ul>
</li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Data Structures and Algorithms</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../../dsa/complexity_analysis/intro.html">Complexity Analysis</a><input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-5"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../dsa/complexity_analysis/master_theorem.html">Master Theorem </a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../dsa/stack/intro.html">Stack</a><input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-6"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../dsa/stack/concept.html">Concept</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../dsa/searching_algorithms/linear_search/intro.html">Linear Search</a><input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-7"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../dsa/searching_algorithms/linear_search/concept.html">Concept</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../dsa/searching_algorithms/binary_search/intro.html">Binary Search</a><input class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-8"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../dsa/searching_algorithms/binary_search/concept.html">Concept</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../dsa/searching_algorithms/binary_search/problems/875-koko-eating-bananas.html">Koko Eating Bananas</a></li>
</ul>
</li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Linear Algebra</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../../linear_algebra/01_preliminaries/intro.html">Preliminaries</a><input class="toctree-checkbox" id="toctree-checkbox-9" name="toctree-checkbox-9" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-9"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../linear_algebra/01_preliminaries/01-fields.html">Fields</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../linear_algebra/01_preliminaries/02-systems-of-linear-equations.html">Systems of Linear Equations</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../linear_algebra/02_vectors/intro.html">Vectors</a><input class="toctree-checkbox" id="toctree-checkbox-10" name="toctree-checkbox-10" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-10"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../linear_algebra/02_vectors/01-vector-definition.html">Vector and Its Definition</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../linear_algebra/02_vectors/02-vector-operation.html">Vector and Its Operations</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../linear_algebra/02_vectors/03-vector-norm.html">Vector Norm and Distance</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../linear_algebra/02_vectors/04-vector-products.html">A First Look at Vector Products</a></li>
</ul>
</li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">References, Resources and Roadmap</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../bibliography.html">Bibliography</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../../_sources/transformer/decoder/shakespeare.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm navbar-btn theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch nav-link" data-mode="light"><i class="fa-solid fa-sun fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="dark"><i class="fa-solid fa-moon fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="auto"><i class="fa-solid fa-circle-half-stroke fa-lg"></i></span>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary"title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</label>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Shakespeare</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#composing-the-configurations">Composing the Configurations</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#reproducibility">Reproducibility</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#tokenization-and-vocabulary">Tokenization and Vocabulary</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#stoi-todo">STOI (TODO)</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#dataset-and-dataloading-poor-man-s-dataloader">Dataset and Dataloading (Poor Man’s Dataloader)</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#memory-mapping">Memory Mapping</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#notation-context-length-shuffling-and-batching">Notation, Context Length, Shuffling and Batching</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#notation">Notation</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#context-length-block-size">Context Length / Block Size</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#shuffling-and-discrete-uniform-sampling">Shuffling and Discrete Uniform Sampling</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#batching">Batching</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#construction-of-input-and-target-sequences">Construction of Input and Target Sequences</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#asynchronous-data-loading-and-prefetching">Asynchronous Data Loading and Prefetching</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#collating-everything-together">Collating Everything Together</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#using-pytorch-s-dataset-and-dataloader">Using PyTorch’s Dataset and Dataloader</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#generative-pre-trained-transformer-gpt">Generative Pre-trained Transformer (GPT)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#token-embeddings">Token Embeddings</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#lookup-operation">Lookup Operation</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#token-embedding-matrix">Token Embedding Matrix</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#representation-mapping">Representation Mapping</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#one-hot-encoding-and-embedding-matrix">One-Hot Encoding and Embedding Matrix</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#positional-embeddings">Positional Embeddings</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#self-attention-and-masked-self-attention">Self-Attention and Masked Self-Attention</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#conditional-probability">Conditional Probability</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#joint-probability">Joint Probability</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="shakespeare">
<h1>Shakespeare<a class="headerlink" href="#shakespeare" title="Permalink to this heading">#</a></h1>
<nav class="contents local" id="contents">
<ul class="simple">
<li><p><a class="reference internal" href="#composing-the-configurations" id="id11">Composing the Configurations</a></p></li>
<li><p><a class="reference internal" href="#reproducibility" id="id12">Reproducibility</a></p></li>
<li><p><a class="reference internal" href="#tokenization-and-vocabulary" id="id13">Tokenization and Vocabulary</a></p>
<ul>
<li><p><a class="reference internal" href="#stoi-todo" id="id14">STOI (TODO)</a></p></li>
</ul>
</li>
<li><p><a class="reference internal" href="#dataset-and-dataloading-poor-man-s-dataloader" id="id15">Dataset and Dataloading (Poor Man’s Dataloader)</a></p>
<ul>
<li><p><a class="reference internal" href="#memory-mapping" id="id16">Memory Mapping</a></p></li>
<li><p><a class="reference internal" href="#notation-context-length-shuffling-and-batching" id="id17">Notation, Context Length, Shuffling and Batching</a></p>
<ul>
<li><p><a class="reference internal" href="#notation" id="id18">Notation</a></p></li>
<li><p><a class="reference internal" href="#context-length-block-size" id="id19">Context Length / Block Size</a></p></li>
<li><p><a class="reference internal" href="#shuffling-and-discrete-uniform-sampling" id="id20">Shuffling and Discrete Uniform Sampling</a></p></li>
<li><p><a class="reference internal" href="#batching" id="id21">Batching</a></p></li>
</ul>
</li>
<li><p><a class="reference internal" href="#construction-of-input-and-target-sequences" id="id22">Construction of Input and Target Sequences</a></p></li>
<li><p><a class="reference internal" href="#asynchronous-data-loading-and-prefetching" id="id23">Asynchronous Data Loading and Prefetching</a></p></li>
<li><p><a class="reference internal" href="#collating-everything-together" id="id24">Collating Everything Together</a></p></li>
<li><p><a class="reference internal" href="#using-pytorch-s-dataset-and-dataloader" id="id25">Using PyTorch’s Dataset and Dataloader</a></p></li>
</ul>
</li>
<li><p><a class="reference internal" href="#generative-pre-trained-transformer-gpt" id="id26">Generative Pre-trained Transformer (GPT)</a></p></li>
<li><p><a class="reference internal" href="#token-embeddings" id="id27">Token Embeddings</a></p>
<ul>
<li><p><a class="reference internal" href="#lookup-operation" id="id28">Lookup Operation</a></p></li>
<li><p><a class="reference internal" href="#token-embedding-matrix" id="id29">Token Embedding Matrix</a></p></li>
<li><p><a class="reference internal" href="#representation-mapping" id="id30">Representation Mapping</a></p></li>
<li><p><a class="reference internal" href="#one-hot-encoding-and-embedding-matrix" id="id31">One-Hot Encoding and Embedding Matrix</a></p></li>
</ul>
</li>
<li><p><a class="reference internal" href="#positional-embeddings" id="id32">Positional Embeddings</a></p></li>
<li><p><a class="reference internal" href="#self-attention-and-masked-self-attention" id="id33">Self-Attention and Masked Self-Attention</a></p></li>
<li><p><a class="reference internal" href="#conditional-probability" id="id34">Conditional Probability</a></p></li>
<li><p><a class="reference internal" href="#joint-probability" id="id35">Joint Probability</a></p></li>
</ul>
</nav>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">__future__</span> <span class="kn">import</span> <span class="n">annotations</span>

<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">time</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">from</span> <span class="nn">pathlib</span> <span class="kn">import</span> <span class="n">Path</span>
<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">Any</span><span class="p">,</span> <span class="n">Dict</span><span class="p">,</span> <span class="n">List</span><span class="p">,</span> <span class="n">Literal</span><span class="p">,</span> <span class="n">Tuple</span><span class="p">,</span> <span class="n">Union</span>

<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">numpy.typing</span> <span class="kn">import</span> <span class="n">ArrayLike</span><span class="p">,</span> <span class="n">NDArray</span>
<span class="kn">import</span> <span class="nn">requests</span>
<span class="kn">import</span> <span class="nn">tiktoken</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">rich.pretty</span> <span class="kn">import</span> <span class="n">pprint</span>
<span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">nn</span>
<span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">DataLoader</span><span class="p">,</span> <span class="n">Dataset</span>
<span class="kn">import</span> <span class="nn">os</span>
<span class="kn">import</span> <span class="nn">random</span>
<span class="kn">import</span> <span class="nn">warnings</span>

<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.nn.functional</span> <span class="k">as</span> <span class="nn">F</span>
<span class="kn">import</span> <span class="nn">torch.backends.cudnn</span>

<span class="kn">from</span> <span class="nn">pydantic</span> <span class="kn">import</span> <span class="n">BaseModel</span><span class="p">,</span> <span class="n">Field</span><span class="p">,</span> <span class="n">model_validator</span><span class="p">,</span> <span class="n">computed_field</span>
</pre></div>
</div>
</div>
</div>
<section id="composing-the-configurations">
<h2><a class="toc-backref" href="#id11" role="doc-backlink">Composing the Configurations</a><a class="headerlink" href="#composing-the-configurations" title="Permalink to this heading">#</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">Composer</span><span class="p">(</span><span class="n">BaseModel</span><span class="p">):</span>
    <span class="n">seed</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">2024</span>
    <span class="n">debug</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span>

    <span class="n">url</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt&quot;</span>
    <span class="n">dataset_name</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="s2">&quot;tinyshakespeare&quot;</span>
    <span class="n">data_folder</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="n">Field</span><span class="p">(</span><span class="n">default</span><span class="o">=</span><span class="s2">&quot;./data/tinyshakespeare&quot;</span><span class="p">,</span> <span class="n">description</span><span class="o">=</span><span class="s2">&quot;Path to the data folder&quot;</span><span class="p">)</span>

    <span class="n">train_path</span><span class="p">:</span> <span class="n">Path</span> <span class="o">=</span> <span class="n">Field</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="n">description</span><span class="o">=</span><span class="s2">&quot;Path to the train file&quot;</span><span class="p">)</span>
    <span class="n">valid_path</span><span class="p">:</span> <span class="n">Path</span> <span class="o">=</span> <span class="n">Field</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="n">description</span><span class="o">=</span><span class="s2">&quot;Path to the valid file&quot;</span><span class="p">)</span>

    <span class="n">encoding_name</span><span class="p">:</span> <span class="n">Literal</span><span class="p">[</span><span class="s1">&#39;gpt2&#39;</span><span class="p">,</span> <span class="s1">&#39;r50k_base&#39;</span><span class="p">,</span> <span class="s1">&#39;p50k_base&#39;</span><span class="p">,</span> <span class="s1">&#39;p50k_edit&#39;</span><span class="p">,</span> <span class="s1">&#39;cl100k_base&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;gpt2&quot;</span>

    <span class="n">batch_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="n">Field</span><span class="p">(</span><span class="n">default</span><span class="o">=</span><span class="mi">64</span><span class="p">,</span> <span class="n">description</span><span class="o">=</span><span class="s2">&quot;Batch size&quot;</span><span class="p">)</span>
    <span class="n">block_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="n">Field</span><span class="p">(</span><span class="n">default</span><span class="o">=</span><span class="mi">128</span><span class="p">,</span> <span class="n">description</span><span class="o">=</span><span class="s2">&quot;Block size, an alias for max length/context window size.&quot;</span><span class="p">,</span> <span class="n">alias</span><span class="o">=</span><span class="s2">&quot;context_length&quot;</span><span class="p">)</span>
    <span class="n">device_type</span><span class="p">:</span> <span class="n">Literal</span><span class="p">[</span><span class="s2">&quot;cpu&quot;</span><span class="p">,</span> <span class="s2">&quot;cuda&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;cpu&quot;</span>
    <span class="n">device</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span> <span class="o">=</span> <span class="n">Field</span><span class="p">(</span><span class="kc">None</span><span class="p">,</span> <span class="n">description</span><span class="o">=</span><span class="s2">&quot;Device to use&quot;</span><span class="p">)</span>

    <span class="c1"># model parameters</span>
    <span class="n">d_model</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="n">Field</span><span class="p">(</span><span class="n">default</span><span class="o">=</span><span class="mi">512</span><span class="p">,</span> <span class="n">description</span><span class="o">=</span><span class="s2">&quot;Dimension of the model&quot;</span><span class="p">)</span>
    <span class="n">d_ff</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="n">Field</span><span class="p">(</span><span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">description</span><span class="o">=</span><span class="s2">&quot;Dimension of the feed forward layer&quot;</span><span class="p">)</span>
    <span class="n">H</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="n">Field</span><span class="p">(</span><span class="n">default</span><span class="o">=</span><span class="mi">8</span><span class="p">,</span> <span class="n">description</span><span class="o">=</span><span class="s2">&quot;Number of heads&quot;</span><span class="p">,</span> <span class="n">alias</span><span class="o">=</span><span class="s2">&quot;num_heads&quot;</span><span class="p">)</span>
    <span class="n">vocab_size</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="n">Field</span><span class="p">(</span><span class="n">default</span><span class="o">=</span><span class="mi">50257</span><span class="p">,</span> <span class="n">description</span><span class="o">=</span><span class="s2">&quot;Vocabulary size&quot;</span><span class="p">)</span>
    <span class="n">num_decoder_blocks</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="n">Field</span><span class="p">(</span><span class="n">default</span><span class="o">=</span><span class="mi">6</span><span class="p">,</span> <span class="n">description</span><span class="o">=</span><span class="s2">&quot;Number of decoder blocks&quot;</span><span class="p">)</span>


    <span class="nd">@model_validator</span><span class="p">(</span><span class="n">mode</span><span class="o">=</span><span class="s2">&quot;after&quot;</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">set_train_valid_paths</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Composer</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">train_path</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">data_folder</span><span class="p">)</span> <span class="o">/</span> <span class="s2">&quot;train.txt&quot;</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">valid_path</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">data_folder</span><span class="p">)</span> <span class="o">/</span> <span class="s2">&quot;valid.txt&quot;</span>
        <span class="k">return</span> <span class="bp">self</span>

    <span class="nd">@model_validator</span><span class="p">(</span><span class="n">mode</span><span class="o">=</span><span class="s2">&quot;after&quot;</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">set_device</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Composer</span><span class="p">:</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">device</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">device_type</span><span class="p">)</span>
        <span class="k">return</span> <span class="bp">self</span>

    <span class="nd">@model_validator</span><span class="p">(</span><span class="n">mode</span><span class="o">=</span><span class="s2">&quot;after&quot;</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">set_debug_fields</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Composer</span><span class="p">:</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">debug</span><span class="p">:</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">batch_size</span> <span class="o">=</span> <span class="mi">2</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">block_size</span> <span class="o">=</span> <span class="mi">8</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">d_model</span> <span class="o">=</span> <span class="mi">4</span>
        <span class="k">return</span> <span class="bp">self</span>

    <span class="k">class</span> <span class="nc">Config</span><span class="p">:</span>
        <span class="n">extra</span> <span class="o">=</span> <span class="s2">&quot;forbid&quot;</span>
        <span class="n">arbitrary_types_allowed</span> <span class="o">=</span> <span class="kc">True</span>

<span class="n">composer</span> <span class="o">=</span> <span class="n">Composer</span><span class="p">(</span><span class="n">debug</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="n">pprint</span><span class="p">(</span><span class="n">composer</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace"><span style="color: #800080; text-decoration-color: #800080; font-weight: bold">Composer</span><span style="font-weight: bold">(</span>
<span style="color: #7fbf7f; text-decoration-color: #7fbf7f">│   </span><span style="color: #808000; text-decoration-color: #808000">seed</span>=<span style="color: #008080; text-decoration-color: #008080; font-weight: bold">2024</span>,
<span style="color: #7fbf7f; text-decoration-color: #7fbf7f">│   </span><span style="color: #808000; text-decoration-color: #808000">debug</span>=<span style="color: #00ff00; text-decoration-color: #00ff00; font-style: italic">True</span>,
<span style="color: #7fbf7f; text-decoration-color: #7fbf7f">│   </span><span style="color: #808000; text-decoration-color: #808000">url</span>=<span style="color: #008000; text-decoration-color: #008000">'https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt'</span>,
<span style="color: #7fbf7f; text-decoration-color: #7fbf7f">│   </span><span style="color: #808000; text-decoration-color: #808000">dataset_name</span>=<span style="color: #008000; text-decoration-color: #008000">'tinyshakespeare'</span>,
<span style="color: #7fbf7f; text-decoration-color: #7fbf7f">│   </span><span style="color: #808000; text-decoration-color: #808000">data_folder</span>=<span style="color: #008000; text-decoration-color: #008000">'./data/tinyshakespeare'</span>,
<span style="color: #7fbf7f; text-decoration-color: #7fbf7f">│   </span><span style="color: #808000; text-decoration-color: #808000">train_path</span>=<span style="color: #800080; text-decoration-color: #800080; font-weight: bold">PosixPath</span><span style="font-weight: bold">(</span><span style="color: #008000; text-decoration-color: #008000">'data/tinyshakespeare/train.txt'</span><span style="font-weight: bold">)</span>,
<span style="color: #7fbf7f; text-decoration-color: #7fbf7f">│   </span><span style="color: #808000; text-decoration-color: #808000">valid_path</span>=<span style="color: #800080; text-decoration-color: #800080; font-weight: bold">PosixPath</span><span style="font-weight: bold">(</span><span style="color: #008000; text-decoration-color: #008000">'data/tinyshakespeare/valid.txt'</span><span style="font-weight: bold">)</span>,
<span style="color: #7fbf7f; text-decoration-color: #7fbf7f">│   </span><span style="color: #808000; text-decoration-color: #808000">encoding_name</span>=<span style="color: #008000; text-decoration-color: #008000">'gpt2'</span>,
<span style="color: #7fbf7f; text-decoration-color: #7fbf7f">│   </span><span style="color: #808000; text-decoration-color: #808000">batch_size</span>=<span style="color: #008080; text-decoration-color: #008080; font-weight: bold">2</span>,
<span style="color: #7fbf7f; text-decoration-color: #7fbf7f">│   </span><span style="color: #808000; text-decoration-color: #808000">block_size</span>=<span style="color: #008080; text-decoration-color: #008080; font-weight: bold">8</span>,
<span style="color: #7fbf7f; text-decoration-color: #7fbf7f">│   </span><span style="color: #808000; text-decoration-color: #808000">device_type</span>=<span style="color: #008000; text-decoration-color: #008000">'cpu'</span>,
<span style="color: #7fbf7f; text-decoration-color: #7fbf7f">│   </span><span style="color: #808000; text-decoration-color: #808000">device</span>=<span style="color: #800080; text-decoration-color: #800080; font-weight: bold">device</span><span style="font-weight: bold">(</span><span style="color: #808000; text-decoration-color: #808000">type</span>=<span style="color: #008000; text-decoration-color: #008000">'cpu'</span><span style="font-weight: bold">)</span>,
<span style="color: #7fbf7f; text-decoration-color: #7fbf7f">│   </span><span style="color: #808000; text-decoration-color: #808000">d_model</span>=<span style="color: #008080; text-decoration-color: #008080; font-weight: bold">4</span>,
<span style="color: #7fbf7f; text-decoration-color: #7fbf7f">│   </span><span style="color: #808000; text-decoration-color: #808000">d_ff</span>=<span style="color: #800080; text-decoration-color: #800080; font-style: italic">None</span>,
<span style="color: #7fbf7f; text-decoration-color: #7fbf7f">│   </span><span style="color: #808000; text-decoration-color: #808000">H</span>=<span style="color: #008080; text-decoration-color: #008080; font-weight: bold">8</span>,
<span style="color: #7fbf7f; text-decoration-color: #7fbf7f">│   </span><span style="color: #808000; text-decoration-color: #808000">vocab_size</span>=<span style="color: #008080; text-decoration-color: #008080; font-weight: bold">50257</span>,
<span style="color: #7fbf7f; text-decoration-color: #7fbf7f">│   </span><span style="color: #808000; text-decoration-color: #808000">num_decoder_blocks</span>=<span style="color: #008080; text-decoration-color: #008080; font-weight: bold">6</span>
<span style="font-weight: bold">)</span>
</pre>
</div></div>
</div>
</section>
<section id="reproducibility">
<h2><a class="toc-backref" href="#id12" role="doc-backlink">Reproducibility</a><a class="headerlink" href="#reproducibility" title="Permalink to this heading">#</a></h2>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">configure_deterministic_mode</span><span class="p">()</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    See https://pytorch.org/docs/stable/generated/torch.use_deterministic_algorithms.html</span>
<span class="sd">    and https://docs.nvidia.com/cuda/cublas/index.html#cublasApi_reproducibility</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># fmt: off</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">use_deterministic_algorithms</span><span class="p">(</span><span class="kc">True</span><span class="p">,</span> <span class="n">warn_only</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">backends</span><span class="o">.</span><span class="n">cudnn</span><span class="o">.</span><span class="n">benchmark</span>        <span class="o">=</span> <span class="kc">False</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">backends</span><span class="o">.</span><span class="n">cudnn</span><span class="o">.</span><span class="n">deterministic</span>    <span class="o">=</span> <span class="kc">True</span>
    <span class="n">torch</span><span class="o">.</span><span class="n">backends</span><span class="o">.</span><span class="n">cudnn</span><span class="o">.</span><span class="n">enabled</span>          <span class="o">=</span> <span class="kc">False</span>

    <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s1">&#39;CUBLAS_WORKSPACE_CONFIG&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="s1">&#39;:4096:8&#39;</span>
    <span class="c1"># fmt: on</span>
    <span class="n">warnings</span><span class="o">.</span><span class="n">warn</span><span class="p">(</span>
        <span class="s2">&quot;Deterministic mode is activated. This will negatively impact performance and may cause increase in CUDA memory footprint.&quot;</span><span class="p">,</span>
        <span class="n">category</span><span class="o">=</span><span class="ne">UserWarning</span><span class="p">,</span>
        <span class="n">stacklevel</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
    <span class="p">)</span>


<span class="k">def</span> <span class="nf">seed_all</span><span class="p">(</span>
    <span class="n">seed</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">1992</span><span class="p">,</span>
    <span class="n">seed_torch</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
    <span class="n">set_torch_deterministic</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">True</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Seed all random number generators.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    seed : int</span>
<span class="sd">        Seed number to be used, by default 1992.</span>
<span class="sd">    seed_torch : bool</span>
<span class="sd">        Whether to seed PyTorch or not, by default True.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    seed: int</span>
<span class="sd">        The seed number.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="c1"># fmt: off</span>
    <span class="n">os</span><span class="o">.</span><span class="n">environ</span><span class="p">[</span><span class="s2">&quot;PYTHONHASHSEED&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="nb">str</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>       <span class="c1"># set PYTHONHASHSEED env var at fixed value</span>
    <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">default_rng</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>                    <span class="c1"># numpy pseudo-random generator</span>
    <span class="n">random</span><span class="o">.</span><span class="n">seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>                              <span class="c1"># python&#39;s built-in pseudo-random generator</span>

    <span class="k">if</span> <span class="n">seed_torch</span><span class="p">:</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">cuda</span><span class="o">.</span><span class="n">manual_seed_all</span><span class="p">(</span><span class="n">seed</span><span class="p">)</span>           <span class="c1"># pytorch (both CPU and CUDA)</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">backends</span><span class="o">.</span><span class="n">cudnn</span><span class="o">.</span><span class="n">deterministic</span> <span class="o">=</span> <span class="kc">True</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">backends</span><span class="o">.</span><span class="n">cudnn</span><span class="o">.</span><span class="n">benchmark</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="n">torch</span><span class="o">.</span><span class="n">backends</span><span class="o">.</span><span class="n">cudnn</span><span class="o">.</span><span class="n">enabled</span> <span class="o">=</span> <span class="kc">False</span>

        <span class="k">if</span> <span class="n">set_torch_deterministic</span><span class="p">:</span>
            <span class="n">configure_deterministic_mode</span><span class="p">()</span>
    <span class="c1"># fmt: on</span>
    <span class="k">return</span> <span class="n">seed</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">seed_all</span><span class="p">(</span><span class="n">composer</span><span class="o">.</span><span class="n">seed</span><span class="p">,</span> <span class="n">seed_torch</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">set_torch_deterministic</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2024
</pre></div>
</div>
</div>
</div>
</section>
<section id="tokenization-and-vocabulary">
<h2><a class="toc-backref" href="#id13" role="doc-backlink">Tokenization and Vocabulary</a><a class="headerlink" href="#tokenization-and-vocabulary" title="Permalink to this heading">#</a></h2>
<ul class="simple">
<li><p><a class="reference external" href="https://huggingface.co/learn/nlp-course/chapter2/4?fw=pt">https://huggingface.co/learn/nlp-course/chapter2/4?fw=pt</a></p></li>
<li><p><a class="github reference external" href="https://github.com/openai/tiktoken">openai/tiktoken</a></p></li>
<li><p><a class="github reference external" href="https://github.com/openai/openai-cookbook/blob/main/examples/How_to_count_tokens_with_tiktoken.ipynb">openai/openai-cookbook</a></p></li>
</ul>
<p>Language models don’t see text like you and I, instead they see a sequence of numbers (known as tokens). Byte pair encoding (BPE) is a way of converting text into tokens. It has a couple desirable properties<a class="footnote-reference brackets" href="#id9" id="id1" role="doc-noteref"><span class="fn-bracket">[</span>1<span class="fn-bracket">]</span></a>:</p>
<ul class="simple">
<li><p>It’s reversible and lossless, so you can convert tokens back into the original text</p></li>
<li><p>It works on arbitrary text, even text that is not in the tokeniser’s training data</p></li>
<li><p>It compresses the text: the token sequence is shorter than the bytes corresponding to the original text. On average, in practice, each token corresponds to about 4 bytes.</p></li>
<li><p>It attempts to let the model see common subwords. For instance, “ing” is a common subword in English, so BPE encodings will often split “encoding” into tokens like “encod” and “ing” (instead of e.g. “enc” and “oding”). Because the model will then see the “ing” token again and again in different contexts, it helps models generalise and better understand grammar.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">am_i_in_jupyter</span><span class="p">()</span> <span class="o">-&gt;</span> <span class="nb">bool</span><span class="p">:</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="kn">from</span> <span class="nn">IPython</span> <span class="kn">import</span> <span class="n">get_ipython</span>
        <span class="k">if</span> <span class="s2">&quot;IPKernelApp&quot;</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">get_ipython</span><span class="p">()</span><span class="o">.</span><span class="n">config</span><span class="p">:</span>
            <span class="k">return</span> <span class="kc">False</span>
    <span class="k">except</span> <span class="ne">ImportError</span><span class="p">:</span>
        <span class="k">return</span> <span class="kc">False</span>
    <span class="k">return</span> <span class="kc">True</span>

<span class="n">IN_JUPYTER</span> <span class="o">=</span> <span class="n">am_i_in_jupyter</span><span class="p">()</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">download</span><span class="p">(</span><span class="n">url</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">dataset_name</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">dest_folder</span><span class="p">:</span> <span class="n">Path</span> <span class="o">|</span> <span class="nb">str</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Path</span><span class="p">:</span>
    <span class="n">dest_folder_path</span> <span class="o">=</span> <span class="n">Path</span><span class="p">(</span><span class="n">dest_folder</span><span class="p">)</span>

    <span class="n">dest_folder_path</span><span class="o">.</span><span class="n">mkdir</span><span class="p">(</span><span class="n">parents</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span> <span class="n">exist_ok</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>

    <span class="n">filepath</span> <span class="o">=</span> <span class="n">dest_folder_path</span> <span class="o">/</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">dataset_name</span><span class="si">}</span><span class="s2">.txt&quot;</span>

    <span class="n">response</span> <span class="o">=</span> <span class="n">requests</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">url</span><span class="p">,</span> <span class="n">stream</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="n">corpus</span> <span class="o">=</span> <span class="n">response</span><span class="o">.</span><span class="n">text</span>
    <span class="n">response</span><span class="o">.</span><span class="n">raise_for_status</span><span class="p">()</span>

    <span class="k">with</span> <span class="nb">open</span><span class="p">(</span><span class="n">filepath</span><span class="p">,</span> <span class="s2">&quot;wb&quot;</span><span class="p">)</span> <span class="k">as</span> <span class="n">f</span><span class="p">:</span>
        <span class="k">for</span> <span class="n">chunk</span> <span class="ow">in</span> <span class="n">response</span><span class="o">.</span><span class="n">iter_content</span><span class="p">(</span><span class="n">chunk_size</span><span class="o">=</span><span class="mi">8192</span><span class="p">):</span>
            <span class="n">f</span><span class="o">.</span><span class="n">write</span><span class="p">(</span><span class="n">chunk</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">filepath</span><span class="p">,</span> <span class="n">corpus</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">filepath</span><span class="p">,</span> <span class="n">corpus</span> <span class="o">=</span> <span class="n">download</span><span class="p">(</span><span class="n">composer</span><span class="o">.</span><span class="n">url</span><span class="p">,</span> <span class="n">composer</span><span class="o">.</span><span class="n">dataset_name</span><span class="p">,</span> <span class="n">composer</span><span class="o">.</span><span class="n">data_folder</span><span class="p">)</span>
<span class="n">pprint</span><span class="p">(</span><span class="n">filepath</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">corpus</span><span class="p">[:</span><span class="mi">100</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace"><span style="color: #800080; text-decoration-color: #800080; font-weight: bold">PosixPath</span><span style="font-weight: bold">(</span><span style="color: #008000; text-decoration-color: #008000">'data/tinyshakespeare/tinyshakespeare.txt'</span><span style="font-weight: bold">)</span>
</pre>
</div><div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>First Citizen:
Before we proceed any further, hear me speak.

All:
Speak, speak.

First Citizen:
You
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">N</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">corpus</span><span class="p">)</span>
<span class="n">train_data</span> <span class="o">=</span> <span class="n">corpus</span><span class="p">[:</span> <span class="nb">int</span><span class="p">(</span><span class="n">N</span> <span class="o">*</span> <span class="mf">0.9</span><span class="p">)]</span>
<span class="n">valid_data</span> <span class="o">=</span> <span class="n">corpus</span><span class="p">[</span><span class="nb">int</span><span class="p">(</span><span class="n">N</span> <span class="o">*</span> <span class="mf">0.9</span><span class="p">)</span> <span class="p">:]</span>

<span class="c1"># encode with tiktoken gpt2 bpe</span>
<span class="n">tokenizer</span> <span class="o">=</span> <span class="n">tiktoken</span><span class="o">.</span><span class="n">get_encoding</span><span class="p">(</span><span class="n">composer</span><span class="o">.</span><span class="n">encoding_name</span><span class="p">)</span>
<span class="n">tiktoken</span><span class="o">.</span><span class="n">list_encoding_names</span><span class="p">(),</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">n_vocab</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>([&#39;gpt2&#39;, &#39;r50k_base&#39;, &#39;p50k_base&#39;, &#39;p50k_edit&#39;, &#39;cl100k_base&#39;], 50257)
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">train_ids</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">encode_ordinary</span><span class="p">(</span><span class="n">train_data</span><span class="p">)</span>
<span class="n">valid_ids</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">encode_ordinary</span><span class="p">(</span><span class="n">valid_data</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;train has </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">train_ids</span><span class="p">)</span><span class="si">:</span><span class="s2">,</span><span class="si">}</span><span class="s2"> tokens&quot;</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;val has </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">valid_ids</span><span class="p">)</span><span class="si">:</span><span class="s2">,</span><span class="si">}</span><span class="s2"> tokens&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>train has 301,966 tokens
val has 36,059 tokens
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="n">train_ids</span><span class="p">[:</span><span class="mi">2</span><span class="p">]))</span>
<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;-&quot;</span> <span class="o">*</span> <span class="mi">80</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="n">train_ids</span><span class="p">[:</span><span class="mi">100</span><span class="p">]))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>First Citizen
--------------------------------------------------------------------------------
First Citizen:
Before we proceed any further, hear me speak.

All:
Speak, speak.

First Citizen:
You are all resolved rather to die than to famish?

All:
Resolved. resolved.

First Citizen:
First, you know Caius Marcius is chief enemy to the people.

All:
We know&#39;t, we know&#39;t.

First Citizen:
Let us kill him, and we
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># export to bin files</span>
<span class="n">train_ids</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">train_ids</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">uint16</span><span class="p">)</span>
<span class="n">valid_ids</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">valid_ids</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">uint16</span><span class="p">)</span>

<span class="n">train_ids</span><span class="o">.</span><span class="n">tofile</span><span class="p">(</span><span class="n">composer</span><span class="o">.</span><span class="n">train_path</span><span class="p">)</span>
<span class="n">valid_ids</span><span class="o">.</span><span class="n">tofile</span><span class="p">(</span><span class="n">composer</span><span class="o">.</span><span class="n">valid_path</span><span class="p">)</span>

<span class="c1"># train.bin has 301,966 tokens</span>
<span class="c1"># val.bin has 36,059 tokens</span>
</pre></div>
</div>
</div>
</div>
<section id="stoi-todo">
<h3><a class="toc-backref" href="#id14" role="doc-backlink">STOI (TODO)</a><a class="headerlink" href="#stoi-todo" title="Permalink to this heading">#</a></h3>
<ul class="simple">
<li><p>The first <code class="docutils literal notranslate"><span class="pre">input</span></code> is the sentence <code class="docutils literal notranslate"><span class="pre">hello</span> <span class="pre">bot</span></code>.</p></li>
<li><p>The tokenization is <code class="docutils literal notranslate"><span class="pre">[0,</span> <span class="pre">3,</span> <span class="pre">4,</span> <span class="pre">1]</span></code> which correctly maps to the tokens <code class="docutils literal notranslate"><span class="pre">[&lt;SOS&gt;,</span> <span class="pre">hello,</span> <span class="pre">bot,</span> <span class="pre">&lt;EOS&gt;]</span></code> as per the <code class="docutils literal notranslate"><span class="pre">stoi</span></code> mapping.</p></li>
<li><p>The shape is <code class="docutils literal notranslate"><span class="pre">[1,</span> <span class="pre">4]</span></code> because we have one sentence with 4 tokens, where the first token is the <code class="docutils literal notranslate"><span class="pre">&lt;SOS&gt;</span></code> token and the last token is the <code class="docutils literal notranslate"><span class="pre">&lt;EOS&gt;</span></code> token.</p>
<ul>
<li><p>In this context, the first dimension of the shape corresponds to the number of sentences (or samples) in the batch, and the second dimension corresponds to the number of tokens in each sentence.</p></li>
</ul>
</li>
</ul>
<hr class="docutils" />
<p>In mathematical terms, we have:</p>
<ul>
<li><p>The vocabulary <span class="math notranslate nohighlight">\(\mathcal{V}\)</span> consists of the unique tokens <span class="math notranslate nohighlight">\(\{\text{&lt;SOS&gt;, &lt;EOS&gt;, &lt;PAD&gt;, hello, bot, human}\}\)</span> in our text data. The size of the vocabulary is <span class="math notranslate nohighlight">\(V = |\mathcal{V}| = 6\)</span>.</p></li>
<li><p>We define a function <span class="math notranslate nohighlight">\(f_{\text{stoi}}\)</span> that maps each token in our vocabulary to a unique integer index.</p>
<div class="math notranslate nohighlight">
\[\begin{split}
  \begin{aligned}
  f_{\text{stoi}}: \mathcal{V} &amp;\to \{0, 1, ..., V-1\} \\
  v &amp;\mapsto f_{\text{stoi}}(v)
  \end{aligned}
  \end{split}\]</div>
<p>This function represents the <code class="docutils literal notranslate"><span class="pre">stoi</span></code> mapping in the code. For example, <span class="math notranslate nohighlight">\(f_{\text{stoi}}(\text{&lt;SOS&gt;}) = 0\)</span>, <span class="math notranslate nohighlight">\(f_{\text{stoi}}(\text{hello}) = 3\)</span>, etc.</p>
</li>
<li><p>A sequence of text, such as the sentence “hello bot”, is represented as a sequence of token indices <span class="math notranslate nohighlight">\(X=(x_1, x_2, x_3, x_4)\)</span> using the <span class="math notranslate nohighlight">\(f_{\text{stoi}}\)</span> mapping. For the sentence “hello bot”, we have:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
    \begin{aligned}
    \mathbf{X} &amp;= (f_{\text{stoi}}(\text{&lt;SOS&gt;}), f_{\text{stoi}}(\text{hello}), f_{{\text{stoi}}}(\text{bot}), f_{\text{stoi}}(\text{&lt;EOS&gt;})) \\
    &amp;= (0, 3, 4, 1)
    \end{aligned}
    \end{split}\]</div>
</li>
<li><p>Although <span class="math notranslate nohighlight">\(\mathbf{X}\)</span> is a sequence, we can consider it to be a vector:</p>
<div class="math notranslate nohighlight">
\[
    \mathbf{X} = \begin{bmatrix} 0 &amp; 3 &amp; 4 &amp; 1 \end{bmatrix} \in \mathbb{Z}^{1 \times 4}
    \]</div>
<p>which correctly corresponds to the shape <code class="docutils literal notranslate"><span class="pre">[1,</span> <span class="pre">4]</span></code> in the code.</p>
</li>
</ul>
</section>
</section>
<section id="dataset-and-dataloading-poor-man-s-dataloader">
<h2><a class="toc-backref" href="#id15" role="doc-backlink">Dataset and Dataloading (Poor Man’s Dataloader)</a><a class="headerlink" href="#dataset-and-dataloading-poor-man-s-dataloader" title="Permalink to this heading">#</a></h2>
<p><strong>TODO: to bridge the gap between the previous section and this one, we need to
explain why we need to construct a dataset.</strong></p>
<hr class="docutils" />
<p>As Karpathy puts it, he implemented a poor man’s
<a class="reference external" href="https://pytorch.org/tutorials/beginner/basics/data_tutorial.html">dataloader</a>.
We will start by dissecting the code and understanding how it works and finally,
show that everything can be done with PyTorch’s <code class="docutils literal notranslate"><span class="pre">Dataset</span></code> and <code class="docutils literal notranslate"><span class="pre">Dataloader</span></code>.</p>
<section id="memory-mapping">
<h3><a class="toc-backref" href="#id16" role="doc-backlink">Memory Mapping</a><a class="headerlink" href="#memory-mapping" title="Permalink to this heading">#</a></h3>
<p>Firstly, Karpathy uses <code class="docutils literal notranslate"><span class="pre">numpy</span></code>’s
<a class="reference external" href="https://numpy.org/doc/stable/reference/generated/numpy.memmap.html">memory mapping</a>
(<code class="docutils literal notranslate"><span class="pre">numpy.memmap</span></code>) to load the data. Memory mapping is used to create a
memory-mapped array from a binary file. This involves mapping the contents of a
file directly into the virtual memory space of the calling process. This allows
applications to access the file data as if it were loaded in memory, using
pointer operations or array indexing, without the need for explicit read or
write operations.</p>
<p>This essentially means that you can access small segments of a large file
without having to load the entire file into memory. The concept draws
similarities to the use of <a class="reference external" href="https://wiki.python.org/moin/Generators">generators</a>
in Python, where you can iterate over a large dataset without having to load the
entire dataset into memory.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">train_data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">memmap</span><span class="p">(</span><span class="n">composer</span><span class="o">.</span><span class="n">train_path</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">uint16</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s2">&quot;r&quot;</span><span class="p">)</span>
<span class="n">train_data_dtype</span> <span class="o">=</span> <span class="n">train_data</span><span class="o">.</span><span class="n">dtype</span>
<span class="n">train_data_shape</span> <span class="o">=</span> <span class="n">train_data</span><span class="o">.</span><span class="n">shape</span>

<span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;data_dtype: </span><span class="si">{</span><span class="n">train_data_dtype</span><span class="si">}</span><span class="s2">, data_shape: </span><span class="si">{</span><span class="n">train_data_shape</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>data_dtype: uint16, data_shape: (301966,)
</pre></div>
</div>
</div>
</div>
<p>We see that the shape of train data is <code class="docutils literal notranslate"><span class="pre">(301966,)</span></code>, which means that it is a 1D (flattened) array
with <span class="math notranslate nohighlight">\(301966\)</span> elements - this is basically the length of the entire train corpus, in terms of
tokens.</p>
</section>
<section id="notation-context-length-shuffling-and-batching">
<h3><a class="toc-backref" href="#id17" role="doc-backlink">Notation, Context Length, Shuffling and Batching</a><a class="headerlink" href="#notation-context-length-shuffling-and-batching" title="Permalink to this heading">#</a></h3>
<p>However, we are not going to pass the entire training corpus as is to the model.
Instead, we are going to pass a <strong>batch</strong> of sequences (each sequence of length
<code class="docutils literal notranslate"><span class="pre">context_length</span></code>) to the model at a time.</p>
<section id="notation">
<h4><a class="toc-backref" href="#id18" role="doc-backlink">Notation</a><a class="headerlink" href="#notation" title="Permalink to this heading">#</a></h4>
<p>Let’s consider a sequence <span class="math notranslate nohighlight">\(\mathbf{x} = (x_1, x_2, \ldots, x_T)\)</span>, where:</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(x_t\)</span> represents the <span class="math notranslate nohighlight">\(t\)</span>-th token in the sequence,</p></li>
<li><p>Each token <span class="math notranslate nohighlight">\(x_t\)</span> is an element of a predefined vocabulary <span class="math notranslate nohighlight">\(\mathcal{V} := \mathcal{X}\)</span>,</p></li>
<li><p><span class="math notranslate nohighlight">\(T\)</span> denotes the total number of tokens in the sequence, i.e., the sequence
length.</p></li>
</ul>
<p>In practice, we handle multiple sequences at once by grouping them into a batch.
This batch, denoted as <span class="math notranslate nohighlight">\(\mathcal{B}\)</span>, is then presented to the model for
parallel processing.</p>
<p>A batch of sequences is represented as a matrix <span class="math notranslate nohighlight">\(\mathbf{X}\)</span>, where each row
corresponds to a sequence in the batch. If the batch size is <span class="math notranslate nohighlight">\(\mathcal{B}\)</span> and
each sequence within the batch has a fixed length <span class="math notranslate nohighlight">\(T\)</span>, then <span class="math notranslate nohighlight">\(\mathbf{X}\)</span> can be
expressed as:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
    \mathbf{X} = \begin{bmatrix} x_{1,1} &amp; x_{1,2} &amp; \ldots &amp; x_{1,T} \\ x_{2,1}
        &amp; x_{2,2} &amp; \ldots &amp; x_{2,T} \\ \vdots &amp; \vdots &amp; \ddots &amp; \vdots \\ x_{\mathcal{B},1} &amp;
        x_{\mathcal{B},2} &amp; \ldots &amp; x_{\mathcal{B},T} \\\end{bmatrix} \in \mathbb{Z}^{\mathcal{B} \times T}
\end{split}\]</div>
<p>Here, <span class="math notranslate nohighlight">\(x_{i,j}\)</span> denotes the <span class="math notranslate nohighlight">\(j\)</span>-th token in the <span class="math notranslate nohighlight">\(i\)</span>-th sequence of the batch.
It’s important to note that while we represent the sequences in a real-valued
space <span class="math notranslate nohighlight">\(\mathbb{Z}^{\mathcal{B} \times T}\)</span> for mathematical convenience, in
practice, each <span class="math notranslate nohighlight">\(x_{i,j}\)</span> corresponds to a discrete token from the vocabulary
<span class="math notranslate nohighlight">\(\mathcal{X}\)</span> so using <span class="math notranslate nohighlight">\(\mathbb{Z}^{+}\)</span> would be more appropriate.</p>
</section>
<section id="context-length-block-size">
<h4><a class="toc-backref" href="#id19" role="doc-backlink">Context Length / Block Size</a><a class="headerlink" href="#context-length-block-size" title="Permalink to this heading">#</a></h4>
<p><span class="math notranslate nohighlight">\(T\)</span> is often referred to as the sequence length, or in the context of GPT, it is
the <code class="docutils literal notranslate"><span class="pre">block_size</span></code> or <code class="docutils literal notranslate"><span class="pre">context_length</span></code> or <code class="docutils literal notranslate"><span class="pre">max_seq_len</span></code>.</p>
<p>It is the length of the sequence that the model will be trained on and is also
the context length/context window that we often hear about.</p>
<p>For example,
<a class="reference external" href="https://blog.google/technology/ai/google-gemini-next-generation-model-february-2024">Gemini 1.5</a>
was announced to have a standard <span class="math notranslate nohighlight">\(128,000\)</span> token context window, up to a maximum
of <span class="math notranslate nohighlight">\(1\)</span> million max length.</p>
<p>Typically, I think that if your model is trained on a certain context length, it
is not trivial to change it. For example, if you train a model on a context
length of <span class="math notranslate nohighlight">\(128\)</span>, you cannot simply change it to <span class="math notranslate nohighlight">\(256\)</span> without retraining the
model. But it seems that it is increasingly possible to do so.</p>
<p>Let’s look at an example, if we define our <span class="math notranslate nohighlight">\(L\)</span> to be <span class="math notranslate nohighlight">\(32\)</span>, then we would expect each
sequence to be of length <span class="math notranslate nohighlight">\(32\)</span>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">first_sequence</span> <span class="o">=</span> <span class="n">train_data</span><span class="p">[</span><span class="mi">0</span><span class="p">:</span><span class="mi">0</span><span class="o">+</span><span class="mi">32</span><span class="p">]</span>
<span class="n">pprint</span><span class="p">(</span><span class="n">first_sequence</span><span class="p">)</span>

<span class="n">first_sequence_decoded</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="n">first_sequence</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">first_sequence_decoded</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace"><span style="color: #800080; text-decoration-color: #800080; font-weight: bold">memmap</span><span style="font-weight: bold">([</span> <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">5962</span>, <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">22307</span>,    <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">25</span>,   <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">198</span>,  <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">8421</span>,   <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">356</span>,  <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">5120</span>,   <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">597</span>,  <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">2252</span>,
<span style="color: #7fbf7f; text-decoration-color: #7fbf7f">│   │      </span><span style="color: #008080; text-decoration-color: #008080; font-weight: bold">11</span>,  <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">3285</span>,   <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">502</span>,  <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">2740</span>,    <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">13</span>,   <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">198</span>,   <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">198</span>,  <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">3237</span>,    <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">25</span>,
<span style="color: #7fbf7f; text-decoration-color: #7fbf7f">│   │     </span><span style="color: #008080; text-decoration-color: #008080; font-weight: bold">198</span>,  <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">5248</span>,   <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">461</span>,    <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">11</span>,  <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">2740</span>,    <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">13</span>,   <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">198</span>,   <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">198</span>,  <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">5962</span>,
<span style="color: #7fbf7f; text-decoration-color: #7fbf7f">│   │   </span><span style="color: #008080; text-decoration-color: #008080; font-weight: bold">22307</span>,    <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">25</span>,   <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">198</span>,  <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">1639</span>,   <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">389</span><span style="font-weight: bold">]</span>, <span style="color: #808000; text-decoration-color: #808000">dtype</span>=<span style="color: #800080; text-decoration-color: #800080">uint16</span><span style="font-weight: bold">)</span>
</pre>
</div><div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>First Citizen:
Before we proceed any further, hear me speak.

All:
Speak, speak.

First Citizen:
You are
</pre></div>
</div>
</div>
</div>
<p>The example is just extracting <span class="math notranslate nohighlight">\(1\)</span> such sequence <span class="math notranslate nohighlight">\(\mathbf{x}\)</span> from the train
corpus. To leverage the prowess of linear algebra operations in CUDA, we would
typically pass a batch of sequences <span class="math notranslate nohighlight">\(\mathcal{B}\)</span> to the model at a time.</p>
<p>Furthermore, we would require some level of randomness in the sequences that we
pass to the model to enable generalisation. You really do not want the model to
overfit to an ordered sequence of tokens in the training corpus.</p>
<p>To this end, let’s see how Karpathy implements batching and shuffling of the
sequences.</p>
</section>
<section id="shuffling-and-discrete-uniform-sampling">
<h4><a class="toc-backref" href="#id20" role="doc-backlink">Shuffling and Discrete Uniform Sampling</a><a class="headerlink" href="#shuffling-and-discrete-uniform-sampling" title="Permalink to this heading">#</a></h4>
<p>To enable shuffling, Karpathy generates a tensor of random integers (essentially a list of
random integers), which serve as indices. These indices are used to select
random sequences from the training (and validation) data.</p>
<p>For simplicity, let’s look at the case where batch size is reduced to <span class="math notranslate nohighlight">\(\mathcal{B} = 1\)</span>.
This means we only need to sample <span class="math notranslate nohighlight">\(1\)</span> sequence from the training data - and consequently
we only need <span class="math notranslate nohighlight">\(1\)</span> random index.</p>
<p>We can easily achieve this via <code class="docutils literal notranslate"><span class="pre">torch.randint</span></code> which generates random integers
from a discrete uniform distribution over the half-open interval <span class="math notranslate nohighlight">\([l, h)\)</span>,
and since we only want to sample <span class="math notranslate nohighlight">\(1\)</span> sequence, we set <code class="docutils literal notranslate"><span class="pre">size=(1,)</span></code>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">generator</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Generator</span><span class="p">(</span><span class="n">device</span><span class="o">=</span><span class="n">composer</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>

<span class="n">generator</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="mi">25</span><span class="p">)</span>

<span class="n">low</span><span class="p">,</span> <span class="n">high</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">train_data</span><span class="p">)</span> <span class="o">-</span> <span class="n">composer</span><span class="o">.</span><span class="n">block_size</span>
<span class="n">size</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span><span class="p">,)</span>
<span class="n">indices</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="n">low</span><span class="o">=</span><span class="n">low</span><span class="p">,</span> <span class="n">high</span><span class="o">=</span><span class="n">high</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">size</span><span class="p">,</span> <span class="n">generator</span><span class="o">=</span><span class="n">generator</span><span class="p">)</span>
<span class="n">pprint</span><span class="p">(</span><span class="n">indices</span><span class="p">)</span>
<span class="n">pprint</span><span class="p">(</span><span class="n">indices</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace"><span style="color: #800080; text-decoration-color: #800080; font-weight: bold">tensor</span><span style="font-weight: bold">([</span><span style="color: #008080; text-decoration-color: #008080; font-weight: bold">122484</span><span style="font-weight: bold">])</span>
</pre>
</div><div class="output text_html"><pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace"><span style="color: #800080; text-decoration-color: #800080; font-weight: bold">torch.Size</span><span style="font-weight: bold">([</span><span style="color: #008080; text-decoration-color: #008080; font-weight: bold">1</span><span style="font-weight: bold">])</span>
</pre>
</div></div>
</div>
<p>The mathematical operation performed by <code class="docutils literal notranslate"><span class="pre">torch.randint(low,</span> <span class="pre">high,</span> <span class="pre">size,</span> <span class="pre">generator)</span></code> can be described as drawing samples from a uniform discrete distribution. Each element of the resulting tensor is an independent and identically distributed <span id="id2">[<a class="reference internal" href="../../bibliography.html#id10" title="Alec Radford, Jeff Wu, Rewon Child, David Luan, Dario Amodei, and Ilya Sutskever. Language models are unsupervised multitask learners. 2019.">Radford <em>et al.</em>, 2019</a>]</span> (i.i.d.) random variable <span class="math notranslate nohighlight">\(X_i\)</span> with the following probability mass function (PMF):</p>
<div class="math notranslate nohighlight">
\[
\mathbb{P}(X_i = k) = \frac{1}{h - l} \quad \text{for} \, k = l, \ldots, h-1 
\]</div>
<p>This PMF implies that each integer in the range <span class="math notranslate nohighlight">\([l, h-1]\)</span> has an equal probability of being selected.</p>
<p>In our demonstration, we selected a random index, specifically <span class="math notranslate nohighlight">\(136,016\)</span>, from
our training dataset. This serves as a starting point for constructing a
sequence, denoted as <span class="math notranslate nohighlight">\(\mathbf{x}\)</span>. This sequence consists of the token found at
the chosen index and extends to include the subsequent <span class="math notranslate nohighlight">\(T\)</span> tokens, where <span class="math notranslate nohighlight">\(T\)</span>
represents the block size. For the sake of simplicity, and to align with our
predefined settings, we have chosen <span class="math notranslate nohighlight">\(T = 8\)</span>. This block size is predetermined in
our <code class="docutils literal notranslate"><span class="pre">composer</span></code> configuration, activated specifically under a <code class="docutils literal notranslate"><span class="pre">debug</span></code> mode.</p>
<p>In code, we can achieve this by slicing the training data from the random index
to the random index plus the block size. This is done by <code class="docutils literal notranslate"><span class="pre">train_data[random_index:random_index+block_size]</span></code>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">random_sequence</span> <span class="o">=</span> <span class="n">train_data</span><span class="p">[</span><span class="n">indices</span><span class="p">:</span><span class="n">indices</span><span class="o">+</span><span class="n">composer</span><span class="o">.</span><span class="n">block_size</span><span class="p">]</span>
<span class="n">pprint</span><span class="p">(</span><span class="n">random_sequence</span><span class="p">)</span>
<span class="n">pprint</span><span class="p">(</span><span class="n">random_sequence</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>

<span class="n">random_sequence_decoded</span> <span class="o">=</span> <span class="n">tokenizer</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="n">random_sequence</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="n">random_sequence</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace"><span style="color: #800080; text-decoration-color: #800080; font-weight: bold">memmap</span><span style="font-weight: bold">([</span><span style="color: #008080; text-decoration-color: #008080; font-weight: bold">11503</span>,   <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">290</span>, <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">21120</span>,    <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">30</span>,   <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">880</span>,   <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">788</span>,    <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">11</span>, <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">29448</span><span style="font-weight: bold">]</span>,
<span style="color: #7fbf7f; text-decoration-color: #7fbf7f">│      </span><span style="color: #808000; text-decoration-color: #808000">dtype</span>=<span style="color: #800080; text-decoration-color: #800080">uint16</span><span style="font-weight: bold">)</span>
</pre>
</div><div class="output text_html"><pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace"><span style="font-weight: bold">(</span><span style="color: #008080; text-decoration-color: #008080; font-weight: bold">8</span>,<span style="font-weight: bold">)</span>
</pre>
</div><div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> priest and clerk? well then, amen
</pre></div>
</div>
</div>
</div>
<p>One might wonder why the highest value of the random integers is
<code class="docutils literal notranslate"><span class="pre">len(self.train_data)</span> <span class="pre">-</span> <span class="pre">self.block_size</span></code>. This is mostly to prevent index out of
range errors. As we shall soon see, we are using these <code class="docutils literal notranslate"><span class="pre">indices</span></code> to slice a
sequence of length <code class="docutils literal notranslate"><span class="pre">block_size</span></code> from the data where you start slicing from the
index <code class="docutils literal notranslate"><span class="pre">index</span></code> and end at <code class="docutils literal notranslate"><span class="pre">index</span> <span class="pre">+</span> <span class="pre">block_size</span></code>.</p>
</section>
<section id="batching">
<h4><a class="toc-backref" href="#id21" role="doc-backlink">Batching</a><a class="headerlink" href="#batching" title="Permalink to this heading">#</a></h4>
<p>Now that we understand how to sample a single sequence from the training data,
let’s look at how we can sample a batch of sequences.
PyTorch made it easy for you, as we can just simply change the <code class="docutils literal notranslate"><span class="pre">size</span></code> parameter
to <code class="docutils literal notranslate"><span class="pre">(batch_size,)</span></code> so we can sample <span class="math notranslate nohighlight">\(\mathcal{B}\)</span> number of indices - and
consequently <span class="math notranslate nohighlight">\(\mathcal{B}\)</span> number of sequences.</p>
<p>In our case, if we set <span class="math notranslate nohighlight">\(\mathcal{B} = 2\)</span>, we would expect to get <span class="math notranslate nohighlight">\(2\)</span> random
indices.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">generator</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Generator</span><span class="p">(</span><span class="n">device</span><span class="o">=</span><span class="n">composer</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
<span class="n">generator</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="mi">25</span><span class="p">)</span>
<span class="n">low</span><span class="p">,</span> <span class="n">high</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">train_data</span><span class="p">)</span> <span class="o">-</span> <span class="n">composer</span><span class="o">.</span><span class="n">block_size</span>
<span class="n">size</span> <span class="o">=</span> <span class="p">(</span><span class="n">composer</span><span class="o">.</span><span class="n">batch_size</span><span class="p">,)</span>
<span class="n">indices</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="n">low</span><span class="o">=</span><span class="n">low</span><span class="p">,</span> <span class="n">high</span><span class="o">=</span><span class="n">high</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">size</span><span class="p">,</span> <span class="n">generator</span><span class="o">=</span><span class="n">generator</span><span class="p">)</span>
<span class="n">pprint</span><span class="p">(</span><span class="n">indices</span><span class="p">)</span>
<span class="n">pprint</span><span class="p">(</span><span class="n">indices</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace"><span style="color: #800080; text-decoration-color: #800080; font-weight: bold">tensor</span><span style="font-weight: bold">([</span><span style="color: #008080; text-decoration-color: #008080; font-weight: bold">122484</span>, <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">196406</span><span style="font-weight: bold">])</span>
</pre>
</div><div class="output text_html"><pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace"><span style="color: #800080; text-decoration-color: #800080; font-weight: bold">torch.Size</span><span style="font-weight: bold">([</span><span style="color: #008080; text-decoration-color: #008080; font-weight: bold">2</span><span style="font-weight: bold">])</span>
</pre>
</div></div>
</div>
<p>We then construct a batch of
input sequences <span class="math notranslate nohighlight">\(\mathcal{B}\)</span> by selecting the tokens at the
indices <span class="math notranslate nohighlight">\(136,016\)</span> and <span class="math notranslate nohighlight">\(197,976\)</span> and the next <span class="math notranslate nohighlight">\(T\)</span> tokens via a for loop - and using <code class="docutils literal notranslate"><span class="pre">torch.stack</span></code>
to stack the sequences into a tensor of shape <span class="math notranslate nohighlight">\(\mathbb{Z}^{\mathcal{B} \times L}\)</span>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">([</span><span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">((</span><span class="n">train_data</span><span class="p">[</span><span class="n">index</span> <span class="p">:</span> <span class="n">index</span> <span class="o">+</span> <span class="n">composer</span><span class="o">.</span><span class="n">block_size</span><span class="p">])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">int64</span><span class="p">))</span> <span class="k">for</span> <span class="n">index</span> <span class="ow">in</span> <span class="n">indices</span><span class="p">])</span>
<span class="n">pprint</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="n">pprint</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace"><span style="color: #800080; text-decoration-color: #800080; font-weight: bold">tensor</span><span style="font-weight: bold">([[</span><span style="color: #008080; text-decoration-color: #008080; font-weight: bold">11503</span>,   <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">290</span>, <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">21120</span>,    <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">30</span>,   <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">880</span>,   <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">788</span>,    <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">11</span>, <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">29448</span><span style="font-weight: bold">]</span>,
<span style="color: #7fbf7f; text-decoration-color: #7fbf7f">│   │   </span><span style="font-weight: bold">[</span>  <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">326</span>,  <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">8616</span>,   <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">373</span>, <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">14855</span>,    <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">13</span>,   <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">198</span>,   <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">198</span>, <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">37286</span><span style="font-weight: bold">]])</span>
</pre>
</div><div class="output text_html"><pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace"><span style="color: #800080; text-decoration-color: #800080; font-weight: bold">torch.Size</span><span style="font-weight: bold">([</span><span style="color: #008080; text-decoration-color: #008080; font-weight: bold">2</span>, <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">8</span><span style="font-weight: bold">])</span>
</pre>
</div></div>
</div>
<p>It is worth reconciling the fact that the slicing uses <code class="docutils literal notranslate"><span class="pre">[index:index</span> <span class="pre">+</span> <span class="pre">block_size]</span></code> and
therefore completes the reasoning behind the <code class="docutils literal notranslate"><span class="pre">len(self.train_data)</span> <span class="pre">-</span> <span class="pre">self.block_size</span></code> in
the <code class="docutils literal notranslate"><span class="pre">torch.randint</span></code> function call - to prevent index out of range errors. Consider
that if we do not subtract <code class="docutils literal notranslate"><span class="pre">block_size</span></code> from the length of the training data, we might
end up with an index that is the last index of the training data, and when we add
<code class="docutils literal notranslate"><span class="pre">block_size</span></code> to it, we would end up with an index that is out of range.</p>
</section>
</section>
<section id="construction-of-input-and-target-sequences">
<h3><a class="toc-backref" href="#id22" role="doc-backlink">Construction of Input and Target Sequences</a><a class="headerlink" href="#construction-of-input-and-target-sequences" title="Permalink to this heading">#</a></h3>
<p>As we will define more formally later, GPT model is an autoregressive
self-supervised learning model<span id="id3">[<a class="reference internal" href="../../bibliography.html#id11" title="Minhyeok Lee. A mathematical interpretation of autoregressive generative pre-trained transformer and self-supervised learning. Mathematics, 2023. URL: https://www.mdpi.com/2227-7390/11/11/2451, doi:10.3390/math11112451.">Lee, 2023</a>]</span> that directly learns a
conditional probability distribution <span class="math notranslate nohighlight">\(\mathbb{P}(x_t | x_{&lt;t} ; \Theta)\)</span> over
the vocabulary <span class="math notranslate nohighlight">\(\mathcal{V}\)</span> of tokens, which is conditioned on the entire
history of tokens <span class="math notranslate nohighlight">\(x_{&lt;t} = (x_1, x_2, \ldots, x_{t-1})\)</span>.</p>
<p>We have seen earlier how to construct an input sequence <span class="math notranslate nohighlight">\(\mathbf{x}\)</span> from the
training data. To put things into perspective, we consider again the first
sequence that we constructed from the training data:</p>
<div class="math notranslate nohighlight">
\[
\mathbf{x} = \begin{bmatrix} 3194 &amp; 612 &amp; 11 &amp; 290 &amp; 284 &amp; 606 &amp; 910 &amp; 11 \end{bmatrix}
\]</div>
<p>representing the sentence <code class="docutils literal notranslate"><span class="pre">'</span> <span class="pre">written</span> <span class="pre">there,</span> <span class="pre">and</span> <span class="pre">to</span> <span class="pre">them</span> <span class="pre">say,'</span></code>.</p>
<p>Given the autoregressive and self-supervised nature, in order to construct the
target sequence <span class="math notranslate nohighlight">\(\mathbf{y}\)</span>, we simply shift the input sequence by one token to
the left. This means that the target sequence <span class="math notranslate nohighlight">\(\mathbf{y}\)</span> is:</p>
<div class="math notranslate nohighlight">
\[
\mathbf{y} = \begin{bmatrix} 612 &amp; 11 &amp; 290 &amp; 284 &amp; 606 &amp; 910 &amp; 11 &amp; 198 \end{bmatrix}
\]</div>
<p>representing the sentence <code class="docutils literal notranslate"><span class="pre">'</span> <span class="pre">there,</span> <span class="pre">and</span> <span class="pre">to</span> <span class="pre">them</span> <span class="pre">say,\n'</span></code>.</p>
<p>This behaviour is autoregressive because we are using the context tokens
<span class="math notranslate nohighlight">\(x_{&lt;t}\)</span> to predict the next token <span class="math notranslate nohighlight">\(x_t\)</span>, and self-supervised because we are
using the input sequence <span class="math notranslate nohighlight">\(\mathbf{x}\)</span> to construct the target sequence
<span class="math notranslate nohighlight">\(\mathbf{y}\)</span> without any external labels.</p>
<p>To illustrate further, the prediction process during training is cumulative:</p>
<ul class="simple">
<li><p>For predicting <span class="math notranslate nohighlight">\(x_2\)</span>, the model uses <span class="math notranslate nohighlight">\(x_1\)</span> as context:
<span class="math notranslate nohighlight">\(\mathbb{P}\left(x_2 \mid x_1\right)\)</span>.</p></li>
<li><p>For predicting <span class="math notranslate nohighlight">\(x_3\)</span>, the model uses both <span class="math notranslate nohighlight">\(x_1\)</span> and <span class="math notranslate nohighlight">\(x_2\)</span> as context:
<span class="math notranslate nohighlight">\(\mathbb{P}\left(x_3 \mid x_1, x_2\right)\)</span>.</p></li>
<li><p>This pattern continues, such that for predicting <span class="math notranslate nohighlight">\(x_t\)</span>, the model uses
<span class="math notranslate nohighlight">\(x_1, x_2, \ldots, x_{t-1}\)</span> as context:
<span class="math notranslate nohighlight">\(\mathbb{P}\left(x_t \mid x_1, x_2, \ldots, x_{t-1}\right)\)</span></p></li>
</ul>
<p>In code, we can achieve this by simply slicing the adding a <code class="docutils literal notranslate"><span class="pre">1</span></code> to the <code class="docutils literal notranslate"><span class="pre">index</span></code>
in the <code class="docutils literal notranslate"><span class="pre">train_data</span></code> slicing operation.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">y</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">([</span><span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">((</span><span class="n">train_data</span><span class="p">[</span><span class="n">index</span> <span class="o">+</span> <span class="mi">1</span><span class="p">:</span> <span class="n">index</span> <span class="o">+</span> <span class="mi">1</span> <span class="o">+</span> <span class="n">composer</span><span class="o">.</span><span class="n">block_size</span><span class="p">])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">int64</span><span class="p">))</span> <span class="k">for</span> <span class="n">index</span> <span class="ow">in</span> <span class="n">indices</span><span class="p">])</span>
<span class="n">pprint</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
<span class="n">pprint</span><span class="p">(</span><span class="n">y</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>

<span class="n">tokenizer</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="n">y</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">numpy</span><span class="p">())</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace"><span style="color: #800080; text-decoration-color: #800080; font-weight: bold">tensor</span><span style="font-weight: bold">([[</span>  <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">290</span>, <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">21120</span>,    <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">30</span>,   <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">880</span>,   <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">788</span>,    <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">11</span>, <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">29448</span>,    <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">13</span><span style="font-weight: bold">]</span>,
<span style="color: #7fbf7f; text-decoration-color: #7fbf7f">│   │   </span><span style="font-weight: bold">[</span> <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">8616</span>,   <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">373</span>, <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">14855</span>,    <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">13</span>,   <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">198</span>,   <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">198</span>, <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">37286</span>,   <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">406</span><span style="font-weight: bold">]])</span>
</pre>
</div><div class="output text_html"><pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace"><span style="color: #800080; text-decoration-color: #800080; font-weight: bold">torch.Size</span><span style="font-weight: bold">([</span><span style="color: #008080; text-decoration-color: #008080; font-weight: bold">2</span>, <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">8</span><span style="font-weight: bold">])</span>
</pre>
</div><div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>&#39; and clerk? well then, amen.&#39;
</pre></div>
</div>
</div>
</div>
</section>
<section id="asynchronous-data-loading-and-prefetching">
<h3><a class="toc-backref" href="#id23" role="doc-backlink">Asynchronous Data Loading and Prefetching</a><a class="headerlink" href="#asynchronous-data-loading-and-prefetching" title="Permalink to this heading">#</a></h3>
<p>As we approach the last part of the code, Karpathy moves <code class="docutils literal notranslate"><span class="pre">x</span></code> and <code class="docutils literal notranslate"><span class="pre">y</span></code> to the
device and returns them.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">if</span> <span class="n">composer</span><span class="o">.</span><span class="n">device_type</span> <span class="o">==</span> <span class="s2">&quot;cuda&quot;</span><span class="p">:</span>
    <span class="c1"># pin arrays x,y, which allows us to move them to GPU asynchronously (non_blocking=True)</span>
    <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">pin_memory</span><span class="p">()</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">composer</span><span class="o">.</span><span class="n">device</span><span class="p">,</span> <span class="n">non_blocking</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span> <span class="n">y</span><span class="o">.</span><span class="n">pin_memory</span><span class="p">()</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">composer</span><span class="o">.</span><span class="n">device</span><span class="p">,</span> <span class="n">non_blocking</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="k">else</span><span class="p">:</span>
    <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">composer</span><span class="o">.</span><span class="n">device</span><span class="p">),</span> <span class="n">y</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">composer</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>This is a common operation in PyTorch, where we move the data to the underlying
device (CPU or GPU or MPS) to leverage the processing capabilities of the
device. It goes without saying that modern deep learning models are trained on
GPUs - and CUDA is the de facto standard for GPU-accelerated computing.</p>
<p>CUDA allows a <code class="docutils literal notranslate"><span class="pre">pin_memory</span></code> and <code class="docutils literal notranslate"><span class="pre">non_blocking</span></code> parameter to be set when transferring
tensor data from CPU to GPU. The <code class="docutils literal notranslate"><span class="pre">pin_memory</span></code> parameter is used to allow <code class="docutils literal notranslate"><span class="pre">.to(&quot;cuda&quot;)</span></code>
to be more <a class="reference external" href="https://devblogs.nvidia.com/how-optimize-data-transfers-cuda-cc/">performant</a>
as it avoids some implicit CPU-to-CPU copies. Tensors which are pinned in memory
also allow the transfer from CPU to GPU to be done asynchronously via <code class="docutils literal notranslate"><span class="pre">non_blocking</span></code> with respect to
the host<a class="footnote-reference brackets" href="#id10" id="id4" role="doc-noteref"><span class="fn-bracket">[</span>2<span class="fn-bracket">]</span></a>.</p>
<p>It can be useful because we can do some other work in CPU while the data is being
transferred to GPU. Consider the below scenario:</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">tensor.pin_memory().to(&quot;cuda&quot;,</span> <span class="pre">non_blocking=True)</span></code> will transfer the tensor
to the GPU asynchronously, and the CPU can continue doing some other work.</p></li>
<li><p>While waiting, CPU can do some other operations without waiting for the
transfer to complete,</p></li>
<li><p>Once <code class="docutils literal notranslate"><span class="pre">tensor</span></code> is transferred to the GPU, then we can do some other operations
on the GPU.</p></li>
</ul>
<p>What is worth noting is that CUDA manages the synchronization such that
operations on the GPU will not start until the transfer is complete. However, CUDA
programming is complex and is out of the scope of this post. Interested readers
can see the reference section.</p>
</section>
<section id="collating-everything-together">
<h3><a class="toc-backref" href="#id24" role="doc-backlink">Collating Everything Together</a><a class="headerlink" href="#collating-everything-together" title="Permalink to this heading">#</a></h3>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">get_batch</span><span class="p">(</span>
    <span class="n">composer</span><span class="p">:</span> <span class="n">Composer</span><span class="p">,</span>
    <span class="o">*</span><span class="p">,</span>
    <span class="n">split</span><span class="p">:</span> <span class="n">Literal</span><span class="p">[</span><span class="s2">&quot;train&quot;</span><span class="p">,</span> <span class="s2">&quot;valid&quot;</span><span class="p">],</span>
    <span class="n">batch_size</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
    <span class="n">block_size</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>
    <span class="n">generator</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Generator</span><span class="p">,</span>
    <span class="n">device</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">device</span><span class="p">,</span>
    <span class="n">device_type</span><span class="p">:</span> <span class="n">Literal</span><span class="p">[</span><span class="s2">&quot;cpu&quot;</span><span class="p">,</span> <span class="s2">&quot;cuda&quot;</span><span class="p">]</span> <span class="o">=</span> <span class="s2">&quot;cpu&quot;</span><span class="p">,</span>
<span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Tuple</span><span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">,</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">]:</span>
    <span class="c1"># We recreate np.memmap every batch to avoid a memory leak, as per</span>
    <span class="c1"># https://stackoverflow.com/questions/45132940/numpy-memmap-memory-usage-want-to-iterate-once/61472122#61472122</span>
    <span class="k">if</span> <span class="n">split</span> <span class="o">==</span> <span class="s2">&quot;train&quot;</span><span class="p">:</span>
        <span class="n">data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">memmap</span><span class="p">(</span><span class="n">composer</span><span class="o">.</span><span class="n">train_path</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">uint16</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s2">&quot;r&quot;</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">data</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">memmap</span><span class="p">(</span><span class="n">composer</span><span class="o">.</span><span class="n">valid_path</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">uint16</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s2">&quot;r&quot;</span><span class="p">)</span>

    <span class="n">low</span><span class="p">,</span> <span class="n">high</span> <span class="o">=</span> <span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">data</span><span class="p">)</span> <span class="o">-</span> <span class="n">block_size</span>
    <span class="n">size</span> <span class="o">=</span> <span class="p">(</span><span class="n">batch_size</span><span class="p">,)</span>

    <span class="n">indices</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randint</span><span class="p">(</span><span class="n">low</span><span class="o">=</span><span class="n">low</span><span class="p">,</span> <span class="n">high</span><span class="o">=</span><span class="n">high</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="n">size</span><span class="p">,</span> <span class="n">generator</span><span class="o">=</span><span class="n">generator</span><span class="p">)</span>

    <span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">([</span><span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">((</span><span class="n">data</span><span class="p">[</span><span class="n">index</span> <span class="p">:</span> <span class="n">index</span> <span class="o">+</span> <span class="n">block_size</span><span class="p">])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">int64</span><span class="p">))</span> <span class="k">for</span> <span class="n">index</span> <span class="ow">in</span> <span class="n">indices</span><span class="p">])</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">stack</span><span class="p">(</span>
        <span class="p">[</span><span class="n">torch</span><span class="o">.</span><span class="n">from_numpy</span><span class="p">((</span><span class="n">data</span><span class="p">[</span><span class="n">index</span> <span class="o">+</span> <span class="mi">1</span> <span class="p">:</span> <span class="n">index</span> <span class="o">+</span> <span class="mi">1</span> <span class="o">+</span> <span class="n">block_size</span><span class="p">])</span><span class="o">.</span><span class="n">astype</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">int64</span><span class="p">))</span> <span class="k">for</span> <span class="n">index</span> <span class="ow">in</span> <span class="n">indices</span><span class="p">]</span>
    <span class="p">)</span>
    <span class="k">if</span> <span class="n">device_type</span> <span class="o">==</span> <span class="s2">&quot;cuda&quot;</span><span class="p">:</span>
        <span class="c1"># pin arrays x,y, which allows us to move them to GPU asynchronously (non_blocking=True)</span>
        <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">pin_memory</span><span class="p">()</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">,</span> <span class="n">non_blocking</span><span class="o">=</span><span class="kc">True</span><span class="p">),</span> <span class="n">y</span><span class="o">.</span><span class="n">pin_memory</span><span class="p">()</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">,</span> <span class="n">non_blocking</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">x</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">),</span> <span class="n">y</span><span class="o">.</span><span class="n">to</span><span class="p">(</span><span class="n">device</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span>

<span class="n">generator</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Generator</span><span class="p">(</span><span class="n">device</span><span class="o">=</span><span class="n">composer</span><span class="o">.</span><span class="n">device</span><span class="p">)</span>
<span class="n">generator</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="mi">25</span><span class="p">)</span>
<span class="n">train_batch</span> <span class="o">=</span> <span class="n">get_batch</span><span class="p">(</span><span class="n">composer</span><span class="p">,</span> <span class="n">split</span><span class="o">=</span><span class="s2">&quot;train&quot;</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">composer</span><span class="o">.</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">block_size</span><span class="o">=</span><span class="n">composer</span><span class="o">.</span><span class="n">block_size</span><span class="p">,</span> <span class="n">device</span><span class="o">=</span><span class="n">composer</span><span class="o">.</span><span class="n">device</span><span class="p">,</span> <span class="n">generator</span><span class="o">=</span><span class="n">generator</span><span class="p">)</span>
<span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">train_batch</span>
<span class="n">pprint</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="n">pprint</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace"><span style="color: #800080; text-decoration-color: #800080; font-weight: bold">tensor</span><span style="font-weight: bold">([[</span><span style="color: #008080; text-decoration-color: #008080; font-weight: bold">11503</span>,   <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">290</span>, <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">21120</span>,    <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">30</span>,   <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">880</span>,   <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">788</span>,    <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">11</span>, <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">29448</span><span style="font-weight: bold">]</span>,
<span style="color: #7fbf7f; text-decoration-color: #7fbf7f">│   │   </span><span style="font-weight: bold">[</span>  <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">326</span>,  <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">8616</span>,   <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">373</span>, <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">14855</span>,    <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">13</span>,   <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">198</span>,   <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">198</span>, <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">37286</span><span style="font-weight: bold">]])</span>
</pre>
</div><div class="output text_html"><pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace"><span style="color: #800080; text-decoration-color: #800080; font-weight: bold">tensor</span><span style="font-weight: bold">([[</span>  <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">290</span>, <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">21120</span>,    <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">30</span>,   <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">880</span>,   <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">788</span>,    <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">11</span>, <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">29448</span>,    <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">13</span><span style="font-weight: bold">]</span>,
<span style="color: #7fbf7f; text-decoration-color: #7fbf7f">│   │   </span><span style="font-weight: bold">[</span> <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">8616</span>,   <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">373</span>, <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">14855</span>,    <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">13</span>,   <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">198</span>,   <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">198</span>, <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">37286</span>,   <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">406</span><span style="font-weight: bold">]])</span>
</pre>
</div></div>
</div>
</section>
<section id="using-pytorch-s-dataset-and-dataloader">
<h3><a class="toc-backref" href="#id25" role="doc-backlink">Using PyTorch’s Dataset and Dataloader</a><a class="headerlink" href="#using-pytorch-s-dataset-and-dataloader" title="Permalink to this heading">#</a></h3>
<p>It is relatively simple to understand - and since there is not a need to
<a class="reference external" href="https://pytorch.org/docs/stable/data.html#dataloader-collate-fn">collate</a> the
data, which makes things a bit easier.</p>
</section>
</section>
<section id="generative-pre-trained-transformer-gpt">
<h2><a class="toc-backref" href="#id26" role="doc-backlink">Generative Pre-trained Transformer (GPT)</a><a class="headerlink" href="#generative-pre-trained-transformer-gpt" title="Permalink to this heading">#</a></h2>
</section>
<section id="token-embeddings">
<h2><a class="toc-backref" href="#id27" role="doc-backlink">Token Embeddings</a><a class="headerlink" href="#token-embeddings" title="Permalink to this heading">#</a></h2>
<p>First, we will look at the first sequence, given by <code class="docutils literal notranslate"><span class="pre">'</span> <span class="pre">priest</span> <span class="pre">and</span> <span class="pre">clerk?</span> <span class="pre">well</span> <span class="pre">then,</span> <span class="pre">amen'</span></code>,
which we have already mapped to its corresponding token IDs.</p>
<div class="math notranslate nohighlight">
\[
\mathbf{x} = \begin{bmatrix} 11503 &amp; 290 &amp; 21120 &amp; 30 &amp; 880 &amp; 788 &amp; 11 &amp; 29448 \end{bmatrix}
\]</div>
<p>The shape is <span class="math notranslate nohighlight">\(1 \times 8\)</span>, which is a single sequence of <span class="math notranslate nohighlight">\(8\)</span> tokens. And in this case,
we have each word/punctuation mapped to a unique token ID, as seen below.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">for</span> <span class="n">token</span> <span class="ow">in</span> <span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">]:</span>
    <span class="nb">print</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;Token ID: </span><span class="si">{</span><span class="n">token</span><span class="o">.</span><span class="n">item</span><span class="p">()</span><span class="si">}</span><span class="s2">, Token: </span><span class="si">{</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">decode</span><span class="p">([</span><span class="n">token</span><span class="o">.</span><span class="n">item</span><span class="p">()])</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Token ID: 11503, Token:  priest
Token ID: 290, Token:  and
Token ID: 21120, Token:  clerk
Token ID: 30, Token: ?
Token ID: 880, Token:  well
Token ID: 788, Token:  then
Token ID: 11, Token: ,
Token ID: 29448, Token:  amen
</pre></div>
</div>
</div>
</div>
<p>Next, we need to map each token to a vector (embeddings) in a high-dimensional
space.</p>
<p>The integer tokens, by themselves, do not carry much information. For example,
the word <code class="docutils literal notranslate"><span class="pre">priest</span></code> is tokenized to be <code class="docutils literal notranslate"><span class="pre">11503</span></code>, which is an arbitrary integer. In
a one-dimensional Euclidean space, the word <code class="docutils literal notranslate"><span class="pre">priest</span></code> and the next word <code class="docutils literal notranslate"><span class="pre">and</span></code>,
indexed by <code class="docutils literal notranslate"><span class="pre">290</span></code>, <strong><em>would appear to be very far apart from each other</em></strong>.
However, if we were to change a tokenizer, and somehow the word <code class="docutils literal notranslate"><span class="pre">priest</span></code> is now
tokenized to be <code class="docutils literal notranslate"><span class="pre">291</span></code>, then the words <code class="docutils literal notranslate"><span class="pre">priest</span></code> and <code class="docutils literal notranslate"><span class="pre">and</span></code> <strong><em>would appear to be
very near to each other</em></strong>.</p>
<p>This means that the model could potentially learn the relationship of two tokens
based solely on their tokenized integers. To address this, we use embedding
vectors. While the initial mapping from words to vectors is dependent on the
tokenizer and may be arbitrary, during training, the model adjusts these vectors
so that words used in similar contexts come to have similar vectors. This allows
the model to capture semantic relationships between words - and by extension,
allows the model to capture relationships between tokens better.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">x0</span> <span class="o">=</span> <span class="n">x</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>
<span class="n">pprint</span><span class="p">(</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">decode</span><span class="p">(</span><span class="n">x0</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()))</span>
<span class="n">pprint</span><span class="p">(</span><span class="n">x0</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace"><span style="color: #008000; text-decoration-color: #008000">' priest and clerk? well then, amen'</span>
</pre>
</div><div class="output text_html"><pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace"><span style="color: #800080; text-decoration-color: #800080; font-weight: bold">tensor</span><span style="font-weight: bold">([</span><span style="color: #008080; text-decoration-color: #008080; font-weight: bold">11503</span>,   <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">290</span>, <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">21120</span>,    <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">30</span>,   <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">880</span>,   <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">788</span>,    <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">11</span>, <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">29448</span><span style="font-weight: bold">])</span>
</pre>
</div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">torch</span><span class="o">.</span><span class="n">manual_seed</span><span class="p">(</span><span class="n">composer</span><span class="o">.</span><span class="n">seed</span><span class="p">)</span>

<span class="n">tok_embed</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Embedding</span><span class="p">(</span><span class="n">num_embeddings</span><span class="o">=</span><span class="n">composer</span><span class="o">.</span><span class="n">vocab_size</span><span class="p">,</span> <span class="n">embedding_dim</span><span class="o">=</span><span class="n">composer</span><span class="o">.</span><span class="n">d_model</span><span class="p">)</span>
<span class="n">x0_tok_embed</span> <span class="o">=</span> <span class="n">tok_embed</span><span class="p">(</span><span class="n">x0</span><span class="p">)</span>
<span class="n">pprint</span><span class="p">(</span><span class="n">x0_tok_embed</span><span class="p">)</span>
<span class="n">pprint</span><span class="p">(</span><span class="n">x0_tok_embed</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace"><span style="color: #800080; text-decoration-color: #800080; font-weight: bold">tensor</span><span style="font-weight: bold">([[</span><span style="color: #008080; text-decoration-color: #008080; font-weight: bold">-1.0213</span>,  <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">0.3146</span>, <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">-0.2616</span>,  <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">0.3730</span><span style="font-weight: bold">]</span>,
<span style="color: #7fbf7f; text-decoration-color: #7fbf7f">│   │   </span><span style="font-weight: bold">[</span> <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">0.5715</span>,  <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">0.1229</span>, <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">-0.8145</span>, <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">-1.4164</span><span style="font-weight: bold">]</span>,
<span style="color: #7fbf7f; text-decoration-color: #7fbf7f">│   │   </span><span style="font-weight: bold">[</span> <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">0.4973</span>, <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">-1.1740</span>, <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">-0.6713</span>, <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">-0.1102</span><span style="font-weight: bold">]</span>,
<span style="color: #7fbf7f; text-decoration-color: #7fbf7f">│   │   </span><span style="font-weight: bold">[</span><span style="color: #008080; text-decoration-color: #008080; font-weight: bold">-2.3167</span>,  <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">0.2943</span>,  <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">0.9573</span>,  <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">0.2935</span><span style="font-weight: bold">]</span>,
<span style="color: #7fbf7f; text-decoration-color: #7fbf7f">│   │   </span><span style="font-weight: bold">[</span> <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">0.0623</span>, <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">-0.1054</span>,  <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">0.8182</span>, <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">-2.4184</span><span style="font-weight: bold">]</span>,
<span style="color: #7fbf7f; text-decoration-color: #7fbf7f">│   │   </span><span style="font-weight: bold">[</span><span style="color: #008080; text-decoration-color: #008080; font-weight: bold">-1.4016</span>,  <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">0.3422</span>, <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">-0.9704</span>, <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">-0.2435</span><span style="font-weight: bold">]</span>,
<span style="color: #7fbf7f; text-decoration-color: #7fbf7f">│   │   </span><span style="font-weight: bold">[</span><span style="color: #008080; text-decoration-color: #008080; font-weight: bold">-0.0576</span>, <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">-0.0596</span>,  <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">0.2764</span>, <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">-0.2403</span><span style="font-weight: bold">]</span>,
<span style="color: #7fbf7f; text-decoration-color: #7fbf7f">│   │   </span><span style="font-weight: bold">[</span> <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">1.2707</span>, <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">-0.5865</span>, <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">-1.4099</span>, <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">-1.3797</span><span style="font-weight: bold">]]</span>, <span style="color: #808000; text-decoration-color: #808000">grad_fn</span>=<span style="font-weight: bold">&lt;</span><span style="color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold">EmbeddingBackward0</span><span style="font-weight: bold">&gt;)</span>
</pre>
</div><div class="output text_html"><pre style="white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace"><span style="color: #800080; text-decoration-color: #800080; font-weight: bold">torch.Size</span><span style="font-weight: bold">([</span><span style="color: #008080; text-decoration-color: #008080; font-weight: bold">8</span>, <span style="color: #008080; text-decoration-color: #008080; font-weight: bold">4</span><span style="font-weight: bold">])</span>
</pre>
</div></div>
</div>
<section id="lookup-operation">
<h3><a class="toc-backref" href="#id28" role="doc-backlink">Lookup Operation</a><a class="headerlink" href="#lookup-operation" title="Permalink to this heading">#</a></h3>
<p>So this operation above is essentially a lookup operation, where we look up the
embedding vector for each token in the sequence. This is done by
<code class="docutils literal notranslate"><span class="pre">self.token_embeddings(x)</span></code>. We run it against the first sequence for simplicity,
and <code class="docutils literal notranslate"><span class="pre">x0_tok_embed</span></code> is the resulting tensor, with a shape of <span class="math notranslate nohighlight">\(T \times D\)</span>. In our
case, the sequence length (block size) is <span class="math notranslate nohighlight">\(T = 8\)</span>, and the embedding dimension
is <span class="math notranslate nohighlight">\(D = 4\)</span>. This means that we have essentially mapped each of the <span class="math notranslate nohighlight">\(8\)</span> tokens
representing <code class="docutils literal notranslate"><span class="pre">priest</span> <span class="pre">and</span> <span class="pre">clerk?</span> <span class="pre">well</span> <span class="pre">then,</span> <span class="pre">amen</span></code> to a <span class="math notranslate nohighlight">\(4\)</span>-dimensional vector.</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">priest</span></code> is mapped to <code class="docutils literal notranslate"><span class="pre">[-1.0213,</span> <span class="pre">0.3146,</span> <span class="pre">-0.2616,</span> <span class="pre">0.3730]</span></code></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">and</span></code> is mapped to <code class="docutils literal notranslate"><span class="pre">[</span> <span class="pre">0.5715,</span> <span class="pre">0.1229,</span> <span class="pre">-0.8145,</span> <span class="pre">-1.4164]</span></code></p></li>
<li><p>…</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">amen</span></code> is mapped to <code class="docutils literal notranslate"><span class="pre">[</span> <span class="pre">1.2707,</span> <span class="pre">-0.5865,</span> <span class="pre">-1.4099,</span> <span class="pre">-1.3797]</span></code></p></li>
</ul>
<p>With each token being a vector, not only does the token carry more information,
it is also much easier to do linear algebra operations on the tokens. For
example, we can easily calculate the mean/sum of the embeddings for pooling, or
we can easily calculate the dot product between two tokens to measure their
similarity in a high-dimensional space (as compared to it being an integer with
only 1 dimension).</p>
<p>Furthermore, the embeddings are learned during training, and the model would try
to capture semantic relationships between tokens. For example, the model would
try to learn that <code class="docutils literal notranslate"><span class="pre">priest</span></code> and <code class="docutils literal notranslate"><span class="pre">clerk</span></code> are related in some way because they
refer to people, and <code class="docutils literal notranslate"><span class="pre">amen</span></code> is related to <code class="docutils literal notranslate"><span class="pre">priest</span></code> because it is often used in
religious contexts.</p>
</section>
<section id="token-embedding-matrix">
<h3><a class="toc-backref" href="#id29" role="doc-backlink">Token Embedding Matrix</a><a class="headerlink" href="#token-embedding-matrix" title="Permalink to this heading">#</a></h3>
<p><span class="math notranslate nohighlight">\(\mathbf{E}\)</span>: is the embedding matrix defined as:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\mathbf{E} = \begin{bmatrix} e_{1,1} &amp; e_{1,2} &amp; \cdots &amp; e_{1,D} \\ e_{2,1} &amp; e_{2,2} &amp; \cdots &amp; e_{2,D} \\ \vdots &amp; \vdots &amp; \ddots &amp; \vdots \\ e_{V,1} &amp; e_{V,2} &amp; \cdots &amp; e_{V,D} \end{bmatrix} \in \mathbb{R}^{V \times D}
\end{split}\]</div>
<p>where</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(V := \lvert \mathcal{V} \rvert\)</span>: is the vocabulary size.</p></li>
<li><p><span class="math notranslate nohighlight">\(D\)</span>: is the embedding dimension.</p></li>
<li><p><span class="math notranslate nohighlight">\(e_{j, d}\)</span>: is the embedding element at position <span class="math notranslate nohighlight">\(j, d\)</span>. For a word <span class="math notranslate nohighlight">\(v_j\)</span> in
the vocabulary <span class="math notranslate nohighlight">\(\mathcal{V}\)</span>, the corresponding row in <span class="math notranslate nohighlight">\(\mathbf{E}\)</span> is the
embedding vector for that word.</p></li>
</ul>
</section>
<section id="representation-mapping">
<h3><a class="toc-backref" href="#id30" role="doc-backlink">Representation Mapping</a><a class="headerlink" href="#representation-mapping" title="Permalink to this heading">#</a></h3>
<p>Define a function <span class="math notranslate nohighlight">\(h_{\text{tok_embed}}: \mathcal{V} \to \mathbb{R}^{D}\)</span> such
that for each token <span class="math notranslate nohighlight">\(x_t \in \mathcal{V}\)</span>, the function
<span class="math notranslate nohighlight">\(h_{\text{tok_embed}}(x_t) = \mathbf{E}_{\text{index}(x_t)}\)</span> returns the
embedding vector from <span class="math notranslate nohighlight">\(\mathbf{E}\)</span>, where <span class="math notranslate nohighlight">\(\text{index}(x_t)\)</span> is the index of
<span class="math notranslate nohighlight">\(x_t\)</span> in the vocabulary <span class="math notranslate nohighlight">\(\mathcal{V}\)</span> (often times <span class="math notranslate nohighlight">\(x_t\)</span> is already an integer
index).</p>
</section>
<section id="one-hot-encoding-and-embedding-matrix">
<h3><a class="toc-backref" href="#id31" role="doc-backlink">One-Hot Encoding and Embedding Matrix</a><a class="headerlink" href="#one-hot-encoding-and-embedding-matrix" title="Permalink to this heading">#</a></h3>
<p>It is worth noting that the underlying mechanism of calling <code class="docutils literal notranslate"><span class="pre">tok_embed(x)</span></code> is
the same as performing a matrix multiplication between a one-hot encoded vector
and the embedding matrix. This is because the one-hot encoded vector is a
sparse vector with only one non-zero element, and when multiplied with the
embedding matrix, it selects the row corresponding to the non-zero element.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">x0_ohe</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">one_hot</span><span class="p">(</span><span class="n">x0</span><span class="p">,</span> <span class="n">num_classes</span><span class="o">=</span><span class="n">composer</span><span class="o">.</span><span class="n">vocab_size</span><span class="p">)</span>
<span class="n">x0_ohe</span> <span class="o">=</span> <span class="n">x0_ohe</span><span class="o">.</span><span class="n">float</span><span class="p">()</span>
<span class="k">assert</span> <span class="n">x0_ohe</span><span class="o">.</span><span class="n">shape</span> <span class="o">==</span> <span class="p">(</span><span class="n">composer</span><span class="o">.</span><span class="n">block_size</span><span class="p">,</span> <span class="n">composer</span><span class="o">.</span><span class="n">vocab_size</span><span class="p">)</span> <span class="c1"># [8, 50257]</span>

<span class="k">for</span> <span class="n">index</span><span class="p">,</span> <span class="n">token_id</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">x0</span><span class="p">):</span>
    <span class="k">assert</span> <span class="n">x0_ohe</span><span class="p">[</span><span class="n">index</span><span class="p">,</span> <span class="n">token_id</span><span class="p">]</span><span class="o">.</span><span class="n">item</span><span class="p">()</span> <span class="o">==</span> <span class="mf">1.0</span> <span class="c1"># check if the one-hot encoding is correct</span>
</pre></div>
</div>
</div>
</div>
<ul class="simple">
<li><p>Recall our tokenized sequence is
<code class="docutils literal notranslate"><span class="pre">[11503,</span> <span class="pre">290,</span> <span class="pre">21120,</span> <span class="pre">30,</span> <span class="pre">880,</span> <span class="pre">788,</span> <span class="pre">11,</span> <span class="pre">29448]</span></code>.</p></li>
<li><p>Converting it to one-hot encoding, we would have a matrix of size
<code class="docutils literal notranslate"><span class="pre">[8,</span> <span class="pre">50257]</span></code> (or more generally <code class="docutils literal notranslate"><span class="pre">[B,</span> <span class="pre">T,</span> <span class="pre">V]</span></code> in the presence of batch size
<code class="docutils literal notranslate"><span class="pre">B</span></code>).</p></li>
<li><p>Each row is a one-hot vector of the token <span class="math notranslate nohighlight">\(x_{t} \in \mathbb{R}^{V}\)</span> at
position <span class="math notranslate nohighlight">\(t\)</span>. For example, the first row would be a one-hot vector of the
token <code class="docutils literal notranslate"><span class="pre">11503</span></code>, so every element in the first row is <span class="math notranslate nohighlight">\(0\)</span> except for the
<span class="math notranslate nohighlight">\(11503\)</span>-th element, which is <span class="math notranslate nohighlight">\(1\)</span>.</p></li>
<li><p>A minute quirk here is that the token <span class="math notranslate nohighlight">\(x_{t}\)</span> exists in the <strong><em>continuous
space</em></strong> instead of the <strong><em>discrete space</em></strong>. This is because we have to
perform the dot product between the one-hot vector and the embedding vector,
which is a continuous vector. This is more of a data type coercion.
Therefore, in our code, we also converted the one-hot vector to <code class="docutils literal notranslate"><span class="pre">.float()</span></code>.</p></li>
</ul>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">embedding_matrix</span> <span class="o">=</span> <span class="n">tok_embed</span><span class="o">.</span><span class="n">weight</span><span class="o">.</span><span class="n">data</span>
<span class="n">x0_ohe_tok_embed</span> <span class="o">=</span> <span class="n">x0_ohe</span> <span class="o">@</span> <span class="n">embedding_matrix</span>
<span class="k">assert</span> <span class="n">torch</span><span class="o">.</span><span class="n">allclose</span><span class="p">(</span><span class="n">x0_tok_embed</span><span class="p">,</span> <span class="n">x0_ohe_tok_embed</span><span class="p">,</span> <span class="n">atol</span><span class="o">=</span><span class="mf">1e-5</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Indeed, we see that the result of <code class="docutils literal notranslate"><span class="pre">tok_embed(x)</span></code> is the same as the result of
<code class="docutils literal notranslate"><span class="pre">x0_ohe</span> <span class="pre">&#64;</span> <span class="pre">embedding_matrix</span></code>. In other words, you can one hot encoded the input
sequence <span class="math notranslate nohighlight">\(\mathbf{x} = (x_1, x_2, \ldots, x_T)\)</span> and then matrix multiply it with the
embedding matrix <span class="math notranslate nohighlight">\(\mathbf{E}\)</span> (via a linear layer) to get the same result as <code class="docutils literal notranslate"><span class="pre">tok_embed(x)</span></code>.</p>
<ul>
<li><p><span class="math notranslate nohighlight">\(\mathbf{O}\)</span>: one-hot representation of the input sequence
<span class="math notranslate nohighlight">\(\mathbf{x} = (x_1, x_2, \ldots, x_T)\)</span>. This is a <span class="math notranslate nohighlight">\(T \times V\)</span> matrix, where
each row represents a token in the sequence and each column corresponds to a
unique word in the vocabulary <span class="math notranslate nohighlight">\(\mathcal{V}\)</span>.</p>
<div class="math notranslate nohighlight">
\[\begin{split}
    \begin{aligned}
    \mathbf{O} &amp;= \begin{bmatrix} o_{1,1} &amp; o_{1,2} &amp; \cdots &amp; o_{1,V} \\ o_{2,1} &amp; o_{2,2} &amp; \cdots &amp; o_{2,V} \\ \vdots &amp; \vdots &amp; \ddots &amp; \vdots \\ o_{T,1} &amp; o_{T,2} &amp; \cdots &amp; o_{T,V} \end{bmatrix} \in \mathbb{R}^{T \times V} \\
    &amp;= \begin{bmatrix} \text{---} &amp; \mathbf{o}_{1, :} &amp; \text{---} \\ \text{---} &amp; \mathbf{o}_{2, :} &amp; \text{---} \\ &amp; \vdots &amp; \\ \text{---} &amp; \mathbf{o}_{T, :} &amp; \text{---} \end{bmatrix} \in \mathbb{R}^{T \times V}
    \end{aligned}
    \end{split}\]</div>
<p>where</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(T\)</span>: is the sequence length.</p></li>
<li><p><span class="math notranslate nohighlight">\(V\)</span>: is the vocabulary size.</p></li>
<li><p><span class="math notranslate nohighlight">\(o_{t, j}\)</span>: is the one-hot encoded element at position <span class="math notranslate nohighlight">\(t, j\)</span>. For a
given token <span class="math notranslate nohighlight">\(x_t\)</span> at the <span class="math notranslate nohighlight">\(t\)</span>-th position in the sequence <span class="math notranslate nohighlight">\(\mathbf{x}\)</span>,
if <span class="math notranslate nohighlight">\(f_{\text{stoi}}(x_t)=j\)</span>, then the element at position <span class="math notranslate nohighlight">\(j\)</span> in the
one-hot vector for token <span class="math notranslate nohighlight">\(x_i\)</span> is 1, and all other elements are 0.</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{o}_{t, :}\)</span>: is the one-hot encoded vector for the token <span class="math notranslate nohighlight">\(x_t\)</span>
at the <span class="math notranslate nohighlight">\(t\)</span>-th position in the sequence <span class="math notranslate nohighlight">\(\mathbf{x}\)</span>. This row form is
more important than column form because it serves as the lookup key for
the embedding matrix <span class="math notranslate nohighlight">\(\mathbf{E}\)</span>.</p></li>
</ul>
</li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{Z}\)</span>: is the output tensor of the embedding layer, obtained by
matrix multiplying <span class="math notranslate nohighlight">\(\mathbf{O}\)</span> with <span class="math notranslate nohighlight">\(\mathbf{E}\)</span>, and it is defined as:</p>
<div class="math notranslate nohighlight">
\[
    \mathbf{Z} = \mathbf{O} \cdot \mathbf{E}
    \]</div>
<div class="math notranslate nohighlight">
\[\begin{split}
    \begin{aligned}
    \mathbf{Z} &amp;= \mathbf{O} \cdot \mathbf{E} \\
    &amp;= \begin{bmatrix} z_{1,1} &amp; z_{1,2} &amp; \cdots &amp; z_{1,D} \\ z_{2,1} &amp; z_{2,2} &amp; \cdots &amp; z_{2,D} \\ \vdots &amp; \vdots &amp; \ddots &amp; \vdots \\ z_{T,1} &amp; z_{T,2} &amp; \cdots &amp; z_{T,D} \end{bmatrix} \in \mathbb{R}^{T \times D} \\
    &amp;= \begin{bmatrix} \text{---} &amp; \mathbf{z}_{1,:} &amp; \text{---} \\ \text{---} &amp; \mathbf{z}_{2,:} &amp; \text{---} \\ &amp; \vdots &amp; \\ \text{---} &amp; \mathbf{z}_{T,:} &amp; \text{---} \end{bmatrix} \in \mathbb{R}^{T \times D}
    \end{aligned}
    \end{split}\]</div>
<p>where</p>
<ul>
<li><p><span class="math notranslate nohighlight">\(T\)</span>: is the sequence length.</p></li>
<li><p><span class="math notranslate nohighlight">\(D\)</span>: is the embedding dimension.</p></li>
<li><p><span class="math notranslate nohighlight">\(z_{t, d}\)</span>: is the element at position <span class="math notranslate nohighlight">\(t, d\)</span> in the tensor
<span class="math notranslate nohighlight">\(\mathbf{Z}\)</span>. For a token <span class="math notranslate nohighlight">\(x_t\)</span> at the <span class="math notranslate nohighlight">\(t\)</span>-th position in the sequence,
<span class="math notranslate nohighlight">\(z_{t, :}\)</span> is the <span class="math notranslate nohighlight">\(D\)</span> dimensional embedding vector for that token.</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{z}_{t, :}\)</span>: is the <span class="math notranslate nohighlight">\(D\)</span> dimensional embedding vector for the
token <span class="math notranslate nohighlight">\(x_t\)</span> at the <span class="math notranslate nohighlight">\(t\)</span>-th position in the sequence.</p>
<p>In this context, each token in the sequence is represented by a <span class="math notranslate nohighlight">\(D\)</span>
dimensional vector. So, the output tensor <span class="math notranslate nohighlight">\(\mathbf{Z}\)</span> captures the
dense representation of the sequence. Each token in the sequence is
replaced by its corresponding embedding vector from the embedding matrix
<span class="math notranslate nohighlight">\(\mathbf{E}\)</span>.</p>
<p>As before, the output tensor <span class="math notranslate nohighlight">\(\mathbf{Z}\)</span> carries semantic information
about the tokens in the sequence. The closer two vectors are in this
embedding space, the more semantically similar they are.</p>
</li>
</ul>
</li>
</ul>
</section>
</section>
<section id="positional-embeddings">
<h2><a class="toc-backref" href="#id32" role="doc-backlink">Positional Embeddings</a><a class="headerlink" href="#positional-embeddings" title="Permalink to this heading">#</a></h2>
<p>For the lack of a better phrase, we say that self-attention, the core function
of GPTs, is permutation invariant. While it is obvious that the input sequence
<span class="math notranslate nohighlight">\(\mathbf{x}\)</span> is ordered in the sense that <span class="math notranslate nohighlight">\(x_1\)</span> comes before <span class="math notranslate nohighlight">\(x_2\)</span>, and <span class="math notranslate nohighlight">\(x_2\)</span>
comes before <span class="math notranslate nohighlight">\(x_3\)</span>, and so on, this information gets lost in the self-attention
mechanism. This means that the model does not differentiate “the cat ate the
mouse” from “the mouse ate the cat” as long as the tokens are the same - and
this is not desirable.</p>
<p>The dominant approach for preserving information about the order of tokens is to
represent this to the model as an additional input associated with each token.
These inputs are called positional encodings, and they can either be learned or
fixed <em>a priori</em> <span id="id5">[<a class="reference internal" href="../../bibliography.html#id2" title="Aston Zhang, Zachary C. Lipton, Mu Li, and Alexander J. Smola. Dive into Deep Learning. Cambridge University Press, 2023. URL: https://D2L.ai.">Zhang <em>et al.</em>, 2023</a>]</span>. What this means is that we can either
construct a learnable parameter that is updated during training, or we can
construct a fixed parameter that is not updated during training. For the sake of
completeness, we will discuss briefly the scheme where the positional encodings
are fixed <em>a priori</em> based on sinusoidal functions - which is also the scheme
described in the paper “Attention is All You Need” <span id="id6">[<a class="reference internal" href="../../bibliography.html#id12" title="Ashish Vaswani, Noam Shazeer, Niki Parmar, Jakob Uszkoreit, Llion Jones, Aidan N. Gomez, Lukasz Kaiser, and Illia Polosukhin. Attention is all you need. 2023. arXiv:1706.03762.">Vaswani <em>et al.</em>, 2023</a>]</span>.</p>
<div class="proof definition admonition" id="decoder-positional-encoding">
<p class="admonition-title"><span class="caption-number">Definition 1 </span> (Positional Encoding)</p>
<section class="definition-content" id="proof-content">
<p>The positional encoding function
<span class="math notranslate nohighlight">\(\mathrm{PE}: \mathbb{N} \times \mathbb{N} \rightarrow \mathbb{R}\)</span> computes the
position encoding for each position <span class="math notranslate nohighlight">\(p \in \mathbb{N}\)</span> and each dimension
<span class="math notranslate nohighlight">\(i \in \mathbb{N}\)</span> in the input embedding space as follows <span id="id7">[<a class="reference internal" href="../../bibliography.html#id11" title="Minhyeok Lee. A mathematical interpretation of autoregressive generative pre-trained transformer and self-supervised learning. Mathematics, 2023. URL: https://www.mdpi.com/2227-7390/11/11/2451, doi:10.3390/math11112451.">Lee, 2023</a>]</span>:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\operatorname{PE}(p, i)= \begin{cases}\sin \left(\frac{p}{10000^{\frac{2 i}{d}}}\right) &amp; \text { if } i \text { is even, } \\ \cos \left(\frac{p}{10000^{\frac{2 i-1}{d}}}\right) &amp; \text { if } i \text { is odd. }\end{cases}
\end{split}\]</div>
</section>
</div><p>The positional encoding function incorporates a 10,000 constant, which serves as
a hyperparameter. This value was determined empirically during the original
development of the Transformer model. It is designed to create a balance between
the higher and lower frequency components of the positional encoding. To
facilitate the optimization process, the GPT model employs layer normalization,
which is applied to the input of both the multi-head self-attention and
position-wise feedforward sublayers. Layer normalization helps alleviate the
vanishing and exploding gradient problems and accelerates training.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">from</span> <span class="nn">abc</span> <span class="kn">import</span> <span class="n">ABC</span><span class="p">,</span> <span class="n">abstractmethod</span>

<span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">from</span> <span class="nn">torch</span> <span class="kn">import</span> <span class="n">nn</span>


<span class="k">class</span> <span class="nc">PositionalEncoding</span><span class="p">(</span><span class="n">ABC</span><span class="p">,</span> <span class="n">nn</span><span class="o">.</span><span class="n">Module</span><span class="p">):</span>
    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">d_model</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">context_length</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">dropout</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.0</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">d_model</span> <span class="o">=</span> <span class="n">d_model</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">context_length</span> <span class="o">=</span> <span class="n">context_length</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span> <span class="o">=</span> <span class="n">nn</span><span class="o">.</span><span class="n">Dropout</span><span class="p">(</span><span class="n">p</span><span class="o">=</span><span class="n">dropout</span><span class="p">,</span> <span class="n">inplace</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

    <span class="nd">@abstractmethod</span>
    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
        <span class="o">...</span>


<span class="k">class</span> <span class="nc">Sinusoid</span><span class="p">(</span><span class="n">PositionalEncoding</span><span class="p">):</span>
    <span class="n">P</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">d_model</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">context_length</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span> <span class="n">dropout</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="mf">0.0</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="kc">None</span><span class="p">:</span>
        <span class="nb">super</span><span class="p">()</span><span class="o">.</span><span class="fm">__init__</span><span class="p">(</span><span class="n">d_model</span><span class="p">,</span> <span class="n">context_length</span><span class="p">,</span> <span class="n">dropout</span><span class="p">)</span>

        <span class="n">P</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_init_positional_encoding</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">register_buffer</span><span class="p">(</span><span class="s2">&quot;P&quot;</span><span class="p">,</span> <span class="n">P</span><span class="p">,</span> <span class="n">persistent</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>  <span class="c1"># with this no need requires_grad=False</span>

    <span class="k">def</span> <span class="nf">_init_positional_encoding</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Initialize the positional encoding tensor.&quot;&quot;&quot;</span>
        <span class="n">P</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="mi">1</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">context_length</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">d_model</span><span class="p">))</span>
        <span class="n">position</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_position_vector</span><span class="p">()</span>
        <span class="n">div_term</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_get_div_term_vector</span><span class="p">()</span>
        <span class="n">P</span><span class="p">[:,</span> <span class="p">:,</span> <span class="mi">0</span><span class="p">::</span><span class="mi">2</span><span class="p">]</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">sin</span><span class="p">(</span><span class="n">position</span> <span class="o">/</span> <span class="n">div_term</span><span class="p">)</span>
        <span class="n">P</span><span class="p">[:,</span> <span class="p">:,</span> <span class="mi">1</span><span class="p">::</span><span class="mi">2</span><span class="p">]</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">cos</span><span class="p">(</span><span class="n">position</span> <span class="o">/</span> <span class="n">div_term</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">P</span>

    <span class="k">def</span> <span class="nf">_get_position_vector</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Return a vector representing the position of each token in a sequence.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">context_length</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>

    <span class="k">def</span> <span class="nf">_get_div_term_vector</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Return a vector representing the divisor term for positional encoding.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">torch</span><span class="o">.</span><span class="n">pow</span><span class="p">(</span>
            <span class="mi">10000</span><span class="p">,</span>
            <span class="n">torch</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">d_model</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">)</span> <span class="o">/</span> <span class="bp">self</span><span class="o">.</span><span class="n">d_model</span><span class="p">,</span>
        <span class="p">)</span>

    <span class="k">def</span> <span class="nf">forward</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">z</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
        <span class="n">z</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">_add_positional_encoding</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>
        <span class="n">z</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">dropout</span><span class="p">(</span><span class="n">z</span><span class="p">)</span>
        <span class="k">return</span> <span class="n">z</span>

    <span class="k">def</span> <span class="nf">_add_positional_encoding</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">z</span><span class="p">:</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">:</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;Add the positional encoding tensor to the input tensor.&quot;&quot;&quot;</span>
        <span class="k">return</span> <span class="n">z</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">P</span><span class="p">[:,</span> <span class="p">:</span> <span class="n">z</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="p">:]</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">encod_block</span> <span class="o">=</span> <span class="n">Sinusoid</span><span class="p">(</span><span class="n">d_model</span><span class="o">=</span><span class="mi">48</span><span class="p">,</span> <span class="n">context_length</span><span class="o">=</span><span class="mi">96</span><span class="p">)</span>

<span class="n">pe</span> <span class="o">=</span> <span class="n">encod_block</span><span class="o">.</span><span class="n">P</span><span class="o">.</span><span class="n">squeeze</span><span class="p">()</span><span class="o">.</span><span class="n">T</span><span class="o">.</span><span class="n">cpu</span><span class="p">()</span><span class="o">.</span><span class="n">numpy</span><span class="p">()</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">nrows</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">ncols</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span><span class="mi">3</span><span class="p">))</span>
<span class="n">pos</span> <span class="o">=</span> <span class="n">ax</span><span class="o">.</span><span class="n">imshow</span><span class="p">(</span><span class="n">pe</span><span class="p">,</span> <span class="n">cmap</span><span class="o">=</span><span class="s2">&quot;RdGy&quot;</span><span class="p">,</span> <span class="n">extent</span><span class="o">=</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="n">pe</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span><span class="n">pe</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">+</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="p">))</span>
<span class="n">fig</span><span class="o">.</span><span class="n">colorbar</span><span class="p">(</span><span class="n">pos</span><span class="p">,</span> <span class="n">ax</span><span class="o">=</span><span class="n">ax</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s2">&quot;Position in sequence&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s2">&quot;Hidden dimension&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="s2">&quot;Positional encoding over hidden dimensions&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xticks</span><span class="p">([</span><span class="mi">1</span><span class="p">]</span><span class="o">+</span><span class="p">[</span><span class="n">i</span><span class="o">*</span><span class="mi">10</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="o">+</span><span class="n">pe</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">//</span><span class="mi">10</span><span class="p">)])</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_yticks</span><span class="p">([</span><span class="mi">1</span><span class="p">]</span><span class="o">+</span><span class="p">[</span><span class="n">i</span><span class="o">*</span><span class="mi">10</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span><span class="mi">1</span><span class="o">+</span><span class="n">pe</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">//</span><span class="mi">10</span><span class="p">)])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/5e9cd6a8b20f305eacccfdc28265f83b2c46945a066ca4d100ce129517932897.png" src="../../_images/5e9cd6a8b20f305eacccfdc28265f83b2c46945a066ca4d100ce129517932897.png" />
</div>
</div>
</section>
<section id="self-attention-and-masked-self-attention">
<h2><a class="toc-backref" href="#id33" role="doc-backlink">Self-Attention and Masked Self-Attention</a><a class="headerlink" href="#self-attention-and-masked-self-attention" title="Permalink to this heading">#</a></h2>
<ol class="arabic simple">
<li><p>Insert arch diagram</p></li>
<li><p>change example since i changed seed.</p></li>
<li><p>Add cosine similarity from transformers notebook to show that embeddings in a subspace.</p></li>
<li><p>Add def/theorem/notation prf</p></li>
<li><p>Conditional and Joint probability</p></li>
<li><p>Model definition in page 5/</p></li>
<li><p>Loss see page 5/6</p></li>
<li><p>autoregressive self supervised def page 6</p></li>
<li><p>Insert intuition of using average of preceding tokens for self attention section:</p>
<ol class="arabic simple">
<li><p>version 1: averaging past context with for loops, the weakest form of aggregation</p></li>
<li><p>min 42 to min 58</p></li>
<li><p>on intuition of softmax and weight distribution</p></li>
</ol>
</li>
<li><p>Time and Space Complexity</p></li>
</ol>
</section>
<section id="conditional-probability">
<h2><a class="toc-backref" href="#id34" role="doc-backlink">Conditional Probability</a><a class="headerlink" href="#conditional-probability" title="Permalink to this heading">#</a></h2>
<p>The GPT model, being autoregressive, directly models the <strong>conditional
probability</strong> of each token given all previous tokens in a sequence. This is the
core operational mechanism of the model, allowing it to predict the next token
based on the preceding context. The conditional probability for each token <span class="math notranslate nohighlight">\(x_t\)</span>
given its predecessors <span class="math notranslate nohighlight">\(x_{&lt;t}\)</span> is expressed as <span class="math notranslate nohighlight">\(P(x_t | x_{&lt;t};
\Theta)\)</span>, where
<span class="math notranslate nohighlight">\(\Theta\)</span> represents the model’s parameters.</p>
</section>
<section id="joint-probability">
<h2><a class="toc-backref" href="#id35" role="doc-backlink">Joint Probability</a><a class="headerlink" href="#joint-probability" title="Permalink to this heading">#</a></h2>
<p>The <strong>joint probability</strong> of a sequence <span class="math notranslate nohighlight">\(\mathbf{x} = (x_1, x_2, ..., x_T)\)</span>
under the model is derived from the product of these conditional probabilities.
By assuming that the probability of each token can be modeled based on its
predecessors, the model implicitly defines a joint probability distribution over
sequences. This joint probability is represented by the product:</p>
<div class="math notranslate nohighlight">
\[
P(\mathbf{x}; \Theta) = \prod_{t=1}^{T} P(x_t | x_{&lt;t}; \Theta)
\]</div>
<p>This formulation shows that while the GPT model operates through conditional
probabilities, the product of these conditional probabilities across a sequence
results in the <strong>joint probability</strong> of the entire sequence. Thus, the GPT model
effectively learns the joint probability distribution over sequences in the
dataset by learning to predict the next token given its context, leveraging the
chain rule of probability.</p>
<p><span id="id8">[<a class="reference internal" href="../../bibliography.html#id11" title="Minhyeok Lee. A mathematical interpretation of autoregressive generative pre-trained transformer and self-supervised learning. Mathematics, 2023. URL: https://www.mdpi.com/2227-7390/11/11/2451, doi:10.3390/math11112451.">Lee, 2023</a>]</span></p>
<ul class="simple">
<li><p><a class="reference external" href="https://devblogs.nvidia.com/how-optimize-data-transfers-cuda-cc/">https://devblogs.nvidia.com/how-optimize-data-transfers-cuda-cc/</a></p></li>
<li><p><a class="reference external" href="https://developer.nvidia.com/blog/how-overlap-data-transfers-cuda-cc/">https://developer.nvidia.com/blog/how-overlap-data-transfers-cuda-cc/</a></p></li>
<li><p><a class="reference external" href="https://e2eml.school/transformers.html">https://e2eml.school/transformers.html</a></p></li>
</ul>
<hr class="footnotes docutils" />
<aside class="footnote brackets" id="id9" role="note">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id1">1</a><span class="fn-bracket">]</span></span>
<p><a class="reference external" href="https://github.com/openai/tiktoken">OpenAI tiktoken</a></p>
</aside>
<aside class="footnote brackets" id="id10" role="note">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id4">2</a><span class="fn-bracket">]</span></span>
<p><a class="reference external" href="https://devblogs.nvidia.com/how-optimize-data-transfers-cuda-cc/">How to Optimize Data Transfers in CUDA C/C++</a></p>
</aside>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./transformer/decoder"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="../concept.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Concept</p>
      </div>
    </a>
    <a class="right-next"
       href="../../deep_learning/training_chronicles/intro.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Training Chronicles</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#composing-the-configurations">Composing the Configurations</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#reproducibility">Reproducibility</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#tokenization-and-vocabulary">Tokenization and Vocabulary</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#stoi-todo">STOI (TODO)</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#dataset-and-dataloading-poor-man-s-dataloader">Dataset and Dataloading (Poor Man’s Dataloader)</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#memory-mapping">Memory Mapping</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#notation-context-length-shuffling-and-batching">Notation, Context Length, Shuffling and Batching</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#notation">Notation</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#context-length-block-size">Context Length / Block Size</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#shuffling-and-discrete-uniform-sampling">Shuffling and Discrete Uniform Sampling</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#batching">Batching</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#construction-of-input-and-target-sequences">Construction of Input and Target Sequences</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#asynchronous-data-loading-and-prefetching">Asynchronous Data Loading and Prefetching</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#collating-everything-together">Collating Everything Together</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#using-pytorch-s-dataset-and-dataloader">Using PyTorch’s Dataset and Dataloader</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#generative-pre-trained-transformer-gpt">Generative Pre-trained Transformer (GPT)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#token-embeddings">Token Embeddings</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#lookup-operation">Lookup Operation</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#token-embedding-matrix">Token Embedding Matrix</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#representation-mapping">Representation Mapping</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#one-hot-encoding-and-embedding-matrix">One-Hot Encoding and Embedding Matrix</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#positional-embeddings">Positional Embeddings</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#self-attention-and-masked-self-attention">Self-Attention and Masked Self-Attention</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#conditional-probability">Conditional Probability</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#joint-probability">Joint Probability</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Gao Hongnan
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2023.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../_static/scripts/bootstrap.js?digest=8d27b9dea8ad943066ae"></script>
<script src="../../_static/scripts/pydata-sphinx-theme.js?digest=8d27b9dea8ad943066ae"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>