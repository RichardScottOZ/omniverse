

<!DOCTYPE html>


<html lang="en" data-content_root="" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

    <title>Concept &#8212; Omniverse</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=8d27b9dea8ad943066ae" rel="stylesheet" />
<link href="../_static/styles/bootstrap.css?digest=8d27b9dea8ad943066ae" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=8d27b9dea8ad943066ae" rel="stylesheet" />

  
  <link href="../_static/vendor/fontawesome/6.5.1/css/all.min.css?digest=8d27b9dea8ad943066ae" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.1/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.1/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.5.1/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" href="../_static/styles/sphinx-book-theme.css?digest=14f4ca6b54d191a8c7657f6c759bf11a5fb86285" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/proof.css" />
    <link rel="stylesheet" type="text/css" href="../_static/custom.css" />
    <link rel="stylesheet" type="text/css" href="../_static/design-style.4045f2051d55cab465a707391d5b2007.min.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=8d27b9dea8ad943066ae" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=8d27b9dea8ad943066ae" />
  <script src="../_static/vendor/fontawesome/6.5.1/js/all.min.js?digest=8d27b9dea8ad943066ae"></script>

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?digest=5a5c038af52cf7bc1a1ec88eea08e6366ee68824"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'transformer/concept';</script>
    <link rel="canonical" href="https://www.gaohongnan.com/transformer/concept.html" />
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Shakespeare" href="decoder/implementation.html" />
    <link rel="prev" title="Notations" href="notations.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a id="pst-skip-link" class="skip-link" href="#main-content">Skip to main content</a>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>
    Back to top
  </button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search..."
         aria-label="Search..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <header class="bd-header navbar navbar-expand-lg bd-navbar">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  

<a class="navbar-brand logo" href="../intro.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../_static/logo.png" class="logo__image only-light" alt="Omniverse - Home"/>
    <script>document.write(`<img src="../_static/logo.png" class="logo__image only-dark" alt="Omniverse - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item"><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">Transformers - Attention is All You Need</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="intro.html">Introduction</a></li>
<li class="toctree-l1"><a class="reference internal" href="notations.html">Notations</a></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#">Concept</a></li>
<li class="toctree-l1"><a class="reference internal" href="decoder/implementation.html">Shakespeare</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Deep Learning</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../deep_learning/training_chronicles/intro.html">Training Chronicles</a><input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-1"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../deep_learning/training_chronicles/loss.html">The Loss Landscape</a></li>
</ul>
</li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Software Engineering</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../software_engineering/devops/continuous-integration/styling.html">Styling, Formatting, and Linting</a></li>
<li class="toctree-l1"><a class="reference internal" href="../software_engineering/design_patterns/dependency-inversion-principle.html">Dependency Inversion Principle</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../software_engineering/concurrency_parallelism_asynchronous/intro.html">Concurrency, Parallelism and Asynchronous Programming</a><input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-2"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../software_engineering/concurrency_parallelism_asynchronous/generator_yield.html">A Rudimentary Introduction to Generator and Yield in Python</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../software_engineering/serving/restful_api/intro.html">RESTful API</a><input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-3"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../software_engineering/serving/restful_api/application_banking.html">Application: Designing a RESTful Banking API with FastAPI and SQLAlchemy</a></li>
</ul>
</li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Computer Science</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../computer_science/type_theory/intro.html">Type Theory, A Very Rudimentary Introduction</a><input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-4"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../computer_science/type_theory/01-subtypes.html">Subtypes</a></li>
<li class="toctree-l2"><a class="reference internal" href="../computer_science/type_theory/02-type-safety.html">Type Safety</a></li>
<li class="toctree-l2"><a class="reference internal" href="../computer_science/type_theory/03-subsumption.html">Subsumption</a></li>
<li class="toctree-l2"><a class="reference internal" href="../computer_science/type_theory/04-generics.html">Generics and Type Variables</a></li>
<li class="toctree-l2"><a class="reference internal" href="../computer_science/type_theory/05-typevar-bound-constraints.html">Bound and Constraint in Generics and Type Variables</a></li>
<li class="toctree-l2"><a class="reference internal" href="../computer_science/type_theory/06-invariance-covariance-contravariance.html">Invariance, Covariance and Contravariance</a></li>
<li class="toctree-l2"><a class="reference internal" href="../computer_science/type_theory/07-pep-3124-overloading.html">Function Overloading</a></li>
<li class="toctree-l2"><a class="reference internal" href="../computer_science/type_theory/08-pep-661-sentinel-values.html">Sentinel Types</a></li>
</ul>
</li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Data Structures and Algorithms</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../dsa/complexity_analysis/intro.html">Complexity Analysis</a><input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-5"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../dsa/complexity_analysis/master_theorem.html">Master Theorem </a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../dsa/stack/intro.html">Stack</a><input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-6"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../dsa/stack/concept.html">Concept</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../dsa/searching_algorithms/linear_search/intro.html">Linear Search</a><input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-7"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../dsa/searching_algorithms/linear_search/concept.html">Concept</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../dsa/searching_algorithms/binary_search/intro.html">Binary Search</a><input class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-8"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../dsa/searching_algorithms/binary_search/concept.html">Concept</a></li>
<li class="toctree-l2"><a class="reference internal" href="../dsa/searching_algorithms/binary_search/problems/875-koko-eating-bananas.html">Koko Eating Bananas</a></li>
</ul>
</li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Linear Algebra</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../linear_algebra/01_preliminaries/intro.html">Preliminaries</a><input class="toctree-checkbox" id="toctree-checkbox-9" name="toctree-checkbox-9" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-9"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../linear_algebra/01_preliminaries/01-fields.html">Fields</a></li>
<li class="toctree-l2"><a class="reference internal" href="../linear_algebra/01_preliminaries/02-systems-of-linear-equations.html">Systems of Linear Equations</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../linear_algebra/02_vectors/intro.html">Vectors</a><input class="toctree-checkbox" id="toctree-checkbox-10" name="toctree-checkbox-10" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-10"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../linear_algebra/02_vectors/01-vector-definition.html">Vector and Its Definition</a></li>
<li class="toctree-l2"><a class="reference internal" href="../linear_algebra/02_vectors/02-vector-operation.html">Vector and Its Operations</a></li>
<li class="toctree-l2"><a class="reference internal" href="../linear_algebra/02_vectors/03-vector-norm.html">Vector Norm and Distance</a></li>
<li class="toctree-l2"><a class="reference internal" href="../linear_algebra/02_vectors/04-vector-products.html">A First Look at Vector Products</a></li>
</ul>
</li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">References, Resources and Roadmap</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../bibliography.html">Bibliography</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../_sources/transformer/concept.md" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.md</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm navbar-btn theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch nav-link" data-mode="light"><i class="fa-solid fa-sun fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="dark"><i class="fa-solid fa-moon fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="auto"><i class="fa-solid fa-circle-half-stroke fa-lg"></i></span>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary"title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</label>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Concept</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#motivation">Motivation</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#abstract">Abstract</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#introduction">Introduction</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#key-1-competent-generalists-over-narrow-experts-1">Key 1. Competent Generalists over Narrow Experts (1)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#key-2-iid-assumption-fails-in-real-world-2-3">Key 2. IID Assumption Fails in Real World (2, 3)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#key-3-multi-task-learning-is-nacent-4">Key 3. Multi-Task Learning is Nacent (4)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#key-4-from-word-embeddings-to-contextual-embeddings-5-6">Key 4. From Word Embeddings to Contextual Embeddings (5,6)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#key-5-zero-shot-learning-and-zero-shot-transfer-7">Key 5. Zero Shot Learning and Zero Shot Transfer (7)</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#approach">Approach</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#key-1-modeling-language-models-over-joint-probability-distributions-1">Key 1. Modeling Language Models over Joint Probability Distributions (1)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#key-2-conditional-distributions-2">Key 2. Conditional Distributions (2)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#key-3-conditional-on-task-3">Key 3. Conditional on Task (3)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#key-4-optimizing-unsupervised-is-the-same-as-optimizing-supervised-4">Key 4. Optimizing Unsupervised is the same as Optimizing Supervised (4)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#key-5-large-language-models-has-capacity-to-infer-and-generalize-5">Key 5. Large Language Models has Capacity to Infer and Generalize (5)</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#training-dataset">2.1. Training Dataset</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#key-1-rejection-of-commoncrawl-1-2">Key 1. Rejection of CommonCrawl (1,2)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#key-2-construction-of-webtext-dataset">Key 2. Construction of WebText Dataset</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#input-representation">2.2. Input Representation</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#key-1-byte-pair-encoding-bpe-1-2-3">Key 1. Byte Pair Encoding (BPE) (1,2,3)</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#model">2.3. Model</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#gpt-1-and-gpt-2">GPT-1 and GPT-2</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#autoregressive-self-supervised-learning-paradigm">Autoregressive Self-Supervised Learning Paradigm</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#autoregressive-self-supervised-learning">Autoregressive Self-Supervised Learning</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#estimation-of-the-conditional-probability-distribution">Estimation of the Conditional Probability Distribution</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#initial-condition-of-conditional-probability-distribution">Initial Condition of Conditional Probability Distribution</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#markov-assumption">Markov Assumption</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#the-estimator-function-is-smooth-with-respect-to-the-parameters">The Estimator Function is Smooth with Respect to the Parameters</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#context-length-and-token-context-window">Context Length and Token Context Window</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#conditional-entropy-and-perplexity-as-loss-function">Conditional Entropy and Perplexity as Loss Function</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#conditional-entropy">Conditional Entropy</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#perplexity">Perplexity</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#loss-function">Loss Function</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#convergence">Convergence</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#gpt-is-a-autoregressive-self-supervised-learning-model">GPT is a Autoregressive Self-Supervised Learning Model</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#conditional-on-task">Conditional on Task</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#supervised-fine-tuning">Supervised Fine-Tuning</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#objective-function-for-fine-tuning">Objective Function for Fine-Tuning</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#auxiliary-loss-function">Auxiliary Loss Function</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#references-and-further-readings">References and Further Readings</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="concept">
<h1>Concept<a class="headerlink" href="#concept" title="Permalink to this heading">#</a></h1>
<nav class="contents local" id="contents">
<ul class="simple">
<li><p><a class="reference internal" href="#motivation" id="id17">Motivation</a></p></li>
<li><p><a class="reference internal" href="#abstract" id="id18">Abstract</a></p></li>
<li><p><a class="reference internal" href="#introduction" id="id19">Introduction</a></p>
<ul>
<li><p><a class="reference internal" href="#key-1-competent-generalists-over-narrow-experts-1" id="id20">Key 1. Competent Generalists over Narrow Experts (1)</a></p></li>
<li><p><a class="reference internal" href="#key-2-iid-assumption-fails-in-real-world-2-3" id="id21">Key 2. IID Assumption Fails in Real World (2, 3)</a></p></li>
<li><p><a class="reference internal" href="#key-3-multi-task-learning-is-nacent-4" id="id22">Key 3. Multi-Task Learning is Nacent (4)</a></p></li>
<li><p><a class="reference internal" href="#key-4-from-word-embeddings-to-contextual-embeddings-5-6" id="id23">Key 4. From Word Embeddings to Contextual Embeddings (5,6)</a></p></li>
<li><p><a class="reference internal" href="#key-5-zero-shot-learning-and-zero-shot-transfer-7" id="id24">Key 5. Zero Shot Learning and Zero Shot Transfer (7)</a></p></li>
</ul>
</li>
<li><p><a class="reference internal" href="#approach" id="id25">Approach</a></p>
<ul>
<li><p><a class="reference internal" href="#key-1-modeling-language-models-over-joint-probability-distributions-1" id="id26">Key 1. Modeling Language Models over Joint Probability Distributions (1)</a></p></li>
<li><p><a class="reference internal" href="#key-2-conditional-distributions-2" id="id27">Key 2. Conditional Distributions (2)</a></p></li>
<li><p><a class="reference internal" href="#key-3-conditional-on-task-3" id="id28">Key 3. Conditional on Task (3)</a></p></li>
<li><p><a class="reference internal" href="#key-4-optimizing-unsupervised-is-the-same-as-optimizing-supervised-4" id="id29">Key 4. Optimizing Unsupervised is the same as Optimizing Supervised (4)</a></p></li>
<li><p><a class="reference internal" href="#key-5-large-language-models-has-capacity-to-infer-and-generalize-5" id="id30">Key 5. Large Language Models has Capacity to Infer and Generalize (5)</a></p></li>
</ul>
</li>
<li><p><a class="reference internal" href="#training-dataset" id="id31">2.1. Training Dataset</a></p>
<ul>
<li><p><a class="reference internal" href="#key-1-rejection-of-commoncrawl-1-2" id="id32">Key 1. Rejection of CommonCrawl (1,2)</a></p></li>
<li><p><a class="reference internal" href="#key-2-construction-of-webtext-dataset" id="id33">Key 2. Construction of WebText Dataset</a></p></li>
</ul>
</li>
<li><p><a class="reference internal" href="#input-representation" id="id34">2.2. Input Representation</a></p>
<ul>
<li><p><a class="reference internal" href="#key-1-byte-pair-encoding-bpe-1-2-3" id="id35">Key 1. Byte Pair Encoding (BPE) (1,2,3)</a></p></li>
</ul>
</li>
<li><p><a class="reference internal" href="#model" id="id36">2.3. Model</a></p></li>
<li><p><a class="reference internal" href="#gpt-1-and-gpt-2" id="id37">GPT-1 and GPT-2</a></p></li>
<li><p><a class="reference internal" href="#autoregressive-self-supervised-learning-paradigm" id="id38">Autoregressive Self-Supervised Learning Paradigm</a></p>
<ul>
<li><p><a class="reference internal" href="#autoregressive-self-supervised-learning" id="id39">Autoregressive Self-Supervised Learning</a></p></li>
<li><p><a class="reference internal" href="#estimation-of-the-conditional-probability-distribution" id="id40">Estimation of the Conditional Probability Distribution</a></p></li>
<li><p><a class="reference internal" href="#initial-condition-of-conditional-probability-distribution" id="id41">Initial Condition of Conditional Probability Distribution</a></p></li>
<li><p><a class="reference internal" href="#markov-assumption" id="id42">Markov Assumption</a></p></li>
<li><p><a class="reference internal" href="#the-estimator-function-is-smooth-with-respect-to-the-parameters" id="id43">The Estimator Function is Smooth with Respect to the Parameters</a></p></li>
<li><p><a class="reference internal" href="#context-length-and-token-context-window" id="id44">Context Length and Token Context Window</a></p></li>
<li><p><a class="reference internal" href="#conditional-entropy-and-perplexity-as-loss-function" id="id45">Conditional Entropy and Perplexity as Loss Function</a></p>
<ul>
<li><p><a class="reference internal" href="#conditional-entropy" id="id46">Conditional Entropy</a></p></li>
<li><p><a class="reference internal" href="#perplexity" id="id47">Perplexity</a></p></li>
<li><p><a class="reference internal" href="#loss-function" id="id48">Loss Function</a></p></li>
<li><p><a class="reference internal" href="#convergence" id="id49">Convergence</a></p></li>
</ul>
</li>
<li><p><a class="reference internal" href="#gpt-is-a-autoregressive-self-supervised-learning-model" id="id50">GPT is a Autoregressive Self-Supervised Learning Model</a></p></li>
<li><p><a class="reference internal" href="#conditional-on-task" id="id51">Conditional on Task</a></p></li>
<li><p><a class="reference internal" href="#supervised-fine-tuning" id="id52">Supervised Fine-Tuning</a></p>
<ul>
<li><p><a class="reference internal" href="#objective-function-for-fine-tuning" id="id53">Objective Function for Fine-Tuning</a></p></li>
<li><p><a class="reference internal" href="#auxiliary-loss-function" id="id54">Auxiliary Loss Function</a></p></li>
</ul>
</li>
</ul>
</li>
<li><p><a class="reference internal" href="#references-and-further-readings" id="id55">References and Further Readings</a></p></li>
</ul>
</nav>
<section id="motivation">
<h2><a class="toc-backref" href="#id17" role="doc-backlink">Motivation</a><a class="headerlink" href="#motivation" title="Permalink to this heading">#</a></h2>
<p>…</p>
</section>
<section id="abstract">
<h2><a class="toc-backref" href="#id18" role="doc-backlink">Abstract</a><a class="headerlink" href="#abstract" title="Permalink to this heading">#</a></h2>
<ul class="simple">
<li><p>All previous pretrained language models require a second stage supervised
fine-tuning to adapt to a specific task.</p></li>
<li><p>The authors demonstrated that language models, given enough capacity, and
enough data, can be adapted to a wide range of tasks without the need for
task-specific architectures.</p></li>
<li><p>When conditioned on a document and questions using the
<a class="reference external" href="https://huggingface.co/datasets/stanfordnlp/coqa">CoQA dataset</a> of 127,700+
training samples, essentially a question-answering task, the model is able
to match or exceed the performance of the 3 baselines.</p></li>
<li><p>The author emphasized that the capacity of the model is crucial for the
success of the zero-shot transfer and that the model’s performance scales
log-linearly with the number of parameters. This means that as the model
capacity increases logarithmically, the performance of the model increases
linearly.</p></li>
</ul>
</section>
<section id="introduction">
<h2><a class="toc-backref" href="#id19" role="doc-backlink">Introduction</a><a class="headerlink" href="#introduction" title="Permalink to this heading">#</a></h2>
<section id="key-1-competent-generalists-over-narrow-experts-1">
<h3><a class="toc-backref" href="#id20" role="doc-backlink">Key 1. Competent Generalists over Narrow Experts (1)</a><a class="headerlink" href="#key-1-competent-generalists-over-narrow-experts-1" title="Permalink to this heading">#</a></h3>
<ul class="simple">
<li><p>The mention of works by Krizhevsky et al. (2012), Sutskever et al. (2014),
and Amodei et al. (2016) points to machine learning systems with enough
capacity and trained on large datasets, and supervised fine-tuning, is very
successful in task specific domains such as image recognition, nlp tasks
etc.</p></li>
<li><p>However, such systems, termed as “narrow experts”, are fragile [Recht et al.
(2018)], as they are highly dependent on the specific training regime and
task. A slight pertubation to the input distribution can cause the model to
perform poorly.</p></li>
<li><p>The authors then expressed the desire for “competent generalists” that can
perform well across a wide range of tasks without the need for task-specific
architectures or supervised fine-tuning.</p></li>
</ul>
</section>
<section id="key-2-iid-assumption-fails-in-real-world-2-3">
<h3><a class="toc-backref" href="#id21" role="doc-backlink">Key 2. IID Assumption Fails in Real World (2, 3)</a><a class="headerlink" href="#key-2-iid-assumption-fails-in-real-world-2-3" title="Permalink to this heading">#</a></h3>
<ul class="simple">
<li><p>It goes without saying that the main machine learning goal is to generalize
on the unseen data points. However, to simplify machine learning objective
modeling, we often assume that the training and test data are drawn from the
same distribution, otherwise termed as the Independent and Identically
Distributed (i.i.d.) assumption.</p>
<ul>
<li><p>As an aside, the i.i.d. assumption has deep roots in statistical
modeling because it allows simplification of modeling, notably, we can
express
<a class="reference external" href="https://en.wikipedia.org/wiki/Independent_and_identically_distributed_random_variables">joint probability distributions as the product of marginal distributions</a>.</p></li>
<li><p>And techniques like resampling and cross validation with a holdout set
to evaluate performance are also based on the assumption that the
training and test data are drawn from the same distribution.</p></li>
</ul>
</li>
<li><p>However, as the authors highlighted, the i.i.d. assumption fails in the real
world. The distribution of the test data is often different from the
training data, and the model’s performance degrades significantly when the
test data distribution is different from the training data distribution.</p></li>
<li><p>They attribute this to the prevalence of <strong>single</strong> task training on
<strong>single</strong> domain datasets.</p></li>
</ul>
<p>More readings:</p>
<ul class="simple">
<li><p><a class="reference external" href="https://stats.stackexchange.com/questions/213464/on-the-importance-of-the-i-i-d-assumption-in-statistical-learning">https://stats.stackexchange.com/questions/213464/on-the-importance-of-the-i-i-d-assumption-in-statistical-learning</a></p></li>
<li><p><a class="reference external" href="https://en.wikipedia.org/wiki/Independent_and_identically_distributed_random_variables">https://en.wikipedia.org/wiki/Independent_and_identically_distributed_random_variables</a></p></li>
</ul>
</section>
<section id="key-3-multi-task-learning-is-nacent-4">
<h3><a class="toc-backref" href="#id22" role="doc-backlink">Key 3. Multi-Task Learning is Nacent (4)</a><a class="headerlink" href="#key-3-multi-task-learning-is-nacent-4" title="Permalink to this heading">#</a></h3>
<ul class="simple">
<li><p>The author then highlighted that multi-task learning is a promising
framework where by training a single model on multiple tasks simultaneously,
the model can then leverage generalizable latent space embeddings and
representations to perform well on multiple tasks.</p></li>
<li><p>It was then highlighted that recent work uses, for example, 10 (dataset,
objective) pairs to train a single model (this is
<a class="reference external" href="https://en.wikipedia.org/wiki/Meta-learning_(computer_science)">meta-learning</a>).</p>
<ul>
<li><p>What this means is that each dataset and objective is distinct.</p></li>
<li><p>For example, 1 dataset could be on sentiment data, with the objective of
predicting the sentiment of a sentence, while another dataset could be
on named entity recognition, with the objective of predicting the named
entities in a sentence.</p></li>
</ul>
</li>
<li><p>The challenge is then still rooted in the compilation, curation and
annotation of the datasets and objectives for the model to be generalizable.
So it still reduces to the original problem of single task training on
single domain datasets as we may need just as much curated data to train a
multi-task model as we would need to train multiple single task model. And
it may not scale since we are only looking at 10 (dataset, objective) pairs.</p></li>
</ul>
</section>
<section id="key-4-from-word-embeddings-to-contextual-embeddings-5-6">
<h3><a class="toc-backref" href="#id23" role="doc-backlink">Key 4. From Word Embeddings to Contextual Embeddings (5,6)</a><a class="headerlink" href="#key-4-from-word-embeddings-to-contextual-embeddings-5-6" title="Permalink to this heading">#</a></h3>
<ul>
<li><p>Initially, word embeddings (Word2Vec, GloVe) were used to represent words as
dense fixed-dimensional vectors in a continuous <span class="math notranslate nohighlight">\(D\)</span> dimensional space,
hinging on the fact that words occuring in similar contexts/documents are
similar semantically. These vectors were then used as input to a model to
perform a specific task.</p></li>
<li><p>The next advancement is capturing more contextual information by using
contextual embeddings, where the word embeddings are conditioned on the
entire context of the sentence. Recurrent Neural Networks (RNNs) is one
example and the context embeddings can be “transferred” to other downstream
tasks.</p>
<p>From what I understand, unidirectional RNNs can only capture the context
information from the past, while bidirectional RNNs can capture the context
information from both the past and the future. However, both methods have
its limitations in capturing long-range dependencies.</p>
<p>Furthermore, RNN has a
<a class="reference external" href="https://ai.stackexchange.com/questions/20075/why-does-the-transformer-do-better-than-rnn-and-lstm-in-long-range-context-depen">well known problem in gradient vanishing</a>
which means that the model is biased by the most recent tokens in the
sequence, and the model’s performance degrades as the sequence length
increases.</p>
</li>
<li><p>Full contextual capture via self-attention, allow each token in the sequence
to simultaneously attend to all other tokens in the sequence, and the
attention weights are learned during training. This allows the model to
capture long-range dependencies and is the basis for the Transformer
architecture. Consequently, self-attention is non-sequential by design and
operates over a <em>set</em> of tokens, and not a <em>sequence</em> of tokens. This calls
for the need to introduce positional encodings to the input embeddings to
capture the sequential nature of the tokens.</p>
<p>This offers a significant leap over word embedding era where the embeddings
are static. Now, given two sentences, <em>I went to the river bank</em> versus <em>i
went to the bank to withdraw money</em>, the word “bank” in the first sentence
is semantically different from the word “bank” in the second sentence. The
contextual embeddings can capture this difference.</p>
</li>
<li><p>The authors then went on to mention that the above methods would still
require supervised fine-tuning to adapt to a specific task.</p>
<p>If there are minimal or no supervised data is available, there are other
lines of work using language model to handle it - commonsense reasoning
(Schwartz et al., 2017) and sentiment analysis (Radford et al., 2017).</p>
</li>
</ul>
<p>Further readings:</p>
<ul class="simple">
<li><p><a class="reference external" href="https://ai.stackexchange.com/questions/20075/why-does-the-transformer-do-better-than-rnn-and-lstm-in-long-range-context-depen">https://ai.stackexchange.com/questions/20075/why-does-the-transformer-do-better-than-rnn-and-lstm-in-long-range-context-depen</a></p></li>
<li><p><a class="reference external" href="https://stackoverflow.com/questions/55158554/how-transformer-is-bidirectional-machine-learning">https://stackoverflow.com/questions/55158554/how-transformer-is-bidirectional-machine-learning</a></p></li>
</ul>
</section>
<section id="key-5-zero-shot-learning-and-zero-shot-transfer-7">
<h3><a class="toc-backref" href="#id24" role="doc-backlink">Key 5. Zero Shot Learning and Zero Shot Transfer (7)</a><a class="headerlink" href="#key-5-zero-shot-learning-and-zero-shot-transfer-7" title="Permalink to this heading">#</a></h3>
<ul>
<li><p>The authors then went on to mention that continuing from the two lines of
work above, they continue the trend of using general methods of transfer to
demonstrate that language models can perform down-stream tasks in a
zero-shot manner, without any parameter or architecture modification.</p></li>
<li><p>Zero-shot learning (ZSL) refers to the ability of a model to correctly
perform tasks or recognize categories it has never encountered during its
training phase. The essence of ZSL is to generalize from seen to unseen
classes or tasks by leveraging side information or semantic relationships.
For example, a model trained to recognize on a set of animals (including
horses) but not on zebra, should be able to recognize a zebra as something
close to horse, given the semantic relationship between the two animals.</p>
<p>TODO: may need further clarification: Furthermore, we can actually pass an
unseen label and a zebra image. How? Con</p>
</li>
<li><p>Zero-shot transfer, often discussed within the context of transfer learning,
involves applying a model trained on one set of tasks or domains to a
completely new task or domain without any additional training. Here, the
focus is on the transferability of learned features or knowledge across
different but related tasks or domains. Zero-shot transfer extends the
concept of transfer learning by not requiring any examples from the target
domain during training, relying instead on the model’s ability to generalize
across different contexts based on its pre-existing knowledge.</p></li>
</ul>
<p>Further readings:</p>
<ul class="simple">
<li><p><a class="reference external" href="https://en.wikipedia.org/wiki/Zero-shot_learning">Zero shot learning - Wikipedia</a></p></li>
<li><p><a class="reference external" href="https://ai.stackexchange.com/questions/21719/what-is-the-difference-between-one-shot-learning-transfer-learning-and-fine-tun">https://ai.stackexchange.com/questions/21719/what-is-the-difference-between-one-shot-learning-transfer-learning-and-fine-tun</a></p></li>
<li><p><a class="reference external" href="https://joeddav.github.io/blog/2020/05/29/ZSL.html">https://joeddav.github.io/blog/2020/05/29/ZSL.html</a></p></li>
<li><p><a class="reference external" href="https://arxiv.org/abs/1301.3666">https://arxiv.org/abs/1301.3666</a></p></li>
<li><p><a class="reference external" href="https://ai.stackexchange.com/questions/23527/zero-shot-learning-available-labels-in-testing-set">https://ai.stackexchange.com/questions/23527/zero-shot-learning-available-labels-in-testing-set</a></p></li>
<li><p><a class="reference external" href="https://www.theaidream.com/post/zero-shot-learning-can-you-classify-an-object-without-seeing-it-before">https://www.theaidream.com/post/zero-shot-learning-can-you-classify-an-object-without-seeing-it-before</a></p></li>
<li><p><a class="reference external" href="https://dl.acm.org/doi/10.1145/3293318">https://dl.acm.org/doi/10.1145/3293318</a></p></li>
</ul>
</section>
</section>
<section id="approach">
<h2><a class="toc-backref" href="#id25" role="doc-backlink">Approach</a><a class="headerlink" href="#approach" title="Permalink to this heading">#</a></h2>
<section id="key-1-modeling-language-models-over-joint-probability-distributions-1">
<h3><a class="toc-backref" href="#id26" role="doc-backlink">Key 1. Modeling Language Models over Joint Probability Distributions (1)</a><a class="headerlink" href="#key-1-modeling-language-models-over-joint-probability-distributions-1" title="Permalink to this heading">#</a></h3>
</section>
<section id="key-2-conditional-distributions-2">
<h3><a class="toc-backref" href="#id27" role="doc-backlink">Key 2. Conditional Distributions (2)</a><a class="headerlink" href="#key-2-conditional-distributions-2" title="Permalink to this heading">#</a></h3>
</section>
<section id="key-3-conditional-on-task-3">
<h3><a class="toc-backref" href="#id28" role="doc-backlink">Key 3. Conditional on Task (3)</a><a class="headerlink" href="#key-3-conditional-on-task-3" title="Permalink to this heading">#</a></h3>
</section>
<section id="key-4-optimizing-unsupervised-is-the-same-as-optimizing-supervised-4">
<h3><a class="toc-backref" href="#id29" role="doc-backlink">Key 4. Optimizing Unsupervised is the same as Optimizing Supervised (4)</a><a class="headerlink" href="#key-4-optimizing-unsupervised-is-the-same-as-optimizing-supervised-4" title="Permalink to this heading">#</a></h3>
</section>
<section id="key-5-large-language-models-has-capacity-to-infer-and-generalize-5">
<h3><a class="toc-backref" href="#id30" role="doc-backlink">Key 5. Large Language Models has Capacity to Infer and Generalize (5)</a><a class="headerlink" href="#key-5-large-language-models-has-capacity-to-infer-and-generalize-5" title="Permalink to this heading">#</a></h3>
</section>
</section>
<section id="training-dataset">
<h2><a class="toc-backref" href="#id31" role="doc-backlink">2.1. Training Dataset</a><a class="headerlink" href="#training-dataset" title="Permalink to this heading">#</a></h2>
<section id="key-1-rejection-of-commoncrawl-1-2">
<h3><a class="toc-backref" href="#id32" role="doc-backlink">Key 1. Rejection of CommonCrawl (1,2)</a><a class="headerlink" href="#key-1-rejection-of-commoncrawl-1-2" title="Permalink to this heading">#</a></h3>
<ul class="simple">
<li><p>Prior work usually involves training language model on single domain
datasets (link back to narrow experts).</p></li>
<li><p>But in order to achieve competent generalists, the authors argue that the
model should be trained on a diverse range of tasks and domains.</p></li>
<li><p>CommonCrawl, hosts a huge amount of webscrapes (basically the entire
internet) and is considered a diverse dataset.</p></li>
<li><p>However, the authors rejected CommonCrawl because it has severe data quality
issues.</p></li>
</ul>
</section>
<section id="key-2-construction-of-webtext-dataset">
<h3><a class="toc-backref" href="#id33" role="doc-backlink">Key 2. Construction of WebText Dataset</a><a class="headerlink" href="#key-2-construction-of-webtext-dataset" title="Permalink to this heading">#</a></h3>
<ul class="simple">
<li><p>The authors aimed to create a web scrape that emphasizes document quality
over quantity.</p></li>
<li><p>To ensure a level of document quality without incurring the prohibitive
costs of manual filtering, the authors leveraged human curation indirectly
by scraping all outbound links from Reddit that received at least 3 karma.
Karma in this context serves as a heuristic for content that is interesting,
educational, or entertaining as judged by Reddit users.</p>
<ul>
<li><p>What this outbound link mean is if a reddit post has an outbound link to
another website, the authors scraped the content of the website if the
post received at least 3 karma.</p></li>
</ul>
</li>
<li><p>The resulting dataset, named WebText, contains of text from about 45 million
links curated by Reddit users.</p></li>
<li><p>Further preprocessing such as de-duplication, heuristic based cleaning, as
well as filtering out Wikipedia links resulted in about 40gb of text (8
million documents).</p></li>
<li><p>The snapshot of the dataset is December 2017.</p></li>
<li><p>The exclusion of Wikipedia is made because the authors believe it is a
common source of training data for other works, and in order to
evaluate/test their model on other datasets with little leakage, they
excluded Wikipedia.</p></li>
</ul>
</section>
</section>
<section id="input-representation">
<h2><a class="toc-backref" href="#id34" role="doc-backlink">2.2. Input Representation</a><a class="headerlink" href="#input-representation" title="Permalink to this heading">#</a></h2>
<section id="key-1-byte-pair-encoding-bpe-1-2-3">
<h3><a class="toc-backref" href="#id35" role="doc-backlink">Key 1. Byte Pair Encoding (BPE) (1,2,3)</a><a class="headerlink" href="#key-1-byte-pair-encoding-bpe-1-2-3" title="Permalink to this heading">#</a></h3>
<ul class="simple">
<li><p>The authors highlighted traditional ways of tokenization, includes
lower-casing, punctuation stripping, and splitting on white spaces, as well
as encode unknown vocabulary with a special token so that the model can
learn to handle unseen words in eval/test time.</p>
<ul>
<li><p>An example is LM are bad at analyzing emojis.</p></li>
</ul>
</li>
<li><p>However, the authors mentioned this way restricts the natural language input
space <span class="math notranslate nohighlight">\(\mathcal{X}\)</span> and therefore limit the model space <span class="math notranslate nohighlight">\(\mathcal{H}\)</span>, as
the latter is a function of the former.</p></li>
<li><p>To resolve this, the idea of byte-level encoding can be used - since you
theoretically can encode any character in the world in UTF-8.</p></li>
<li><p>However, the limitation is current byte-level LMs tend to perform poorly on
word level tasks.</p></li>
<li><p>The authors then introduced the BPE algorithm (is “byte-level” because it
operates on UTF-8 encoded strings) where they striked a balance between
character-level and word-level tokenization.</p></li>
<li><p>So in summary, BPE is the tokenizer used to encode the input text into a
sequence of tokens - which form the input representation to the model.</p></li>
</ul>
<p>More readings (honestly not well-versed with BPE):</p>
<ul class="simple">
<li><p><a class="github reference external" href="https://github.com/karpathy/minbpe">karpathy/minbpe</a></p></li>
<li><p><a class="reference external" href="https://huggingface.co/learn/nlp-course/en/chapter6/5">https://huggingface.co/learn/nlp-course/en/chapter6/5</a></p></li>
</ul>
</section>
</section>
<section id="model">
<h2><a class="toc-backref" href="#id36" role="doc-backlink">2.3. Model</a><a class="headerlink" href="#model" title="Permalink to this heading">#</a></h2>
<p>…</p>
</section>
<section id="gpt-1-and-gpt-2">
<h2><a class="toc-backref" href="#id37" role="doc-backlink">GPT-1 and GPT-2</a><a class="headerlink" href="#gpt-1-and-gpt-2" title="Permalink to this heading">#</a></h2>
<p>In Natural Language Understanding (NLU), there are a wide range of tasks, such
as textual entailment, question answering, semantic similarity assessment, and
document classification. These tasks are inherently labeled, but given the
scarcity of such data, it makes
<a class="reference external" href="https://en.wikipedia.org/wiki/Discriminative_model">discriminative</a> models such
as Bidirectional Long Short-Term Memory (Bi-LSTM) underperform
<span id="id1">[<a class="reference internal" href="../bibliography.html#id15" title="Alec Radford, Karthik Narasimhan, Tim Salimans, and Ilya Sutskever. Improving language understanding by generative pre-training. 2018.">Radford <em>et al.</em>, 2018</a>]</span>, likely leading to poor performance on these tasks.</p>
<p>In the paper
<a class="reference external" href="https://cdn.openai.com/research-covers/language-unsupervised/language_understanding_paper.pdf"><em>Improving Language Understanding by Generative Pre-Training</em></a>,
the authors demonstrated that <em>generative pre-training</em> of a language model on a
diverse corpus of unlabeled text, followed by <em>discriminative fine-tuning</em> on
each specific task, can overcome the constraints of the small amount of
annotated data for these specific tasks. The process is collectively termed as
<a class="reference external" href="https://en.wikipedia.org/wiki/Semi-supervised_learning">semi-supervised learning</a>
and the goal is to learn an <strong><em>universal representation</em></strong> of the natural
language space that can be used across a wide range of tasks.</p>
<p>The pretraining objective is to predict the next token in a sequence, in an
<strong><em>autoregressive</em></strong> manner, given the previous tokens. The pretrained model,
often known as the <strong><em>foundational model</em></strong> (or <em>backbone</em>), serves as a base
from which specialized capabilities can be added through <em>fine-tuning</em> on
specific tasks. In the fine-tuning phase, task-specific adaptations are
necessary: the input format must be adjusted to align with the particular
requirements of the task at hand, and the model’s final layer—or “head”—needs to
be replaced to accommodate the task’s specific class structure. The author
showed that this approach yielded state-of-the-art results on a wide range of
NLU tasks.</p>
<p>Notwithstanding the success of this approach, the same set of authors came up
with a new paper in the following year, titled
<a class="reference external" href="https://cdn.openai.com/better-language-models/language_models_are_unsupervised_multitask_learners.pdf"><em>Language Models are Unsupervised Multitask Learners</em></a>,
where they introduced a new model, <em>GPT-2</em>, that was larger in model capacity,
and trained on a much larger unlabeled corpus, <strong>WebText</strong>. However, the key
innovation was to void the supervised fine-tuning step, and instead, they
demonstrated that GPT-2 could be used directly on a wide range of NLU tasks
directly, with what they termed as the <em>zero-shot transfer</em>. The motivation is
that the authors think that foundational language models should be competent
generalists, rather than narrowly experts <span id="id2">[<a class="reference internal" href="../bibliography.html#id10" title="Alec Radford, Jeff Wu, Rewon Child, David Luan, Dario Amodei, and Ilya Sutskever. Language models are unsupervised multitask learners. 2019.">Radford <em>et al.</em>, 2019</a>]</span>. They call
for the need to shift the language model paradigm to one that is generic enough
to handle NLU tasks without the need to curate specific training data for each
specific task.</p>
<p>In what follows, we take a look how the authors formalized the framework. We
start by defining certain definitions and notations that will be used throughout
this article.</p>
</section>
<section id="autoregressive-self-supervised-learning-paradigm">
<h2><a class="toc-backref" href="#id38" role="doc-backlink">Autoregressive Self-Supervised Learning Paradigm</a><a class="headerlink" href="#autoregressive-self-supervised-learning-paradigm" title="Permalink to this heading">#</a></h2>
<p>Let <span class="math notranslate nohighlight">\(\mathcal{D}\)</span> be the true but unknown distribution of the natural language
space. In the context of unsupervised learning with self-supervision, such as
language modeling, we consider both the inputs and the implicit labels derived
from the same data sequence. Thus, while traditionally we might decompose the
distribution <span class="math notranslate nohighlight">\(\mathcal{D}\)</span> of a supervised learning task into input space
<span class="math notranslate nohighlight">\(\mathcal{X}\)</span> and label space <span class="math notranslate nohighlight">\(\mathcal{Y}\)</span>, in this scenario, <span class="math notranslate nohighlight">\(\mathcal{X}\)</span> and
<span class="math notranslate nohighlight">\(\mathcal{Y}\)</span> are intrinsically linked, because <span class="math notranslate nohighlight">\(\mathcal{Y}\)</span> is a shifted
version of <span class="math notranslate nohighlight">\(\mathcal{X}\)</span>, and so we can consider <span class="math notranslate nohighlight">\(\mathcal{D}\)</span> as a distribution
over <span class="math notranslate nohighlight">\(\mathcal{X}\)</span> only.</p>
<p>Since <span class="math notranslate nohighlight">\(\mathcal{D}\)</span> is a distribution, we also define it as a probability
distribution over <span class="math notranslate nohighlight">\(\mathcal{X}\)</span>, and we can write it as:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{aligned}
\mathcal{D} &amp;= \mathbb{P}(\mathcal{X} ; \boldsymbol{\Theta}) \\
            &amp;= \mathbb{P}_{\{\mathcal{X} ; \boldsymbol{\Theta}\}}(\mathbf{x})
\end{aligned}
\end{split}\]</div>
<p>where <span class="math notranslate nohighlight">\(\boldsymbol{\Theta}\)</span> is the parameter space that defines the distribution
<span class="math notranslate nohighlight">\(\mathbb{P}(\mathcal{X} ; \boldsymbol{\Theta})\)</span> and <span class="math notranslate nohighlight">\(\mathbf{x}\)</span> is a sample
from <span class="math notranslate nohighlight">\(\mathcal{X}\)</span> generated by the distribution <span class="math notranslate nohighlight">\(\mathcal{D}\)</span>. It is common to
treat <span class="math notranslate nohighlight">\(\mathbf{x}\)</span> as a sequence of tokens (i.e. a sentence is a sequence of
tokens), and we can write <span class="math notranslate nohighlight">\(\mathbf{x} = \left(x_1, x_2, \ldots, x_T\right)\)</span>,
where <span class="math notranslate nohighlight">\(T\)</span> is the length of the sequence.</p>
<p>Given such a sequence <span class="math notranslate nohighlight">\(\mathbf{x}\)</span>, the joint probability of the sequence can be
factorized into the product of the conditional probabilities of each token in
the sequence via the
<a class="reference external" href="https://en.wikipedia.org/wiki/Chain_rule_(probability)">chain rule of probability</a>:</p>
<div class="math notranslate nohighlight">
\[
\mathbb{P}(\mathbf{x} ; \boldsymbol{\Theta}) = \prod_{t=1}^T \mathbb{P}(x_t \mid x_1, x_2, \ldots, x_{t-1} ; \boldsymbol{\Theta})
\]</div>
<p>We can do this because natural language are <em>inherently ordered</em>. Such
decomposition allows for <em>tractable sampling</em> from and <em>estimation</em> of the
distribution <span class="math notranslate nohighlight">\(\mathbb{P}(\mathbf{x} ; \boldsymbol{\Theta})\)</span> as well as any
conditionals in the form of
<span class="math notranslate nohighlight">\(\mathbb{P}(x_{t-k}, x_{t-k+1}, \ldots, x_{t} \mid x_{1}, x_{2}, \ldots, x_{t-k-1} ; \boldsymbol{\Theta})\)</span>
<span id="id3">[<a class="reference internal" href="../bibliography.html#id10" title="Alec Radford, Jeff Wu, Rewon Child, David Luan, Dario Amodei, and Ilya Sutskever. Language models are unsupervised multitask learners. 2019.">Radford <em>et al.</em>, 2019</a>]</span>.</p>
<p>To this end, consider a corpus <span class="math notranslate nohighlight">\(\mathcal{S}\)</span> with <span class="math notranslate nohighlight">\(N\)</span> sequences
<span class="math notranslate nohighlight">\(\left\{\mathbf{x}_{1}, \mathbf{x}_{2}, \ldots, \mathbf{x}_{N}\right\}\)</span>,</p>
<div class="math notranslate nohighlight">
\[
\mathcal{S} = \left\{\mathbf{x}_{1}, \mathbf{x}_{2}, \ldots, \mathbf{x}_{N}\right\} \underset{\text{i.i.d.}}{\sim} \mathcal{D}
\]</div>
<p>where each sequence <span class="math notranslate nohighlight">\(\mathbf{x}_{n}\)</span> is a sequence of tokens that are sampled
<span class="math notranslate nohighlight">\(\text{i.i.d.}\)</span> from the distribution <span class="math notranslate nohighlight">\(\mathcal{D}\)</span>.</p>
<p>Then, we can frame the
<a class="reference external" href="https://gao-hongnan.github.io/gaohn-galaxy/probability_theory/08_estimation_theory/maximum_likelihood_estimation/concept.html">likelihood function</a>
<span class="math notranslate nohighlight">\(\hat{\mathcal{L}}(\cdot)\)</span> as the likelihood of observing the sequences in the
corpus <span class="math notranslate nohighlight">\(\mathcal{S}\)</span>,</p>
<div class="math notranslate nohighlight">
\[
\hat{\mathcal{L}}\left(\mathcal{S} ; \hat{\boldsymbol{\Theta}}\right) = \prod_{n=1}^N \mathbb{P}(\mathbf{x}_{n} ; \hat{\boldsymbol{\Theta}})
\]</div>
<p>where <span class="math notranslate nohighlight">\(\hat{\boldsymbol{\Theta}}\)</span> is the estimated parameter space that
approximates the true parameter space <span class="math notranslate nohighlight">\(\boldsymbol{\Theta}\)</span>.</p>
<p>Subsequently, the objective function is now well-defined, to be the maximization
of the likelihood of the sequences in the corpus <span class="math notranslate nohighlight">\(\mathcal{S}\)</span>,</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{aligned}
\hat{\boldsymbol{\theta}}^{*} &amp;= \underset{\hat{\boldsymbol{\theta}} \in \boldsymbol{\Theta}}{\text{argmax}} \hat{\mathcal{L}}\left(\mathcal{S} ; \hat{\boldsymbol{\Theta}}\right) \\
                              &amp;= \underset{\hat{\boldsymbol{\theta}} \in \boldsymbol{\Theta}}{\text{argmax}} \prod_{n=1}^N \mathbb{P}(\mathbf{x}_{n} ; \hat{\boldsymbol{\Theta}}) \\
                              &amp;= \underset{\hat{\boldsymbol{\theta}} \in \boldsymbol{\Theta}}{\text{argmax}} \prod_{n=1}^N \prod_{t=1}^{T_n} \mathbb{P}(x_{n, t} \mid x_{n, 1}, x_{n, 2}, \ldots, x_{n, t-1} ; \hat{\boldsymbol{\Theta}}) \\
\end{aligned}
\end{split}\]</div>
<p>where <span class="math notranslate nohighlight">\(T_n\)</span> is the length of the sequence <span class="math notranslate nohighlight">\(\mathbf{x}_{n}\)</span>.</p>
<p>Owing to the fact that multiplying many probabilities together can lead to
<a class="reference external" href="https://d2l.ai/chapter_appendix-mathematics-for-deep-learning/maximum-likelihood.html#numerical-optimization-and-the-negative-log-likelihood">numerical instability</a>
because the product of many probabilities can be very small, it is common and
necessary to use the log-likelihood as the objective function, because it can be
proven that maximizing the log-likelihood is equivalent to maximizing the
likelihood itself.</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{aligned}
\hat{\boldsymbol{\theta}}^{*} &amp;= \underset{\hat{\boldsymbol{\theta}} \in \boldsymbol{\Theta}}{\text{argmax}} \log\left(\hat{\mathcal{L}}\left(\mathcal{S} ; \hat{\boldsymbol{\Theta}}\right)\right) \\
&amp;= \underset{\hat{\boldsymbol{\theta}} \in \boldsymbol{\Theta}}{\text{argmax}} \sum_{n=1}^N \sum_{t=1}^{T_n} \log \mathbb{P}(x_{n, t} \mid x_{n, 1}, x_{n, 2}, \ldots, x_{n, t-1} ; \hat{\boldsymbol{\Theta}}) \\
\end{aligned}
\end{split}\]</div>
<p>Furthermore, since we are treating the the loss function as a form of
minimization, we can simply negate the log-likelihood to obtain the negative
log-likelihood as the objective function to be minimized,</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{aligned}
\hat{\boldsymbol{\theta}}^{*} &amp;= \underset{\hat{\boldsymbol{\theta}} \in \boldsymbol{\Theta}}{\text{argmin}} \left(-\log\left(\hat{\mathcal{L}}\left(\mathcal{S} ; \hat{\boldsymbol{\Theta}}\right)\right)\right) \\
&amp;= \underset{\hat{\boldsymbol{\theta}} \in \boldsymbol{\Theta}}{\text{argmin}} \left(-\sum_{n=1}^N \sum_{t=1}^{T_n} \log \mathbb{P}(x_{n, t} \mid x_{n, 1}, x_{n, 2}, \ldots, x_{n, t-1} ; \hat{\boldsymbol{\Theta}})\right) \\
\end{aligned}
\end{split}\]</div>
<p>It is worth noting that the objective function is a function of the parameter
space <span class="math notranslate nohighlight">\(\hat{\boldsymbol{\Theta}}\)</span>, and not the data <span class="math notranslate nohighlight">\(\mathcal{S}\)</span>, so all
analysis such as convergence and consistency will be with respect to the
parameter space <span class="math notranslate nohighlight">\(\hat{\boldsymbol{\Theta}}\)</span>.</p>
<p>To this end, we denote the GPT model <span class="math notranslate nohighlight">\(\mathcal{G}\)</span> to be an <em>autoregressive</em> and
<em>self-supervised learning</em> model that is trained to maximize the likelihood of
observing all data points <span class="math notranslate nohighlight">\(\mathbf{x} \in \mathcal{S}\)</span> via the objective
function <span class="math notranslate nohighlight">\(\hat{\mathcal{L}}\left(\mathcal{S} ; \hat{\boldsymbol{\Theta}}\right)\)</span>
by learning the conditional probability distribution
<span class="math notranslate nohighlight">\(\mathbb{P}(x_t \mid x_{&lt;t} ; \hat{\boldsymbol{\Theta}})\)</span> over the vocabulary
<span class="math notranslate nohighlight">\(\mathcal{V}\)</span> of tokens, conditioned on the contextual preciding tokens
<span class="math notranslate nohighlight">\(x_{&lt;t} = \left(x_1, x_2, \ldots, x_{t-1}\right)\)</span>. We are clear that although
the goal is to model the joint probability distribution of the token sequences,
we can do so by estimating the joint probability distribution via the
conditional probability distributions.</p>
<div class="proof remark admonition" id="decoder-simplified-objective-function">
<p class="admonition-title"><span class="caption-number">Remark 1 </span> (Simplification of the Objective Function)</p>
<section class="remark-content" id="proof-content">
<p>In what follows, we will mostly focus on the inner summand of the objective
function, namely, we will look at the loss function for a single sequence
<span class="math notranslate nohighlight">\(\mathbf{x}\)</span>. And in particular the conditional probability distribution
<span class="math notranslate nohighlight">\(\mathbb{P}(x_t \mid x_{&lt;t} ; \hat{\boldsymbol{\Theta}})\)</span>. It should be clear
that the objective function is over all <span class="math notranslate nohighlight">\(N\)</span> sequences in the corpus <span class="math notranslate nohighlight">\(\mathcal{S}\)</span>,
where each sequence <span class="math notranslate nohighlight">\(\mathbf{x}_n\)</span> can be decomposed into the product of the
conditional probabilities of each token in the sequence.</p>
</section>
</div><section id="autoregressive-self-supervised-learning">
<h3><a class="toc-backref" href="#id39" role="doc-backlink">Autoregressive Self-Supervised Learning</a><a class="headerlink" href="#autoregressive-self-supervised-learning" title="Permalink to this heading">#</a></h3>
<p>The learning paradigm of an autoregressive self-supervised learning framework
can be formalized as a learning algorithm <span class="math notranslate nohighlight">\(\mathcal{A}\)</span> that is trained to
predict the next token <span class="math notranslate nohighlight">\(x_t\)</span> in a sequence given the previous tokens
<span class="math notranslate nohighlight">\(x_{&lt;t} = \left(x_1, x_2, \ldots, x_{t-1}\right)\)</span> in the sequence <span class="math notranslate nohighlight">\(\mathbf{x}\)</span>
(<em>autoregressive</em>), where <span class="math notranslate nohighlight">\(t \in \{1, 2, \ldots, T\}\)</span> is the position of the
token in the sequence, and <em>self-supervised</em> because the “label” <span class="math notranslate nohighlight">\(x_t\)</span> is
derived from the input sequence <span class="math notranslate nohighlight">\(\mathbf{x}\)</span> itself. The model <span class="math notranslate nohighlight">\(\mathcal{G}\)</span>
then uses <span class="math notranslate nohighlight">\(\mathcal{A}\)</span> to learn a <strong><em>conditional probability distribution</em></strong>
<span class="math notranslate nohighlight">\(\mathbb{P}(x_t \mid x_{&lt;t} ; \boldsymbol{\Theta})\)</span> over the vocabulary
<span class="math notranslate nohighlight">\(\mathcal{V}\)</span> of tokens, conditioned on the contextual preciding tokens
<span class="math notranslate nohighlight">\(x_{&lt;t} = \left(x_1, x_2, \ldots, x_{t-1}\right)\)</span>, where <span class="math notranslate nohighlight">\(\boldsymbol{\Theta}\)</span>
is the parameter space that defines the distribution
<span class="math notranslate nohighlight">\(\mathbb{P}(x_t \mid x_{&lt;t} ; \boldsymbol{\Theta})\)</span>.</p>
<p>The distinction between <span class="math notranslate nohighlight">\(\mathcal{V}\)</span> and <span class="math notranslate nohighlight">\(\mathcal{X}\)</span> is that <span class="math notranslate nohighlight">\(\mathcal{V}\)</span> is
the vocabulary of tokens, which is a discrete space, and <span class="math notranslate nohighlight">\(\mathcal{X}\)</span> is the
natural language space, which is a combinatorial discrete space. We can think of
<span class="math notranslate nohighlight">\(\mathcal{X}\)</span> as the natural language space of <em><strong>all possible sequences</strong></em>
<span class="math notranslate nohighlight">\(\mathbf{x}\)</span> that can be formed from the vocabulary <span class="math notranslate nohighlight">\(\mathcal{V}\)</span> (an
enumeration over <span class="math notranslate nohighlight">\(\mathcal{V}\)</span>). Consequently, there is no confusion that a
<em>sequence</em> <span class="math notranslate nohighlight">\(\mathbf{x}\)</span> is a member of <span class="math notranslate nohighlight">\(\mathcal{X}\)</span>, and a <em>token</em> <span class="math notranslate nohighlight">\(x_t\)</span> is a
member of <span class="math notranslate nohighlight">\(\mathcal{V}\)</span>.</p>
<p>Through this learning algorithm, we can recover all chained conditional
probabilities of the form <span class="math notranslate nohighlight">\(\mathbb{P}(x_t \mid x_{&lt;t} ; \boldsymbol{\Theta})\)</span>,
which implicitly defines the joint probability distribution
<span class="math notranslate nohighlight">\(\mathbb{P}(\mathbf{x}
; \boldsymbol{\Theta})\)</span> over the natural language space
<span class="math notranslate nohighlight">\(\mathcal{X}\)</span><a class="footnote-reference brackets" href="#id16" id="id4" role="doc-noteref"><span class="fn-bracket">[</span>1<span class="fn-bracket">]</span></a>.</p>
</section>
<section id="estimation-of-the-conditional-probability-distribution">
<h3><a class="toc-backref" href="#id40" role="doc-backlink">Estimation of the Conditional Probability Distribution</a><a class="headerlink" href="#estimation-of-the-conditional-probability-distribution" title="Permalink to this heading">#</a></h3>
<p>In practice, we can only <em><strong>estimate</strong></em> the conditional probability distribution
<span class="math notranslate nohighlight">\(\mathbb{P}(x_t \mid x_{&lt;t} ; \boldsymbol{\Theta})\)</span> from the corpus
<span class="math notranslate nohighlight">\(\mathcal{S}\)</span>, and we can write the process of estimating as:</p>
<div class="math notranslate nohighlight">
\[
\hat{\mathbb{P}}(x_t \mid x_{&lt;t} ; \hat{\boldsymbol{\Theta}}) \approx \mathbb{P}(x_t \mid x_{&lt;t} ; \boldsymbol{\Theta})
\]</div>
<p>where <span class="math notranslate nohighlight">\(\hat{\boldsymbol{\Theta}}\)</span> is the estimated parameter space that
approximates the true parameter space <span class="math notranslate nohighlight">\(\boldsymbol{\Theta}\)</span>.</p>
<p>To facilitate the notational burden, we denote the estimated conditional
probability distribution
<span class="math notranslate nohighlight">\(\hat{\mathbb{P}}(x_t \mid x_{&lt;t} ; \hat{\boldsymbol{\Theta}})\)</span> as a function
<span class="math notranslate nohighlight">\(f_{\hat{\boldsymbol{\Theta}}}(\cdot)\)</span>, and equate them as:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{aligned}
f_{\hat{\boldsymbol{\Theta}}}(x_t \mid x_{&lt;t}) &amp;:= \mathbb{P}(x_t \mid x_{&lt;t} ; \boldsymbol{\Theta}) \\
\end{aligned}
\end{split}\]</div>
<p>where <span class="math notranslate nohighlight">\(f_{\hat{\boldsymbol{\Theta}}}(x_t \mid x_{&lt;t})\)</span> can be realised as our
GPT model <span class="math notranslate nohighlight">\(\mathcal{G}\)</span>.</p>
<p>To this end, we should be clear that this learning process is to approximate the
true distribution <span class="math notranslate nohighlight">\(\mathcal{D}\)</span> of the natural language space <span class="math notranslate nohighlight">\(\mathcal{X}\)</span>, but
instead of modeling over the entire space <span class="math notranslate nohighlight">\(\mathcal{X}\)</span>, consisting of all
sequences <span class="math notranslate nohighlight">\(\mathbf{x}\)</span>, we model over the vocabulary <span class="math notranslate nohighlight">\(\mathcal{V}\)</span> of tokens,
which is to generate the next token in a sequence given the previous tokens in
the sequence.</p>
</section>
<section id="initial-condition-of-conditional-probability-distribution">
<h3><a class="toc-backref" href="#id41" role="doc-backlink">Initial Condition of Conditional Probability Distribution</a><a class="headerlink" href="#initial-condition-of-conditional-probability-distribution" title="Permalink to this heading">#</a></h3>
<p>While the earlier conditional distribution seems correct by definition of the
<a class="reference external" href="https://en.wikipedia.org/wiki/Chain_rule_(probability)">chain rule of probability</a>,
it is worth noting that we are being a bit loose when <span class="math notranslate nohighlight">\(t=1\)</span>. Firstly, when
<span class="math notranslate nohighlight">\(t=1\)</span>, we are actually conditioning on nothing, and so it is the case that we
are estimating <span class="math notranslate nohighlight">\(\mathbb{P}(x_1 ; \boldsymbol{\Theta})\)</span>. But this is not part of
the learning process because we would need something to condition on. For the
sake of completeness, we can treat the initial token <span class="math notranslate nohighlight">\(x_1\)</span> as the initial
condition, and we can write the chain rule as:</p>
<div class="math notranslate nohighlight">
\[
\mathbb{P}(\mathbf{x} ; \boldsymbol{\Theta}) = \mathbb{P}(x_1 ; \boldsymbol{\Theta}) \prod_{t=2}^T \mathbb{P}(x_t \mid x_1, x_2, \ldots, x_{t-1} ; \boldsymbol{\Theta})
\]</div>
<p>where <span class="math notranslate nohighlight">\(\mathbb{P}(x_1 ; \boldsymbol{\Theta})\)</span> can be thought of the “initial
prompt” or “initial condition” of the sequence <span class="math notranslate nohighlight">\(\mathbf{x}\)</span>.</p>
<p>For further reading, one can find more details below:</p>
<ul class="simple">
<li><p><a class="reference external" href="https://d2l.ai/chapter_recurrent-neural-networks/sequence">Working with Sequences - Dive Into Deep Learning</a></p></li>
<li><p><a class="reference external" href="https://github.com/huggingface/transformers/issues/28860">How do LLMs learn to be “Generative”, as we often describe them?</a></p></li>
</ul>
</section>
<section id="markov-assumption">
<h3><a class="toc-backref" href="#id42" role="doc-backlink">Markov Assumption</a><a class="headerlink" href="#markov-assumption" title="Permalink to this heading">#</a></h3>
<p>Now suppose that we wish to employ the strategy mentioned above, where we
condition only on the <span class="math notranslate nohighlight">\(\tau\)</span> previous time steps, i.e.,
<span class="math notranslate nohighlight">\(x_{t-1}, \ldots, x_{t-\tau}\)</span>, rather than the entire sequence history
<span class="math notranslate nohighlight">\(x_{t-1}, \ldots, x_1\)</span>. Whenever we can throw away the history beyond the
previous <span class="math notranslate nohighlight">\(\tau\)</span> steps without any loss in predictive power, we say that the
sequence satisfies a Markov condition, i.e., that the future is conditionally
independent of the past, given the recent history. When <span class="math notranslate nohighlight">\(\tau=1\)</span>, we say that
the data is characterized by a first-order Markov model, and when <span class="math notranslate nohighlight">\(\tau=k\)</span>, we
say that the data is characterized by a <span class="math notranslate nohighlight">\(k^{\text {th }}\)</span>-order Markov model
<span id="id5">[<a class="reference internal" href="../bibliography.html#id2" title="Aston Zhang, Zachary C. Lipton, Mu Li, and Alexander J. Smola. Dive into Deep Learning. Cambridge University Press, 2023. URL: https://D2L.ai.">Zhang <em>et al.</em>, 2023</a>]</span>.</p>
<p>More formally, a discrete-time Markov chain is a sequence of
<a class="reference external" href="https://en.wikipedia.org/wiki/Random_variable">random variables</a>
<span class="math notranslate nohighlight">\(X_1, X_2, X_3, \ldots\)</span> with the
<a class="reference external" href="https://en.wikipedia.org/wiki/Markov_property">Markov property</a>, namely that
the probability of moving to the next state depends only on the present state
and not on the previous states:</p>
<div class="math notranslate nohighlight">
\[
\mathbb{P}\left(X_{t+1} \mid X_{1}, X_{2}, \ldots, X_{t}\right) = \mathbb{P}\left(X_{t+1} \mid X_{t-k+1}, X_{t-k+2}, \ldots, X_{t}\right)
\]</div>
<p>for all <span class="math notranslate nohighlight">\(t \in \mathbb{N}\)</span> and all states
<span class="math notranslate nohighlight">\(X_{t+1}, X_{t}, X_{1}, X_{2}, \ldots\)</span>.</p>
<p>The <a class="reference external" href="https://en.wikipedia.org/wiki/Markov_property">Markov assumption</a> is more
of an implicit assumption in the autoregressive self-supervised learning
framework where we can draw parallels to. We often find it useful to work with
models that proceed as though a Markov condition were satisfied, even when we
know that this is only approximately true. With real text documents we continue
to gain information as we include more and more leftwards context. But these
gains diminish rapidly. Thus, sometimes we compromise, obviating computational
and statistical difficulties by training models whose validity depends on a
<span class="math notranslate nohighlight">\(k^{\text {th }}\)</span>-order Markov condition. Even today’s massive RNN- and
Transformer based language models seldom incorporate more than thousands of
words of context <span id="id6">[<a class="reference internal" href="../bibliography.html#id2" title="Aston Zhang, Zachary C. Lipton, Mu Li, and Alexander J. Smola. Dive into Deep Learning. Cambridge University Press, 2023. URL: https://D2L.ai.">Zhang <em>et al.</em>, 2023</a>]</span>. In short, the Markov assumption is a
convenient assumption to simplify the modeling of the joint probability
distribution of the token sequences.</p>
<p>Further readings on the Markov assumption can be found in the following:</p>
<ul class="simple">
<li><p><a class="reference external" href="https://news.ycombinator.com/item?id=35551452">GPT-4 absolutely isn’t a Markov chain</a></p></li>
<li><p><a class="reference external" href="https://twitter.com/karpathy/status/1645115622517542913">GPT is a Finite State Markov Chain - Andrej Karpathy</a></p></li>
<li><p><a class="reference external" href="https://d2l.ai/chapter_recurrent-neural-networks/sequence.html">Working with Sequences - Dive Into Deep Learning</a></p></li>
<li><p><a class="reference external" href="https://cs.stackexchange.com/questions/160891/why-gpt-model-is-a-higher-order-hidden-markov-model">Why GPT model is a higher order hidden markov model</a></p></li>
</ul>
</section>
<section id="the-estimator-function-is-smooth-with-respect-to-the-parameters">
<h3><a class="toc-backref" href="#id43" role="doc-backlink">The Estimator Function is Smooth with Respect to the Parameters</a><a class="headerlink" href="#the-estimator-function-is-smooth-with-respect-to-the-parameters" title="Permalink to this heading">#</a></h3>
<p>This assumption is a common one in the context of deep learning, because for
when we say that the estimator function <span class="math notranslate nohighlight">\(f_{\hat{\boldsymbol{\Theta}}}(\cdot)\)</span>
is <em>smooth</em> with respect to the parameter space <span class="math notranslate nohighlight">\(\hat{\boldsymbol{\Theta}}\)</span>, we
state a simplified definition as follows.</p>
<p>The estimator function <span class="math notranslate nohighlight">\(f_{\hat{\boldsymbol{\Theta}}}(\cdot)\)</span> is <em>smooth</em> with
respect to the parameter space <span class="math notranslate nohighlight">\(\hat{\boldsymbol{\Theta}}\)</span> if the function is
continuous and differentiable with respect to the parameter space
<span class="math notranslate nohighlight">\(\hat{\boldsymbol{\Theta}}\)</span> up to a certain order (usually the first for SGD
variants and second order for Newton).</p>
<p>What this implies is that the derivative of the function with respect to the
parameter space <span class="math notranslate nohighlight">\(\hat{\boldsymbol{\Theta}}\)</span>, denoted as
<span class="math notranslate nohighlight">\(\nabla_{\hat{\boldsymbol{\Theta}}} f_{\hat{\boldsymbol{\Theta}}}(\cdot)\)</span> is
continuous. Loosely, you can think of that a small perturbation in the parameter
space <span class="math notranslate nohighlight">\(\hat{\boldsymbol{\Theta}}\)</span> will result in a small change in the output of
the function <span class="math notranslate nohighlight">\(f_{\hat{\boldsymbol{\Theta}}}(\cdot)\)</span> - enabling gradient-based
optimization algorithms to work effectively as if not, then taking a step in the
direction of the gradient would not guarantee a decrease in the loss function,
slowing down convergence.</p>
<p>However, this is also not a strict assumption as in practice, piece-wise linear
activation functions are not smooth because the derivative is not continuous at
<span class="math notranslate nohighlight">\(0\)</span>, and consequently, <span class="math notranslate nohighlight">\(f_{\hat{\boldsymbol{\Theta}}}(\cdot)\)</span> is
<a class="reference external" href="https://stats.stackexchange.com/questions/473643/why-are-neural-networks-smooth-functions">not smooth with respect to the parameter space</a>
<span class="math notranslate nohighlight">\(\hat{\boldsymbol{\Theta}}\)</span>.</p>
</section>
<section id="context-length-and-token-context-window">
<h3><a class="toc-backref" href="#id44" role="doc-backlink">Context Length and Token Context Window</a><a class="headerlink" href="#context-length-and-token-context-window" title="Permalink to this heading">#</a></h3>
<p>Given a coherent sequence of tokens <span class="math notranslate nohighlight">\(\mathbf{x}\)</span>, say, <em>the tabby cat walks by
the river bank</em>, we may not always pass the full sequence to the model. Based on
a <em>context length</em> <span class="math notranslate nohighlight">\(\tau\)</span>, we can pass a <em>token context window</em> of length <span class="math notranslate nohighlight">\(\tau\)</span>
to the model. For instance, if <span class="math notranslate nohighlight">\(\tau=4\)</span>, then the token context window would be
<span class="math notranslate nohighlight">\(\left(x_{t-3}, x_{t-2}, x_{t-1}, x_{t}\right)\)</span>, and the model would be trained
to predict the next token <span class="math notranslate nohighlight">\(x_{t+1}\)</span> given the token context window. In other
words, the sentence above would be broken down into the following token context
windows:</p>
<ul class="simple">
<li><p><em>the tabby cat walks</em></p></li>
<li><p><em>by the river bank</em></p></li>
</ul>
<p>And the longer the context length, the model would be able to capture
longer-range dependenciees in the sequence, but also may increase the
computational complexity of the model <span id="id7">[<a class="reference internal" href="../bibliography.html#id11" title="Minhyeok Lee. A mathematical interpretation of autoregressive generative pre-trained transformer and self-supervised learning. Mathematics, 2023. URL: https://www.mdpi.com/2227-7390/11/11/2451, doi:10.3390/math11112451.">Lee, 2023</a>]</span>.</p>
<p>More formally, we can define the token context window as a function
<span class="math notranslate nohighlight">\(C_{\tau}(\mathbf{x}, t)\)</span> that maps a sequence <span class="math notranslate nohighlight">\(\mathbf{x}\)</span> and a position <span class="math notranslate nohighlight">\(t\)</span>
to a token context window of length <span class="math notranslate nohighlight">\(\tau\)</span>:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{aligned}
C_{\tau} : \mathcal{X} \times \mathbb{N} &amp;\rightarrow \mathcal{X}^{\tau} \\
(\mathbf{x}, t) &amp;\mapsto \left(x_{t-\tau+1}, x_{t-\tau+2}, \ldots, x_{t}\right)
\end{aligned}
\end{split}\]</div>
</section>
<section id="conditional-entropy-and-perplexity-as-loss-function">
<h3><a class="toc-backref" href="#id45" role="doc-backlink">Conditional Entropy and Perplexity as Loss Function</a><a class="headerlink" href="#conditional-entropy-and-perplexity-as-loss-function" title="Permalink to this heading">#</a></h3>
<p>Having defined the basis of the autoregressive self-supervised learning
framework, we can now define the loss function <span class="math notranslate nohighlight">\(\mathcal{L}\)</span> that is used to
train the model <span class="math notranslate nohighlight">\(\mathcal{G}\)</span> to maximize the likelihood of the sequences in the
corpus <span class="math notranslate nohighlight">\(\mathcal{S}\)</span>. In order to transit towards the final objective/loss
function, we would need to define the notion of
<a class="reference external" href="https://en.wikipedia.org/wiki/Conditional_entropy"><em><strong>conditional entropy</strong></em></a>.</p>
<section id="conditional-entropy">
<h4><a class="toc-backref" href="#id46" role="doc-backlink">Conditional Entropy</a><a class="headerlink" href="#conditional-entropy" title="Permalink to this heading">#</a></h4>
<p>Define <span class="math notranslate nohighlight">\(X_t\)</span> as a random variable representing the token at position <span class="math notranslate nohighlight">\(t\)</span> in the
sequence <span class="math notranslate nohighlight">\(\mathbf{x}\)</span> and <span class="math notranslate nohighlight">\(X_{&lt;t} = \left(X_1, X_2, \ldots, X_{t-1}\right)\)</span> as
random variables representing the tokens at positions <span class="math notranslate nohighlight">\(1, 2, \ldots, t-1\)</span> in the
sequence <span class="math notranslate nohighlight">\(\mathbf{x}\)</span>. Then the conditional
<a class="reference external" href="https://en.wikipedia.org/wiki/Shannon_Entropy">entropy</a> of the token <span class="math notranslate nohighlight">\(X_t\)</span>
given a specific realization of <span class="math notranslate nohighlight">\(X_{&lt;t}\)</span> is defined as:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{aligned}
H\left(X_t \mid X_{&lt;t} = x_{&lt;t} \right) &amp;= -\sum_{x_t \in \mathcal{V}} \mathbb{P}\left(x_t \mid x_{&lt;t} ; \boldsymbol{\Theta}\right) \log \mathbb{P}\left(x_t \mid x_{&lt;t} ; \boldsymbol{\Theta}\right) \\
\end{aligned}
\end{split}\]</div>
<p>This calculates the conditional entropy given a specific realization of the
context <span class="math notranslate nohighlight">\(X_{&lt;t} = x_{&lt;t}\)</span>, where we see that summation sums over all
possibilities of the token <span class="math notranslate nohighlight">\(x_t\)</span> in the vocabulary <span class="math notranslate nohighlight">\(\mathcal{V}\)</span>, considering
the probability of the token <span class="math notranslate nohighlight">\(x_t\)</span> given <em>a particular preceding</em> sequence of
tokens.</p>
<p>To account for all possible realizations of the context <span class="math notranslate nohighlight">\(X_{&lt;t}\)</span>, we simply sum
over all possible realizations of the context <span class="math notranslate nohighlight">\(X_{&lt;t}\)</span>, and we can write the
conditional entropy as:</p>
<div class="math notranslate nohighlight">
\[
\begin{aligned}
H\left(X_t \mid X_{&lt;t}\right) = -\sum_{x_{t} \in \mathcal{V}} \sum_{x_{&lt;t} \in \mathcal{V}^{&lt;t}} \mathbb{P}\left(x_t, x_{&lt;t} ; \boldsymbol{\Theta}\right) \log \mathbb{P}\left(x_t \mid x_{&lt;t} ; \boldsymbol{\Theta}\right)
\end{aligned}
\]</div>
<p>where <span class="math notranslate nohighlight">\(\mathbb{P}\left(x_t, x_{&lt;t} ; \boldsymbol{\Theta}\right)\)</span> is the joint
probability distribution of observing the sequence <span class="math notranslate nohighlight">\((x_{&lt;t}, x_t)\)</span>,
<span class="math notranslate nohighlight">\(\mathbb{P}\left(x_t \mid x_{&lt;t} ; \boldsymbol{\Theta}\right)\)</span> is the
conditional probability distribution of observing the token <span class="math notranslate nohighlight">\(x_t\)</span> given the
context <span class="math notranslate nohighlight">\(x_{&lt;t}\)</span>, and <span class="math notranslate nohighlight">\(\mathcal{V}^{&lt;t}\)</span> is the set of all possible realizations
of the context <span class="math notranslate nohighlight">\(X_{&lt;t}\)</span>.</p>
<p>It is worth noting that the conditional entropy <span class="math notranslate nohighlight">\(H\left(X_t \mid X_{&lt;t}\right)\)</span>
is also the conditional expectation of the negative log-likelihood of the token
<span class="math notranslate nohighlight">\(X_t\)</span> given the context <span class="math notranslate nohighlight">\(X_{&lt;t}\)</span>, and we can write it as:</p>
<div class="math notranslate nohighlight">
\[
H\left(X_t \mid X_{&lt;t}\right) = -\mathbb{E}_{\mathcal{D}}\left[\log \mathbb{P}\left(X_t \mid X_{&lt;t} ; \boldsymbol{\Theta}\right)\right]
\]</div>
<p>One can more details on the concept of conditional entropy in the following:</p>
<ul class="simple">
<li><p><a class="reference external" href="https://en.wikipedia.org/wiki/Conditional_entropy">Conditional Entropy - Wikipedia</a></p></li>
<li><p><a class="reference external" href="https://en.wikipedia.org/wiki/Conditional_expectation">Conditional Expectation - Wikipedia</a></p></li>
</ul>
</section>
<section id="perplexity">
<h4><a class="toc-backref" href="#id47" role="doc-backlink">Perplexity</a><a class="headerlink" href="#perplexity" title="Permalink to this heading">#</a></h4>
<p>Language model has a standing history of using
<a class="reference external" href="https://en.wikipedia.org/wiki/Perplexity"><strong>Perplexity</strong></a> as a measure of the
quality of a language model. It is a measure of how well a probability
distribution or probability model predicts a sample. Without going into the
details, we define the perplexity of a probability distribution
<span class="math notranslate nohighlight">\(\mathbb{P}(x_t \mid x_{&lt;t} ; \boldsymbol{\Theta})\)</span> as the exponential of the
conditional entropy of the distribution, and we can write it as:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{aligned}
\operatorname{Perplexity}\left(\mathbb{P}(x_t \mid x_{&lt;t} ; \boldsymbol{\Theta})\right) &amp;= \exp\left(H\left(X_t \mid X_{&lt;t}\right)\right) \\
\end{aligned}
\end{split}\]</div>
<p>To read more about perplexity, one can find more details in the following:</p>
<ul class="simple">
<li><p><a class="reference external" href="https://en.wikipedia.org/wiki/Perplexity">Perplexity - Wikipedia</a></p></li>
<li><p><a class="reference external" href="https://huggingface.co/docs/transformers/en/perplexity">Perplexity of fixed-length models</a></p></li>
</ul>
</section>
<section id="loss-function">
<h4><a class="toc-backref" href="#id48" role="doc-backlink">Loss Function</a><a class="headerlink" href="#loss-function" title="Permalink to this heading">#</a></h4>
<p>Given the definitions of the conditional entropy and perplexity, we can
formalize the loss function <span class="math notranslate nohighlight">\(\mathcal{L}\)</span> as:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{aligned}
\mathcal{L}\left(\mathcal{D} ; \boldsymbol{\Theta}\right) &amp;= -\sum_{\mathbf{x} \in \mathcal{D}} \sum_{t=1}^T \log \mathbb{P}\left(x_t \mid C_{\tau}(\mathbf{x}, t) ; \boldsymbol{\Theta}\right) \\
\end{aligned}
\end{split}\]</div>
<p>and the objective function is to minimize the loss function <span class="math notranslate nohighlight">\(\mathcal{L}\)</span>,</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{aligned}
\boldsymbol{\theta}^{*} &amp;= \underset{\boldsymbol{\theta} \in \boldsymbol{\Theta}}{\text{argmin}} \mathcal{L}\left(\mathcal{D} ; \boldsymbol{\Theta}\right) \\
                        &amp;= \underset{\boldsymbol{\theta} \in \boldsymbol{\Theta}}{\text{argmin}} -\sum_{\mathbf{x} \in \mathcal{D}} \sum_{t=1}^T \log \mathbb{P}\left(x_t \mid C_{\tau}(\mathbf{x}, t) ; \boldsymbol{\Theta}\right) \\
\end{aligned}
\end{split}\]</div>
<p>However, we do not know the true distribution <span class="math notranslate nohighlight">\(\mathcal{D}\)</span>, and so we can only
estimate the loss function <span class="math notranslate nohighlight">\(\mathcal{L}\)</span> from the corpus <span class="math notranslate nohighlight">\(\mathcal{S}\)</span>, and we
can write the process of estimating via the negative log-likelihood as:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{aligned}
\hat{\mathcal{L}}\left(\mathcal{S} ; \hat{\boldsymbol{\Theta}}\right) &amp;= -\sum_{\mathbf{x} \in \mathcal{S}} \sum_{t=1}^T \log \mathbb{P}\left(x_t \mid C_{\tau}(\mathbf{x}, t) ; \hat{\boldsymbol{\Theta}}\right) \\
    &amp;= -\sum_{n=1}^N \sum_{t=1}^{T_n} \log \mathbb{P}\left(x_{n, t} \mid C_{\tau}(\mathbf{x}_{n}, t) ; \hat{\boldsymbol{\Theta}}\right) \\
\end{aligned}
\end{split}\]</div>
<p>and consequently, the objective function is to minimize the estimated loss
function
<span class="math notranslate nohighlight">\(\hat{\mathcal{L}}\left(\mathcal{S} ; \hat{\boldsymbol{\Theta}}\right)\)</span>,</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{aligned}
\hat{\boldsymbol{\theta}}^{*} &amp;= \underset{\hat{\boldsymbol{\theta}} \in \boldsymbol{\Theta}}{\text{argmin}} \hat{\mathcal{L}}\left(\mathcal{S} ; \hat{\boldsymbol{\Theta}}\right) \\
                              &amp;= \underset{\hat{\boldsymbol{\theta}} \in \boldsymbol{\Theta}}{\text{argmin}} -\sum_{n=1}^N \sum_{t=1}^{T_n} \log \mathbb{P}\left(x_{n, t} \mid C_{\tau}(\mathbf{x}_{n}, t) ; \hat{\boldsymbol{\Theta}}\right) \\
\end{aligned}
\end{split}\]</div>
</section>
<section id="convergence">
<h4><a class="toc-backref" href="#id49" role="doc-backlink">Convergence</a><a class="headerlink" href="#convergence" title="Permalink to this heading">#</a></h4>
<p>It can be shown that the given the Markov assumption and a token context window
size of <span class="math notranslate nohighlight">\(\tau\)</span>, the loss function <span class="math notranslate nohighlight">\(\mathcal{L}\)</span> is a
<a class="reference external" href="https://en.wikipedia.org/wiki/Consistent_estimator">consistent estimator</a> of
the true distribution <span class="math notranslate nohighlight">\(\mathcal{D}\)</span>, and the the objective
<span class="math notranslate nohighlight">\(\hat{\mathcal{L}}\left(\mathcal{S} ; \hat{\boldsymbol{\Theta}}\right)\)</span>
converges to the true conditional probability distribution
<span class="math notranslate nohighlight">\(\mathbb{P}(x_t \mid x_{&lt;t} ; \boldsymbol{\Theta})\)</span> over <span class="math notranslate nohighlight">\(\mathcal{D}\)</span> as the
size of the corpus <span class="math notranslate nohighlight">\(\mathcal{S}\)</span> goes to infinity, if the model has sufficient
capacity and the optimization algorithm is appropriate <span id="id8">[<a class="reference internal" href="../bibliography.html#id11" title="Minhyeok Lee. A mathematical interpretation of autoregressive generative pre-trained transformer and self-supervised learning. Mathematics, 2023. URL: https://www.mdpi.com/2227-7390/11/11/2451, doi:10.3390/math11112451.">Lee, 2023</a>]</span>.</p>
<p>Furthermore, the proposition that the conditional entropy
<span class="math notranslate nohighlight">\(H\left(X_t \mid X_{&lt;t}\right)\)</span> of the true data-generating process is upper
bounded by the by the logarithm of the size of the vocabulary <span class="math notranslate nohighlight">\(\mathcal{V}\)</span>,
i.e., <span class="math notranslate nohighlight">\(H\left(X_t \mid X_{&lt;t}\right) \leq \log |\mathcal{V}|\)</span>
<span id="id9">[<a class="reference internal" href="../bibliography.html#id11" title="Minhyeok Lee. A mathematical interpretation of autoregressive generative pre-trained transformer and self-supervised learning. Mathematics, 2023. URL: https://www.mdpi.com/2227-7390/11/11/2451, doi:10.3390/math11112451.">Lee, 2023</a>]</span>.</p>
<p>The proposition that the conditional entropy has an upper limit, carries
significant implications for optimizing autoregressive self-supervised learning
models. Specifically, because the conditional entropy cannot exceed the
logarithm of the vocabulary size <span class="math notranslate nohighlight">\(\mathcal{V}\)</span>, we infer a similar upper limit
on perplexity. This cap on perplexity offers a valuable benchmark for evaluating
and comparing different models, establishing a theoretical maximum for model
performance based on the size of the vocabulary <span id="id10">[<a class="reference internal" href="../bibliography.html#id11" title="Minhyeok Lee. A mathematical interpretation of autoregressive generative pre-trained transformer and self-supervised learning. Mathematics, 2023. URL: https://www.mdpi.com/2227-7390/11/11/2451, doi:10.3390/math11112451.">Lee, 2023</a>]</span>.</p>
</section>
</section>
<section id="gpt-is-a-autoregressive-self-supervised-learning-model">
<h3><a class="toc-backref" href="#id50" role="doc-backlink">GPT is a Autoregressive Self-Supervised Learning Model</a><a class="headerlink" href="#gpt-is-a-autoregressive-self-supervised-learning-model" title="Permalink to this heading">#</a></h3>
<p>Finally, we can piece together the autoregressive self-supervised learning
framework to define the GPT model <span class="math notranslate nohighlight">\(\mathcal{G}\)</span> as a model that is trained to
maximize the likelihood of the sequences in the corpus <span class="math notranslate nohighlight">\(\mathcal{S}\)</span> via the
objective function
<span class="math notranslate nohighlight">\(\hat{\mathcal{L}}\left(\mathcal{S} ; \hat{\boldsymbol{\Theta}}\right)\)</span> where
<span class="math notranslate nohighlight">\(\hat{\boldsymbol{\Theta}}\)</span> is the estimated parameter space that approximates
the true parameter space <span class="math notranslate nohighlight">\(\boldsymbol{\Theta}\)</span>, and <span class="math notranslate nohighlight">\(\mathcal{S}\)</span> is the corpus
of sequences that are sampled <span class="math notranslate nohighlight">\(\text{i.i.d.}\)</span> from the distribution
<span class="math notranslate nohighlight">\(\mathcal{D}\)</span>.</p>
<p>In pseudo-code, the GPT model <span class="math notranslate nohighlight">\(\mathcal{G}\)</span> consists of decoder blocks, each
block consisting of a multi-head self-attention mechanism and a position-wise
feed-forward neural network, with a head layer to produce a probability
distribution over the vocabulary <span class="math notranslate nohighlight">\(\mathcal{V}\)</span> of tokens.</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{aligned}
h_0 &amp;= \mathcal{S} \cdot \mathbf{W}_{e}+ \mathbf{W}_{p} \\
h_{\ell} &amp;= \text{DecoderBlock}(h_{\ell-1}) \quad \text{for} \quad \ell = 1, 2, \ldots, L \\
\mathbb{P}(x_t \mid C_{\tau}(\mathbf{x}, t) ; \boldsymbol{\Theta}) &amp;= \text{softmax}(h_{L} \cdot \mathbf{W}_{e}^{\top})
\end{aligned}
\end{split}\]</div>
<p>where:</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\mathbf{W}_{e}\)</span> is the embedding matrix that maps the token to a vector
representation in a continuous vector space,</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{W}_{p}\)</span> is the positional encoding matrix that encodes the position
of the token in the sequence,</p></li>
<li><p><span class="math notranslate nohighlight">\(\text{DecoderBlock}\)</span> is a function that applies a multi-head self-attention
mechanism and a position-wise feed-forward neural network to the input
sequence,</p></li>
<li><p><span class="math notranslate nohighlight">\(\mathbf{W}_{e}^{\top}\)</span> is the transpose of the embedding matrix that maps
the vector representation of the token back to the vocabulary space.</p></li>
</ul>
<p>Note that it is only a pseudo-code because notations like <span class="math notranslate nohighlight">\(\mathbf{W}_{e}\)</span> are
used to denote both the token embedding matrix in <span class="math notranslate nohighlight">\(h_0\)</span> and the transformed
contextual embedding matrix in the head/linear/last layer. The actual
implementation of the GPT model is more complex, and we will take a look at it
in later sections.</p>
</section>
<section id="conditional-on-task">
<h3><a class="toc-backref" href="#id51" role="doc-backlink">Conditional on Task</a><a class="headerlink" href="#conditional-on-task" title="Permalink to this heading">#</a></h3>
<p>In the GPT-2 paper, <em>Language Models are Unsupervised Multitask Learners</em>, the
authors introduced the concept of <em>conditional on task</em> where the GPT model
<span class="math notranslate nohighlight">\(\mathcal{G}\)</span> theoretically should not only learn the conditional probability
distribution <span class="math notranslate nohighlight">\(\mathbb{P}(x_t \mid x_{&lt;t} ; \boldsymbol{\Theta})\)</span> but also learn
the conditional probability distribution
<span class="math notranslate nohighlight">\(\mathbb{P}(x_t \mid x_{&lt;t} ; \boldsymbol{\Theta}, \mathcal{T})\)</span> where
<span class="math notranslate nohighlight">\(\mathcal{T}\)</span> is the task that the model should implicitly learn
<span id="id11">[<a class="reference internal" href="../bibliography.html#id10" title="Alec Radford, Jeff Wu, Rewon Child, David Luan, Dario Amodei, and Ilya Sutskever. Language models are unsupervised multitask learners. 2019.">Radford <em>et al.</em>, 2019</a>]</span>. This is a powerful concept because if such a
hypothesis is correct, then the GPT model <span class="math notranslate nohighlight">\(\mathcal{G}\)</span> can indeed be a
multi-task learner, and can be used directly on a wide range of NLU tasks
without the need for supervised fine-tuning for downstream domain-specific
tasks.</p>
<p>In practice, the authors mentioned that task conditioning is often implemented
at an architectural level, via task specific encoder and decoder in the paper
<a class="reference external" href="https://arxiv.org/abs/1706.05137"><em>One Model To Learn Them All</em></a>
<span id="id12">[<a class="reference internal" href="../bibliography.html#id17" title="Lukasz Kaiser, Aidan N. Gomez, Noam Shazeer, Ashish Vaswani, Niki Parmar, Llion Jones, and Jakob Uszkoreit. One model to learn them all. 2017. arXiv:1706.05137.">Kaiser <em>et al.</em>, 2017</a>]</span>, for instance, or at an algorithmic level, such as the
inner and outer loop optimization framework, as seen in the paper
<a class="reference external" href="https://arxiv.org/abs/1703.03400"><em>Model-Agnostic Meta-Learning for Fast Adaptation of Deep Networks</em></a>
<span id="id13">[<a class="reference internal" href="../bibliography.html#id16" title="Chelsea Finn, Pieter Abbeel, and Sergey Levine. Model-agnostic meta-learning for fast adaptation of deep networks. 2017. arXiv:1703.03400.">Finn <em>et al.</em>, 2017</a>]</span>.</p>
<p>However, the authors further mentioned that without task-specific architectural
changes, one can leverage the sequential nature of the natural language space
where we can construct a tasks, inputs and outputs all as a sequence of symbols
<span id="id14">[<a class="reference internal" href="../bibliography.html#id10" title="Alec Radford, Jeff Wu, Rewon Child, David Luan, Dario Amodei, and Ilya Sutskever. Language models are unsupervised multitask learners. 2019.">Radford <em>et al.</em>, 2019</a>]</span>. For example, a translation task can be formulated
as a sequence of symbols via
<code class="docutils literal notranslate"><span class="pre">(translate</span> <span class="pre">to</span> <span class="pre">french,</span> <span class="pre">english</span> <span class="pre">sequence,</span> <span class="pre">french</span> <span class="pre">sequence)</span></code>, where the model can
now learn to also condition on the task <code class="docutils literal notranslate"><span class="pre">(translate</span> <span class="pre">to</span> <span class="pre">french)</span></code> in addition to
the sequence of tokens. The paper <em>The Natural Language Decathlon: Multitask
Learning as Question Answering</em> exemplifies this concept with their model
<strong>Multitask Question Answering Network (MQAN)</strong>, where a single model is trained
to perform many diverse natural language processing tasks simultaneously.</p>
</section>
<section id="supervised-fine-tuning">
<h3><a class="toc-backref" href="#id52" role="doc-backlink">Supervised Fine-Tuning</a><a class="headerlink" href="#supervised-fine-tuning" title="Permalink to this heading">#</a></h3>
<p>Though GPT-2 has demonstrated that it can be used directly on a wide range of
NLU without the need for supervised fine-tuning, it is worth taking a detour
back to how GPT-1 was fine-tuned immediately after the pretraining phase.</p>
<p>In the paper <em>Improving Language Understanding by Generative Pre-Training</em>,
after the pretrained (foundational) model was trained with the objective
function
<span class="math notranslate nohighlight">\(\hat{\mathcal{L}}\left(\mathcal{S} ; \hat{\boldsymbol{\Theta}}\right)\)</span>, we
would then fine-tune the model on a specific task by replacing the final layer
of the model with a task-specific layer, and then train the model on the
specific task with the task-specific layer. The authors showed that this
approach yielded state-of-the-art results on a wide range of NLU tasks.</p>
<section id="objective-function-for-fine-tuning">
<h4><a class="toc-backref" href="#id53" role="doc-backlink">Objective Function for Fine-Tuning</a><a class="headerlink" href="#objective-function-for-fine-tuning" title="Permalink to this heading">#</a></h4>
<p>More concretely, now our dataset <span class="math notranslate nohighlight">\(\mathcal{S}\)</span> is a dataset of labeled examples
<span class="math notranslate nohighlight">\(\mathcal{S} = \left\{\left(\mathbf{x}_n, y_n\right)\right\}_{n=1}^N\)</span>, where it
may be sampled together from a new underlying distribution <span class="math notranslate nohighlight">\(\mathcal{D}\)</span>,
usually a cartesian product <span class="math notranslate nohighlight">\(\mathcal{X} \times \mathcal{Y}\)</span> where <span class="math notranslate nohighlight">\(\mathcal{Y}\)</span>
is the label space. Each input sequence <span class="math notranslate nohighlight">\(\mathbf{x}_n\)</span> is a sequence of tokens,
and each output label <span class="math notranslate nohighlight">\(y_n\)</span> is a label from the set of labels <span class="math notranslate nohighlight">\(\mathcal{Y}\)</span>.</p>
<p>A task specific layer is often used to replace the original head layer, for
instance, if we are training the model on a text classification task with
<span class="math notranslate nohighlight">\(\mathcal{C}\)</span> number of classes, then the task specific layer would be a linear
layer with <span class="math notranslate nohighlight">\(\mathcal{C}\)</span> number of output units. Of course, the output of this
layer, being the logits, will usually pass into appropriate loss functions such
as the cross-entropy loss with a softmax layer on top of the logits to induce a
<em>not so well-calibrated</em> probability distribution over the classes
<span class="math notranslate nohighlight">\(\mathcal{C}\)</span>.</p>
<p>If we denote the loss function (or the negative log-likelihood) of the
pre-training phase as
<span class="math notranslate nohighlight">\(\hat{\mathcal{L}}_{1}\left(\mathcal{S}_{1} ; \hat{\boldsymbol{\Theta}}_{1}\right)\)</span>,
then the objective in this second phase is simply to maximize the likelihood of
the labeled examples <span class="math notranslate nohighlight">\(\mathcal{S}\)</span> via the objective function
<span class="math notranslate nohighlight">\(\hat{\mathcal{L}}_{2}\left(\mathcal{S}_{2} ; \hat{\boldsymbol{\Theta}}_{2}\right)\)</span>
where <span class="math notranslate nohighlight">\(\hat{\boldsymbol{\Theta}}_{1}\)</span> is the estimated parameter space for the
pre-training phase, and <span class="math notranslate nohighlight">\(\hat{\boldsymbol{\Theta}}_{2}\)</span> is the estimated
parameter space for the fine-tuning phase. Note that the
<span class="math notranslate nohighlight">\(\hat{\boldsymbol{\Theta}}_{2}\)</span> is initialized with partial weights from the
pre-trained model <span class="math notranslate nohighlight">\(\mathcal{G}\)</span>, so it naturally should overlap with the
<span class="math notranslate nohighlight">\(\hat{\boldsymbol{\Theta}}_{1}\)</span> up to the number of <em>frozen</em> layers.</p>
<p>We denote the maximization as a minimization of the negative log-likelihood:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{aligned}
\hat{\boldsymbol{\theta}}_{2}^{*} &amp;= \underset{\hat{\boldsymbol{\theta}}_{2} \in \boldsymbol{\Theta}_{2}}{\text{argmin}} \hat{\mathcal{L}}_{2}\left(\mathcal{S}_{2} ; \hat{\boldsymbol{\Theta}}_{2}\right) \\
                                    &amp;= \underset{\hat{\boldsymbol{\theta}}_{2} \in \boldsymbol{\Theta}_{2}}{\text{argmin}} -\sum_{n=1}^N \log \mathbb{P}\left(y_n \mid \mathbf{x}_n ; \hat{\boldsymbol{\Theta}}_{2}\right) \\
\end{aligned}
\end{split}\]</div>
<p>It is also customary to find the expected loss over the dataset <span class="math notranslate nohighlight">\(\mathcal{S}\)</span>,</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{aligned}
\hat{\boldsymbol{\theta}}_{2}^{*} &amp;= \underset{\hat{\boldsymbol{\theta}}_{2} \in \boldsymbol{\Theta}_{2}}{\text{argmin}} \mathbb{E}_{\mathcal{S}}\left[\hat{\mathcal{L}}_{2}\left(\mathcal{S}_{2} ; \hat{\boldsymbol{\Theta}}_{2}\right)\right] \\
                                    &amp;= \underset{\hat{\boldsymbol{\theta}}_{2} \in \boldsymbol{\Theta}_{2}}{\text{argmin}} -\mathbb{E}_{\mathcal{S}}\left[\sum_{n=1}^N \log \mathbb{P}\left(y_n \mid \mathbf{x}_n ; \hat{\boldsymbol{\Theta}}_{2}\right)\right] \\
                                    &amp;= -\frac{1}{N} \sum_{n=1}^N \log \mathbb{P}\left(y_n \mid \mathbf{x}_n ; \hat{\boldsymbol{\Theta}}_{2}\right) \\
\end{aligned}
\end{split}\]</div>
<p>where <span class="math notranslate nohighlight">\(N\)</span> is the number of samples in the dataset <span class="math notranslate nohighlight">\(\mathcal{S}\)</span>.</p>
</section>
<section id="auxiliary-loss-function">
<h4><a class="toc-backref" href="#id54" role="doc-backlink">Auxiliary Loss Function</a><a class="headerlink" href="#auxiliary-loss-function" title="Permalink to this heading">#</a></h4>
<p>In the context of fine-tuning GPT-1 or similar models for specific tasks, the
term “auxiliary (supplementary) loss” refers to additional objectives or loss
functions that are incorporated into the fine-tuning process alongside the
primary loss function. This approach is based on the idea that including
auxiliary tasks or losses can help improve the model’s performance on the main
task by leveraging the knowledge gained during pre-training. The author also
mentioned that this method (a) improving generalization of the supervised model,
and (b) accelerating convergence <span id="id15">[<a class="reference internal" href="../bibliography.html#id15" title="Alec Radford, Karthik Narasimhan, Tim Salimans, and Ilya Sutskever. Improving language understanding by generative pre-training. 2018.">Radford <em>et al.</em>, 2018</a>]</span>.</p>
<p>During pre-training, models like GPT-1 learn to predict the next token in a
sequence, which is a form of auxiliary task. When fine-tuning these models on
downstream tasks, the authors of the GPT-1 paper found it beneficial to include
the pre-training loss (the auxiliary loss) in the fine-tuning loss function.
This is done by calculating the primary loss for the specific task (e.g.,
classification, named-entity recognition) and then combining it with the
auxiliary loss, often with a weighting factor to balance their contributions.
The weighting factor, denoted as <span class="math notranslate nohighlight">\(\alpha\)</span> in the fine-tuning loss function,
allows for adjusting the relative importance of the primary and auxiliary losses
during the fine-tuning process.</p>
<p>To this end, the final loss function for fine-tuning the GPT-1 model on a
specific task is a combination of the primary loss and the auxiliary loss, and
we can write it as:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{aligned}
\hat{\mathcal{L}}_{3}\left(\mathcal{S}_{2} ; \hat{\boldsymbol{\Theta}}_{3}\right) &amp;= \alpha \hat{\mathcal{L}}_{2}\left(\mathcal{S}_{2} ; \hat{\boldsymbol{\Theta}}_{2}\right) + (1 - \alpha) \hat{\mathcal{L}}_{1}\left(\mathcal{S}_{1} ; \hat{\boldsymbol{\Theta}}_{1}\right) \\
\end{aligned}
\end{split}\]</div>
<p>and we can minimize the new auxiliary loss function in the same way.</p>
</section>
</section>
</section>
<section id="references-and-further-readings">
<h2><a class="toc-backref" href="#id55" role="doc-backlink">References and Further Readings</a><a class="headerlink" href="#references-and-further-readings" title="Permalink to this heading">#</a></h2>
<ul class="simple">
<li><p><a class="reference external" href="https://developers.google.com/machine-learning/gan/generative">https://developers.google.com/machine-learning/gan/generative</a></p></li>
<li><p><a class="reference external" href="https://probmlcourse.github.io/csc412/lectures/week_2/">https://probmlcourse.github.io/csc412/lectures/week_2/</a></p></li>
<li><p>speech and recognition chapter 3 important</p></li>
<li><p><a class="reference external" href="https://stackoverflow.com/questions/66451430/changes-in-gpt2-gpt3-model-during-few-shot-learning">https://stackoverflow.com/questions/66451430/changes-in-gpt2-gpt3-model-during-few-shot-learning</a></p></li>
<li><p><a class="reference external" href="https://ai.stackexchange.com/questions/12579/why-can-we-approximate-the-joint-probability-distribution-using-the-output-vecto">https://ai.stackexchange.com/questions/12579/why-can-we-approximate-the-joint-probability-distribution-using-the-output-vecto</a></p></li>
<li><p><a class="reference external" href="https://datascience.stackexchange.com/questions/65806/why-joint-probability-in-generative-models">https://datascience.stackexchange.com/questions/65806/why-joint-probability-in-generative-models</a></p></li>
<li><p><a class="reference external" href="https://d2l.ai/chapter_recurrent-neural-networks/language-model.html">https://d2l.ai/chapter_recurrent-neural-networks/language-model.html</a></p></li>
<li><p><a class="reference external" href="https://stanford-cs324.github.io/winter2022/lectures/introduction/">https://stanford-cs324.github.io/winter2022/lectures/introduction/</a></p></li>
<li><p><a class="reference external" href="https://www.probabilitycourse.com/chapter5/5_1_1_joint_pmf.php">https://www.probabilitycourse.com/chapter5/5_1_1_joint_pmf.php</a></p></li>
<li><p><a class="reference external" href="https://math.stackexchange.com/questions/1566215/difference-between-joint-probability-distribution-and-conditional-probability-di">https://math.stackexchange.com/questions/1566215/difference-between-joint-probability-distribution-and-conditional-probability-di</a></p></li>
<li><p><a class="reference external" href="https://eugeneyan.com/writing/attention/">https://eugeneyan.com/writing/attention/</a></p></li>
<li><p><a class="reference external" href="https://d2l.ai/chapter_convolutional-modern/resnet.html">https://d2l.ai/chapter_convolutional-modern/resnet.html</a></p></li>
<li><p><a class="reference external" href="https://songhuiming.github.io/pages/2023/05/28/gpt-1-gpt-2-gpt-3-instructgpt-chatgpt-and-gpt-4-summary/">https://songhuiming.github.io/pages/2023/05/28/gpt-1-gpt-2-gpt-3-instructgpt-chatgpt-and-gpt-4-summary/</a></p></li>
<li><p><a class="reference external" href="https://keras.io/api/keras_nlp/metrics/perplexity/">https://keras.io/api/keras_nlp/metrics/perplexity/</a></p></li>
<li><p><a class="reference external" href="https://lightning.ai/docs/torchmetrics/stable/text/perplexity.html">https://lightning.ai/docs/torchmetrics/stable/text/perplexity.html</a></p></li>
<li><p><a class="reference external" href="https://huggingface.co/docs/transformers/perplexity">https://huggingface.co/docs/transformers/perplexity</a></p></li>
</ul>
<hr class="footnotes docutils" />
<aside class="footnote brackets" id="id16" role="note">
<span class="label"><span class="fn-bracket">[</span><a role="doc-backlink" href="#id4">1</a><span class="fn-bracket">]</span></span>
<p>This part is not concrete as the formalization is not rigorous in the
statistical learning framework, but the general idea is there.</p>
</aside>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./transformer"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="notations.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Notations</p>
      </div>
    </a>
    <a class="right-next"
       href="decoder/implementation.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Shakespeare</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#motivation">Motivation</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#abstract">Abstract</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#introduction">Introduction</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#key-1-competent-generalists-over-narrow-experts-1">Key 1. Competent Generalists over Narrow Experts (1)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#key-2-iid-assumption-fails-in-real-world-2-3">Key 2. IID Assumption Fails in Real World (2, 3)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#key-3-multi-task-learning-is-nacent-4">Key 3. Multi-Task Learning is Nacent (4)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#key-4-from-word-embeddings-to-contextual-embeddings-5-6">Key 4. From Word Embeddings to Contextual Embeddings (5,6)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#key-5-zero-shot-learning-and-zero-shot-transfer-7">Key 5. Zero Shot Learning and Zero Shot Transfer (7)</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#approach">Approach</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#key-1-modeling-language-models-over-joint-probability-distributions-1">Key 1. Modeling Language Models over Joint Probability Distributions (1)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#key-2-conditional-distributions-2">Key 2. Conditional Distributions (2)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#key-3-conditional-on-task-3">Key 3. Conditional on Task (3)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#key-4-optimizing-unsupervised-is-the-same-as-optimizing-supervised-4">Key 4. Optimizing Unsupervised is the same as Optimizing Supervised (4)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#key-5-large-language-models-has-capacity-to-infer-and-generalize-5">Key 5. Large Language Models has Capacity to Infer and Generalize (5)</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#training-dataset">2.1. Training Dataset</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#key-1-rejection-of-commoncrawl-1-2">Key 1. Rejection of CommonCrawl (1,2)</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#key-2-construction-of-webtext-dataset">Key 2. Construction of WebText Dataset</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#input-representation">2.2. Input Representation</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#key-1-byte-pair-encoding-bpe-1-2-3">Key 1. Byte Pair Encoding (BPE) (1,2,3)</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#model">2.3. Model</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#gpt-1-and-gpt-2">GPT-1 and GPT-2</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#autoregressive-self-supervised-learning-paradigm">Autoregressive Self-Supervised Learning Paradigm</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#autoregressive-self-supervised-learning">Autoregressive Self-Supervised Learning</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#estimation-of-the-conditional-probability-distribution">Estimation of the Conditional Probability Distribution</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#initial-condition-of-conditional-probability-distribution">Initial Condition of Conditional Probability Distribution</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#markov-assumption">Markov Assumption</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#the-estimator-function-is-smooth-with-respect-to-the-parameters">The Estimator Function is Smooth with Respect to the Parameters</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#context-length-and-token-context-window">Context Length and Token Context Window</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#conditional-entropy-and-perplexity-as-loss-function">Conditional Entropy and Perplexity as Loss Function</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#conditional-entropy">Conditional Entropy</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#perplexity">Perplexity</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#loss-function">Loss Function</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#convergence">Convergence</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#gpt-is-a-autoregressive-self-supervised-learning-model">GPT is a Autoregressive Self-Supervised Learning Model</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#conditional-on-task">Conditional on Task</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#supervised-fine-tuning">Supervised Fine-Tuning</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#objective-function-for-fine-tuning">Objective Function for Fine-Tuning</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#auxiliary-loss-function">Auxiliary Loss Function</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#references-and-further-readings">References and Further Readings</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Gao Hongnan
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2023.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/bootstrap.js?digest=8d27b9dea8ad943066ae"></script>
<script src="../_static/scripts/pydata-sphinx-theme.js?digest=8d27b9dea8ad943066ae"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>