{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shakespeare\n",
    "\n",
    "\n",
    "```{contents}\n",
    ":local:\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import os\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from typing import Any, Dict, List, Literal, Tuple, Union\n",
    "\n",
    "import numpy as np\n",
    "from numpy.typing import ArrayLike, NDArray\n",
    "import requests\n",
    "import tiktoken\n",
    "import torch\n",
    "from rich.pretty import pprint\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "import os\n",
    "import random\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn\n",
    "\n",
    "from pydantic import BaseModel, Field, model_validator, computed_field\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Composing the Configurations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Composer</span><span style=\"font-weight: bold\">(</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #808000; text-decoration-color: #808000\">seed</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2024</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #808000; text-decoration-color: #808000\">debug</span>=<span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #808000; text-decoration-color: #808000\">url</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt'</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #808000; text-decoration-color: #808000\">dataset_name</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'tinyshakespeare'</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #808000; text-decoration-color: #808000\">data_folder</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'./data/tinyshakespeare'</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #808000; text-decoration-color: #808000\">train_path</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">PosixPath</span><span style=\"font-weight: bold\">(</span><span style=\"color: #008000; text-decoration-color: #008000\">'data/tinyshakespeare/train.txt'</span><span style=\"font-weight: bold\">)</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #808000; text-decoration-color: #808000\">valid_path</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">PosixPath</span><span style=\"font-weight: bold\">(</span><span style=\"color: #008000; text-decoration-color: #008000\">'data/tinyshakespeare/valid.txt'</span><span style=\"font-weight: bold\">)</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #808000; text-decoration-color: #808000\">encoding_name</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'gpt2'</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #808000; text-decoration-color: #808000\">batch_size</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #808000; text-decoration-color: #808000\">block_size</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #808000; text-decoration-color: #808000\">device_type</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'cpu'</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #808000; text-decoration-color: #808000\">device</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">device</span><span style=\"font-weight: bold\">(</span><span style=\"color: #808000; text-decoration-color: #808000\">type</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'cpu'</span><span style=\"font-weight: bold\">)</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #808000; text-decoration-color: #808000\">d_model</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #808000; text-decoration-color: #808000\">d_ff</span>=<span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #808000; text-decoration-color: #808000\">H</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #808000; text-decoration-color: #808000\">vocab_size</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">50257</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #808000; text-decoration-color: #808000\">num_decoder_blocks</span>=<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6</span>\n",
       "<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mComposer\u001b[0m\u001b[1m(\u001b[0m\n",
       "\u001b[2;32m│   \u001b[0m\u001b[33mseed\u001b[0m=\u001b[1;36m2024\u001b[0m,\n",
       "\u001b[2;32m│   \u001b[0m\u001b[33mdebug\u001b[0m=\u001b[3;92mTrue\u001b[0m,\n",
       "\u001b[2;32m│   \u001b[0m\u001b[33murl\u001b[0m=\u001b[32m'https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt'\u001b[0m,\n",
       "\u001b[2;32m│   \u001b[0m\u001b[33mdataset_name\u001b[0m=\u001b[32m'tinyshakespeare'\u001b[0m,\n",
       "\u001b[2;32m│   \u001b[0m\u001b[33mdata_folder\u001b[0m=\u001b[32m'./data/tinyshakespeare'\u001b[0m,\n",
       "\u001b[2;32m│   \u001b[0m\u001b[33mtrain_path\u001b[0m=\u001b[1;35mPosixPath\u001b[0m\u001b[1m(\u001b[0m\u001b[32m'data/tinyshakespeare/train.txt'\u001b[0m\u001b[1m)\u001b[0m,\n",
       "\u001b[2;32m│   \u001b[0m\u001b[33mvalid_path\u001b[0m=\u001b[1;35mPosixPath\u001b[0m\u001b[1m(\u001b[0m\u001b[32m'data/tinyshakespeare/valid.txt'\u001b[0m\u001b[1m)\u001b[0m,\n",
       "\u001b[2;32m│   \u001b[0m\u001b[33mencoding_name\u001b[0m=\u001b[32m'gpt2'\u001b[0m,\n",
       "\u001b[2;32m│   \u001b[0m\u001b[33mbatch_size\u001b[0m=\u001b[1;36m2\u001b[0m,\n",
       "\u001b[2;32m│   \u001b[0m\u001b[33mblock_size\u001b[0m=\u001b[1;36m8\u001b[0m,\n",
       "\u001b[2;32m│   \u001b[0m\u001b[33mdevice_type\u001b[0m=\u001b[32m'cpu'\u001b[0m,\n",
       "\u001b[2;32m│   \u001b[0m\u001b[33mdevice\u001b[0m=\u001b[1;35mdevice\u001b[0m\u001b[1m(\u001b[0m\u001b[33mtype\u001b[0m=\u001b[32m'cpu'\u001b[0m\u001b[1m)\u001b[0m,\n",
       "\u001b[2;32m│   \u001b[0m\u001b[33md_model\u001b[0m=\u001b[1;36m4\u001b[0m,\n",
       "\u001b[2;32m│   \u001b[0m\u001b[33md_ff\u001b[0m=\u001b[3;35mNone\u001b[0m,\n",
       "\u001b[2;32m│   \u001b[0m\u001b[33mH\u001b[0m=\u001b[1;36m8\u001b[0m,\n",
       "\u001b[2;32m│   \u001b[0m\u001b[33mvocab_size\u001b[0m=\u001b[1;36m50257\u001b[0m,\n",
       "\u001b[2;32m│   \u001b[0m\u001b[33mnum_decoder_blocks\u001b[0m=\u001b[1;36m6\u001b[0m\n",
       "\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class Composer(BaseModel):\n",
    "    seed: int = 2024\n",
    "    debug: bool = False\n",
    "\n",
    "    url: str = \"https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\"\n",
    "    dataset_name: str = \"tinyshakespeare\"\n",
    "    data_folder: str = Field(default=\"./data/tinyshakespeare\", description=\"Path to the data folder\")\n",
    "\n",
    "    train_path: Path = Field(None, description=\"Path to the train file\")\n",
    "    valid_path: Path = Field(None, description=\"Path to the valid file\")\n",
    "\n",
    "    encoding_name: Literal['gpt2', 'r50k_base', 'p50k_base', 'p50k_edit', 'cl100k_base'] = \"gpt2\"\n",
    "\n",
    "    batch_size: int = Field(default=64, description=\"Batch size\")\n",
    "    block_size: int = Field(default=128, description=\"Block size, an alias for max length/context window size.\", alias=\"context_length\")\n",
    "    device_type: Literal[\"cpu\", \"cuda\"] = \"cpu\"\n",
    "    device: torch.device = Field(None, description=\"Device to use\")\n",
    "\n",
    "    # model parameters\n",
    "    d_model: int = Field(default=512, description=\"Dimension of the model\")\n",
    "    d_ff: int = Field(default=None, description=\"Dimension of the feed forward layer\")\n",
    "    H: int = Field(default=8, description=\"Number of heads\", alias=\"num_heads\")\n",
    "    vocab_size: int = Field(default=50257, description=\"Vocabulary size\")\n",
    "    num_decoder_blocks: int = Field(default=6, description=\"Number of decoder blocks\")\n",
    "\n",
    "\n",
    "    @model_validator(mode=\"after\")\n",
    "    def set_train_valid_paths(self) -> Composer:\n",
    "        self.train_path = Path(self.data_folder) / \"train.txt\"\n",
    "        self.valid_path = Path(self.data_folder) / \"valid.txt\"\n",
    "        return self\n",
    "\n",
    "    @model_validator(mode=\"after\")\n",
    "    def set_device(self) -> Composer:\n",
    "        self.device = torch.device(self.device_type)\n",
    "        return self\n",
    "\n",
    "    @model_validator(mode=\"after\")\n",
    "    def set_debug_fields(self) -> Composer:\n",
    "        if self.debug:\n",
    "            self.batch_size = 2\n",
    "            self.block_size = 8\n",
    "            self.d_model = 4\n",
    "        return self\n",
    "\n",
    "    class Config:\n",
    "        extra = \"forbid\"\n",
    "        arbitrary_types_allowed = True\n",
    "\n",
    "composer = Composer(debug=True)\n",
    "pprint(composer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "def configure_deterministic_mode() -> None:\n",
    "    \"\"\"\n",
    "    See https://pytorch.org/docs/stable/generated/torch.use_deterministic_algorithms.html\n",
    "    and https://docs.nvidia.com/cuda/cublas/index.html#cublasApi_reproducibility\n",
    "    \"\"\"\n",
    "    # fmt: off\n",
    "    torch.use_deterministic_algorithms(True, warn_only=True)\n",
    "    torch.backends.cudnn.benchmark        = False\n",
    "    torch.backends.cudnn.deterministic    = True\n",
    "    torch.backends.cudnn.enabled          = False\n",
    "\n",
    "    os.environ['CUBLAS_WORKSPACE_CONFIG'] = ':4096:8'\n",
    "    # fmt: on\n",
    "    warnings.warn(\n",
    "        \"Deterministic mode is activated. This will negatively impact performance and may cause increase in CUDA memory footprint.\",\n",
    "        category=UserWarning,\n",
    "        stacklevel=2,\n",
    "    )\n",
    "\n",
    "\n",
    "def seed_all(\n",
    "    seed: int = 1992,\n",
    "    seed_torch: bool = True,\n",
    "    set_torch_deterministic: bool = True,\n",
    ") -> int:\n",
    "    \"\"\"\n",
    "    Seed all random number generators.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    seed : int\n",
    "        Seed number to be used, by default 1992.\n",
    "    seed_torch : bool\n",
    "        Whether to seed PyTorch or not, by default True.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    seed: int\n",
    "        The seed number.\n",
    "    \"\"\"\n",
    "    # fmt: off\n",
    "    os.environ[\"PYTHONHASHSEED\"] = str(seed)       # set PYTHONHASHSEED env var at fixed value\n",
    "    np.random.default_rng(seed)                    # numpy pseudo-random generator\n",
    "    random.seed(seed)                              # python's built-in pseudo-random generator\n",
    "\n",
    "    if seed_torch:\n",
    "        torch.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)           # pytorch (both CPU and CUDA)\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "        torch.backends.cudnn.enabled = False\n",
    "\n",
    "        if set_torch_deterministic:\n",
    "            configure_deterministic_mode()\n",
    "    # fmt: on\n",
    "    return seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2024"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed_all(composer.seed, seed_torch=True, set_torch_deterministic=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenization and Vocabulary\n",
    "\n",
    "- https://huggingface.co/learn/nlp-course/chapter2/4?fw=pt\n",
    "- https://github.com/openai/tiktoken\n",
    "- https://github.com/openai/openai-cookbook/blob/main/examples/How_to_count_tokens_with_tiktoken.ipynb\n",
    "\n",
    "Language models don't see text like you and I, instead they see a sequence of numbers (known as tokens). Byte pair encoding (BPE) is a way of converting text into tokens. It has a couple desirable properties[^1]:\n",
    "\n",
    "- It's reversible and lossless, so you can convert tokens back into the original text\n",
    "- It works on arbitrary text, even text that is not in the tokeniser's training data\n",
    "- It compresses the text: the token sequence is shorter than the bytes corresponding to the original text. On average, in practice, each token corresponds to about 4 bytes.\n",
    "- It attempts to let the model see common subwords. For instance, \"ing\" is a common subword in English, so BPE encodings will often split \"encoding\" into tokens like \"encod\" and \"ing\" (instead of e.g. \"enc\" and \"oding\"). Because the model will then see the \"ing\" token again and again in different contexts, it helps models generalise and better understand grammar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "def am_i_in_jupyter() -> bool:\n",
    "    try:\n",
    "        from IPython import get_ipython\n",
    "        if \"IPKernelApp\" not in get_ipython().config:\n",
    "            return False\n",
    "    except ImportError:\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "IN_JUPYTER = am_i_in_jupyter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download(url: str, dataset_name: str, dest_folder: Path | str) -> Path:\n",
    "    dest_folder_path = Path(dest_folder)\n",
    "\n",
    "    dest_folder_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    filepath = dest_folder_path / f\"{dataset_name}.txt\"\n",
    "\n",
    "    response = requests.get(url, stream=True)\n",
    "    corpus = response.text\n",
    "    response.raise_for_status()\n",
    "\n",
    "    with open(filepath, \"wb\") as f:\n",
    "        for chunk in response.iter_content(chunk_size=8192):\n",
    "            f.write(chunk)\n",
    "\n",
    "    return filepath, corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">PosixPath</span><span style=\"font-weight: bold\">(</span><span style=\"color: #008000; text-decoration-color: #008000\">'data/tinyshakespeare/tinyshakespeare.txt'</span><span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mPosixPath\u001b[0m\u001b[1m(\u001b[0m\u001b[32m'data/tinyshakespeare/tinyshakespeare.txt'\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Citizen:\n",
      "Before we proceed any further, hear me speak.\n",
      "\n",
      "All:\n",
      "Speak, speak.\n",
      "\n",
      "First Citizen:\n",
      "You\n"
     ]
    }
   ],
   "source": [
    "filepath, corpus = download(composer.url, composer.dataset_name, composer.data_folder)\n",
    "pprint(filepath)\n",
    "print(corpus[:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['gpt2', 'r50k_base', 'p50k_base', 'p50k_edit', 'cl100k_base'], 50257)"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N = len(corpus)\n",
    "train_data = corpus[: int(N * 0.9)]\n",
    "valid_data = corpus[int(N * 0.9) :]\n",
    "\n",
    "# encode with tiktoken gpt2 bpe\n",
    "tokenizer = tiktoken.get_encoding(composer.encoding_name)\n",
    "tiktoken.list_encoding_names(), tokenizer.n_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train has 301,966 tokens\n",
      "val has 36,059 tokens\n"
     ]
    }
   ],
   "source": [
    "train_ids = tokenizer.encode_ordinary(train_data)\n",
    "valid_ids = tokenizer.encode_ordinary(valid_data)\n",
    "print(f\"train has {len(train_ids):,} tokens\")\n",
    "print(f\"val has {len(valid_ids):,} tokens\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Citizen\n",
      "--------------------------------------------------------------------------------\n",
      "First Citizen:\n",
      "Before we proceed any further, hear me speak.\n",
      "\n",
      "All:\n",
      "Speak, speak.\n",
      "\n",
      "First Citizen:\n",
      "You are all resolved rather to die than to famish?\n",
      "\n",
      "All:\n",
      "Resolved. resolved.\n",
      "\n",
      "First Citizen:\n",
      "First, you know Caius Marcius is chief enemy to the people.\n",
      "\n",
      "All:\n",
      "We know't, we know't.\n",
      "\n",
      "First Citizen:\n",
      "Let us kill him, and we\n"
     ]
    }
   ],
   "source": [
    "print(tokenizer.decode(train_ids[:2]))\n",
    "print(\"-\" * 80)\n",
    "print(tokenizer.decode(train_ids[:100]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export to bin files\n",
    "train_ids = np.array(train_ids, dtype=np.uint16)\n",
    "valid_ids = np.array(valid_ids, dtype=np.uint16)\n",
    "\n",
    "train_ids.tofile(composer.train_path)\n",
    "valid_ids.tofile(composer.valid_path)\n",
    "\n",
    "# train.bin has 301,966 tokens\n",
    "# val.bin has 36,059 tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STOI (TODO)\n",
    "\n",
    "- The first `input` is the sentence `hello bot`.\n",
    "- The tokenization is `[0, 3, 4, 1]` which correctly maps to the tokens `[<SOS>, hello, bot, <EOS>]` as per the `stoi` mapping.\n",
    "- The shape is `[1, 4]` because we have one sentence with 4 tokens, where the first token is the `<SOS>` token and the last token is the `<EOS>` token.\n",
    "    - In this context, the first dimension of the shape corresponds to the number of sentences (or samples) in the batch, and the second dimension corresponds to the number of tokens in each sentence.\n",
    "\n",
    "---\n",
    "\n",
    "In mathematical terms, we have:\n",
    "\n",
    "- The vocabulary $\\mathcal{V}$ consists of the unique tokens $\\{\\text{<SOS>, <EOS>, <PAD>, hello, bot, human}\\}$ in our text data. The size of the vocabulary is $V = |\\mathcal{V}| = 6$.\n",
    "\n",
    "- We define a function $f_{\\text{stoi}}$ that maps each token in our vocabulary to a unique integer index. \n",
    "  \n",
    "  $$\n",
    "  \\begin{aligned}\n",
    "  f_{\\text{stoi}}: \\mathcal{V} &\\to \\{0, 1, ..., V-1\\} \\\\\n",
    "  v &\\mapsto f_{\\text{stoi}}(v)\n",
    "  \\end{aligned}\n",
    "  $$\n",
    "  \n",
    "  This function represents the `stoi` mapping in the code. For example, $f_{\\text{stoi}}(\\text{<SOS>}) = 0$, $f_{\\text{stoi}}(\\text{hello}) = 3$, etc.\n",
    "\n",
    "- A sequence of text, such as the sentence \"hello bot\", is represented as a sequence of token indices $X=(x_1, x_2, x_3, x_4)$ using the $f_{\\text{stoi}}$ mapping. For the sentence \"hello bot\", we have:\n",
    "  \n",
    "    $$\n",
    "    \\begin{aligned}\n",
    "    \\mathbf{X} &= (f_{\\text{stoi}}(\\text{<SOS>}), f_{\\text{stoi}}(\\text{hello}), f_{{\\text{stoi}}}(\\text{bot}), f_{\\text{stoi}}(\\text{<EOS>})) \\\\\n",
    "    &= (0, 3, 4, 1)\n",
    "    \\end{aligned}\n",
    "    $$\n",
    "\n",
    "- Although $\\mathbf{X}$ is a sequence, we can consider it to be a vector:\n",
    "\n",
    "    $$\n",
    "    \\mathbf{X} = \\begin{bmatrix} 0 & 3 & 4 & 1 \\end{bmatrix} \\in \\mathbb{Z}^{1 \\times 4}\n",
    "    $$\n",
    "\n",
    "    which correctly corresponds to the shape `[1, 4]` in the code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset and Dataloading (Poor Man's Dataloader)\n",
    "\n",
    "**TODO: to bridge the gap between the previous section and this one, we need to\n",
    "explain why we need to construct a dataset.**\n",
    "\n",
    "---\n",
    "\n",
    "As Karpathy puts it, he implemented a poor man's\n",
    "[dataloader](https://pytorch.org/tutorials/beginner/basics/data_tutorial.html).\n",
    "We will start by dissecting the code and understanding how it works and finally,\n",
    "show that everything can be done with PyTorch's `Dataset` and `Dataloader`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Memory Mapping\n",
    "\n",
    "Firstly, Karpathy uses `numpy`'s\n",
    "[memory mapping](https://numpy.org/doc/stable/reference/generated/numpy.memmap.html)\n",
    "(`numpy.memmap`) to load the data. Memory mapping is used to create a\n",
    "memory-mapped array from a binary file. This involves mapping the contents of a\n",
    "file directly into the virtual memory space of the calling process. This allows\n",
    "applications to access the file data as if it were loaded in memory, using\n",
    "pointer operations or array indexing, without the need for explicit read or\n",
    "write operations.\n",
    "\n",
    "This essentially means that you can access small segments of a large file\n",
    "without having to load the entire file into memory. The concept draws\n",
    "similarities to the use of [generators](https://wiki.python.org/moin/Generators)\n",
    "in Python, where you can iterate over a large dataset without having to load the\n",
    "entire dataset into memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_dtype: uint16, data_shape: (301966,)\n"
     ]
    }
   ],
   "source": [
    "train_data = np.memmap(composer.train_path, dtype=np.uint16, mode=\"r\")\n",
    "train_data_dtype = train_data.dtype\n",
    "train_data_shape = train_data.shape\n",
    "\n",
    "print(f\"data_dtype: {train_data_dtype}, data_shape: {train_data_shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the shape of train data is `(301966,)`, which means that it is a 1D (flattened) array \n",
    "with $301966$ elements - this is basically the length of the entire train corpus, in terms of\n",
    "tokens."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notation, Context Length, Shuffling and Batching"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, we are not going to pass the entire training corpus as is to the model.\n",
    "Instead, we are going to pass a **batch** of sequences (each sequence of length\n",
    "`context_length`) to the model at a time.\n",
    "\n",
    "#### Notation\n",
    "\n",
    "Let's consider a sequence $\\mathbf{x} = (x_1, x_2, \\ldots, x_T)$, where:\n",
    "\n",
    "-   $x_t$ represents the $t$-th token in the sequence,\n",
    "-   Each token $x_t$ is an element of a predefined vocabulary $\\mathcal{V} := \\mathcal{X}$,\n",
    "-   $T$ denotes the total number of tokens in the sequence, i.e., the sequence\n",
    "    length.\n",
    "\n",
    "In practice, we handle multiple sequences at once by grouping them into a batch.\n",
    "This batch, denoted as $\\mathcal{B}$, is then presented to the model for\n",
    "parallel processing.\n",
    "\n",
    "A batch of sequences is represented as a matrix $\\mathbf{X}$, where each row\n",
    "corresponds to a sequence in the batch. If the batch size is $\\mathcal{B}$ and\n",
    "each sequence within the batch has a fixed length $T$, then $\\mathbf{X}$ can be\n",
    "expressed as:\n",
    "\n",
    "$$\n",
    "    \\mathbf{X} = \\begin{bmatrix} x_{1,1} & x_{1,2} & \\ldots & x_{1,T} \\\\ x_{2,1}\n",
    "        & x_{2,2} & \\ldots & x_{2,T} \\\\ \\vdots & \\vdots & \\ddots & \\vdots \\\\ x_{\\mathcal{B},1} &\n",
    "        x_{\\mathcal{B},2} & \\ldots & x_{\\mathcal{B},T} \\\\\\end{bmatrix} \\in \\mathbb{Z}^{\\mathcal{B} \\times T}\n",
    "$$\n",
    "\n",
    "Here, $x_{i,j}$ denotes the $j$-th token in the $i$-th sequence of the batch.\n",
    "It's important to note that while we represent the sequences in a real-valued\n",
    "space $\\mathbb{Z}^{\\mathcal{B} \\times T}$ for mathematical convenience, in\n",
    "practice, each $x_{i,j}$ corresponds to a discrete token from the vocabulary\n",
    "$\\mathcal{X}$ so using $\\mathbb{Z}^{+}$ would be more appropriate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Context Length / Block Size\n",
    "\n",
    "$T$ is often referred to as the sequence length, or in the context of GPT, it is\n",
    "the `block_size` or `context_length` or `max_seq_len`.\n",
    "\n",
    "It is the length of the sequence that the model will be trained on and is also\n",
    "the context length/context window that we often hear about.\n",
    "\n",
    "For example,\n",
    "[Gemini 1.5](https://blog.google/technology/ai/google-gemini-next-generation-model-february-2024)\n",
    "was announced to have a standard $128,000$ token context window, up to a maximum\n",
    "of $1$ million max length.\n",
    "\n",
    "Typically, I think that if your model is trained on a certain context length, it\n",
    "is not trivial to change it. For example, if you train a model on a context\n",
    "length of $128$, you cannot simply change it to $256$ without retraining the\n",
    "model. But it seems that it is increasingly possible to do so."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at an example, if we define our $L$ to be $32$, then we would expect each\n",
    "sequence to be of length $32$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">memmap</span><span style=\"font-weight: bold\">([</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5962</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">22307</span>,    <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">25</span>,   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">198</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8421</span>,   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">356</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5120</span>,   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">597</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2252</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │      </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">11</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3285</span>,   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">502</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2740</span>,    <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">13</span>,   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">198</span>,   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">198</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3237</span>,    <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">25</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │     </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">198</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5248</span>,   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">461</span>,    <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">11</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2740</span>,    <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">13</span>,   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">198</span>,   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">198</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5962</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">22307</span>,    <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">25</span>,   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">198</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1639</span>,   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">389</span><span style=\"font-weight: bold\">]</span>, <span style=\"color: #808000; text-decoration-color: #808000\">dtype</span>=<span style=\"color: #800080; text-decoration-color: #800080\">uint16</span><span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mmemmap\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m \u001b[1;36m5962\u001b[0m, \u001b[1;36m22307\u001b[0m,    \u001b[1;36m25\u001b[0m,   \u001b[1;36m198\u001b[0m,  \u001b[1;36m8421\u001b[0m,   \u001b[1;36m356\u001b[0m,  \u001b[1;36m5120\u001b[0m,   \u001b[1;36m597\u001b[0m,  \u001b[1;36m2252\u001b[0m,\n",
       "\u001b[2;32m│   │      \u001b[0m\u001b[1;36m11\u001b[0m,  \u001b[1;36m3285\u001b[0m,   \u001b[1;36m502\u001b[0m,  \u001b[1;36m2740\u001b[0m,    \u001b[1;36m13\u001b[0m,   \u001b[1;36m198\u001b[0m,   \u001b[1;36m198\u001b[0m,  \u001b[1;36m3237\u001b[0m,    \u001b[1;36m25\u001b[0m,\n",
       "\u001b[2;32m│   │     \u001b[0m\u001b[1;36m198\u001b[0m,  \u001b[1;36m5248\u001b[0m,   \u001b[1;36m461\u001b[0m,    \u001b[1;36m11\u001b[0m,  \u001b[1;36m2740\u001b[0m,    \u001b[1;36m13\u001b[0m,   \u001b[1;36m198\u001b[0m,   \u001b[1;36m198\u001b[0m,  \u001b[1;36m5962\u001b[0m,\n",
       "\u001b[2;32m│   │   \u001b[0m\u001b[1;36m22307\u001b[0m,    \u001b[1;36m25\u001b[0m,   \u001b[1;36m198\u001b[0m,  \u001b[1;36m1639\u001b[0m,   \u001b[1;36m389\u001b[0m\u001b[1m]\u001b[0m, \u001b[33mdtype\u001b[0m=\u001b[35muint16\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Citizen:\n",
      "Before we proceed any further, hear me speak.\n",
      "\n",
      "All:\n",
      "Speak, speak.\n",
      "\n",
      "First Citizen:\n",
      "You are\n"
     ]
    }
   ],
   "source": [
    "first_sequence = train_data[0:0+32]\n",
    "pprint(first_sequence)\n",
    "\n",
    "first_sequence_decoded = tokenizer.decode(first_sequence)\n",
    "print(first_sequence_decoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The example is just extracting $1$ such sequence $\\mathbf{x}$ from the train\n",
    "corpus. To leverage the prowess of linear algebra operations in CUDA, we would\n",
    "typically pass a batch of sequences $\\mathcal{B}$ to the model at a time.\n",
    "\n",
    "Furthermore, we would require some level of randomness in the sequences that we\n",
    "pass to the model to enable generalisation. You really do not want the model to\n",
    "overfit to an ordered sequence of tokens in the training corpus.\n",
    "\n",
    "To this end, let's see how Karpathy implements batching and shuffling of the\n",
    "sequences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Shuffling and Discrete Uniform Sampling\n",
    "\n",
    "To enable shuffling, Karpathy generates a tensor of random integers (essentially a list of\n",
    "random integers), which serve as indices. These indices are used to select\n",
    "random sequences from the training (and validation) data.\n",
    "\n",
    "For simplicity, let's look at the case where batch size is reduced to $\\mathcal{B} = 1$.\n",
    "This means we only need to sample $1$ sequence from the training data - and consequently\n",
    "we only need $1$ random index.\n",
    "\n",
    "We can easily achieve this via `torch.randint` which generates random integers\n",
    "from a discrete uniform distribution over the half-open interval $[l, h)$,\n",
    "and since we only want to sample $1$ sequence, we set `size=(1,)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">tensor</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">122484</span><span style=\"font-weight: bold\">])</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m122484\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">torch.Size</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span><span style=\"font-weight: bold\">])</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "generator = torch.Generator(device=composer.device)\n",
    "\n",
    "generator.manual_seed(25)\n",
    "\n",
    "low, high = 0, len(train_data) - composer.block_size\n",
    "size = (1,)\n",
    "indices: torch.Tensor = torch.randint(low=low, high=high, size=size, generator=generator)\n",
    "pprint(indices)\n",
    "pprint(indices.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The mathematical operation performed by `torch.randint(low, high, size, generator)` can be described as drawing samples from a uniform discrete distribution. Each element of the resulting tensor is an independent and identically distributed {cite}`radford2019language` (i.i.d.) random variable $X_i$ with the following probability mass function (PMF):\n",
    "\n",
    "$$\n",
    "\\mathbb{P}(X_i = k) = \\frac{1}{h - l} \\quad \\text{for} \\, k = l, \\ldots, h-1 \n",
    "$$\n",
    "\n",
    "This PMF implies that each integer in the range $[l, h-1]$ has an equal probability of being selected."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our demonstration, we selected a random index, specifically $136,016$, from\n",
    "our training dataset. This serves as a starting point for constructing a\n",
    "sequence, denoted as $\\mathbf{x}$. This sequence consists of the token found at\n",
    "the chosen index and extends to include the subsequent $T$ tokens, where $T$\n",
    "represents the block size. For the sake of simplicity, and to align with our\n",
    "predefined settings, we have chosen $T = 8$. This block size is predetermined in\n",
    "our `composer` configuration, activated specifically under a `debug` mode.\n",
    "\n",
    "In code, we can achieve this by slicing the training data from the random index\n",
    "to the random index plus the block size. This is done by `train_data[random_index:random_index+block_size]`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">memmap</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">11503</span>,   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">290</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">21120</span>,    <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">30</span>,   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">880</span>,   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">788</span>,    <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">11</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">29448</span><span style=\"font-weight: bold\">]</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│      </span><span style=\"color: #808000; text-decoration-color: #808000\">dtype</span>=<span style=\"color: #800080; text-decoration-color: #800080\">uint16</span><span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mmemmap\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m11503\u001b[0m,   \u001b[1;36m290\u001b[0m, \u001b[1;36m21120\u001b[0m,    \u001b[1;36m30\u001b[0m,   \u001b[1;36m880\u001b[0m,   \u001b[1;36m788\u001b[0m,    \u001b[1;36m11\u001b[0m, \u001b[1;36m29448\u001b[0m\u001b[1m]\u001b[0m,\n",
       "\u001b[2;32m│      \u001b[0m\u001b[33mdtype\u001b[0m=\u001b[35muint16\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">(</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8</span>,<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m(\u001b[0m\u001b[1;36m8\u001b[0m,\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " priest and clerk? well then, amen\n"
     ]
    }
   ],
   "source": [
    "random_sequence = train_data[indices:indices+composer.block_size]\n",
    "pprint(random_sequence)\n",
    "pprint(random_sequence.shape)\n",
    "\n",
    "random_sequence_decoded = tokenizer.decode(random_sequence)\n",
    "print(tokenizer.decode(random_sequence))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One might wonder why the highest value of the random integers is\n",
    "`len(self.train_data) - self.block_size`. This is mostly to prevent index out of\n",
    "range errors. As we shall soon see, we are using these `indices` to slice a\n",
    "sequence of length `block_size` from the data where you start slicing from the\n",
    "index `index` and end at `index + block_size`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Batching\n",
    "\n",
    "Now that we understand how to sample a single sequence from the training data,\n",
    "let's look at how we can sample a batch of sequences.\n",
    "PyTorch made it easy for you, as we can just simply change the `size` parameter\n",
    "to `(batch_size,)` so we can sample $\\mathcal{B}$ number of indices - and\n",
    "consequently $\\mathcal{B}$ number of sequences.\n",
    "\n",
    "In our case, if we set $\\mathcal{B} = 2$, we would expect to get $2$ random\n",
    "indices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">tensor</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">122484</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">196406</span><span style=\"font-weight: bold\">])</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m122484\u001b[0m, \u001b[1;36m196406\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">torch.Size</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span><span style=\"font-weight: bold\">])</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "generator = torch.Generator(device=composer.device)\n",
    "generator.manual_seed(25)\n",
    "low, high = 0, len(train_data) - composer.block_size\n",
    "size = (composer.batch_size,)\n",
    "indices: torch.Tensor = torch.randint(low=low, high=high, size=size, generator=generator)\n",
    "pprint(indices)\n",
    "pprint(indices.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then construct a batch of \n",
    "input sequences $\\mathcal{B}$ by selecting the tokens at the\n",
    "indices $136,016$ and $197,976$ and the next $T$ tokens via a for loop - and using `torch.stack`\n",
    "to stack the sequences into a tensor of shape $\\mathbb{Z}^{\\mathcal{B} \\times L}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">tensor</span><span style=\"font-weight: bold\">([[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">11503</span>,   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">290</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">21120</span>,    <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">30</span>,   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">880</span>,   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">788</span>,    <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">11</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">29448</span><span style=\"font-weight: bold\">]</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"font-weight: bold\">[</span>  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">326</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8616</span>,   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">373</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">14855</span>,    <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">13</span>,   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">198</span>,   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">198</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">37286</span><span style=\"font-weight: bold\">]])</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m11503\u001b[0m,   \u001b[1;36m290\u001b[0m, \u001b[1;36m21120\u001b[0m,    \u001b[1;36m30\u001b[0m,   \u001b[1;36m880\u001b[0m,   \u001b[1;36m788\u001b[0m,    \u001b[1;36m11\u001b[0m, \u001b[1;36m29448\u001b[0m\u001b[1m]\u001b[0m,\n",
       "\u001b[2;32m│   │   \u001b[0m\u001b[1m[\u001b[0m  \u001b[1;36m326\u001b[0m,  \u001b[1;36m8616\u001b[0m,   \u001b[1;36m373\u001b[0m, \u001b[1;36m14855\u001b[0m,    \u001b[1;36m13\u001b[0m,   \u001b[1;36m198\u001b[0m,   \u001b[1;36m198\u001b[0m, \u001b[1;36m37286\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">torch.Size</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8</span><span style=\"font-weight: bold\">])</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m2\u001b[0m, \u001b[1;36m8\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = torch.stack([torch.from_numpy((train_data[index : index + composer.block_size]).astype(np.int64)) for index in indices])\n",
    "pprint(x)\n",
    "pprint(x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is worth reconciling the fact that the slicing uses `[index:index + block_size]` and\n",
    "therefore completes the reasoning behind the `len(self.train_data) - self.block_size` in\n",
    "the `torch.randint` function call - to prevent index out of range errors. Consider\n",
    "that if we do not subtract `block_size` from the length of the training data, we might\n",
    "end up with an index that is the last index of the training data, and when we add\n",
    "`block_size` to it, we would end up with an index that is out of range."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construction of Input and Target Sequences\n",
    "\n",
    "As we will define more formally later, GPT model is an autoregressive\n",
    "self-supervised learning model{cite}`math11112451` that directly learns a\n",
    "conditional probability distribution $\\mathbb{P}(x_t | x_{<t} ; \\Theta)$ over\n",
    "the vocabulary $\\mathcal{V}$ of tokens, which is conditioned on the entire\n",
    "history of tokens $x_{<t} = (x_1, x_2, \\ldots, x_{t-1})$.\n",
    "\n",
    "We have seen earlier how to construct an input sequence $\\mathbf{x}$ from the\n",
    "training data. To put things into perspective, we consider again the first\n",
    "sequence that we constructed from the training data:\n",
    "\n",
    "$$\n",
    "\\mathbf{x} = \\begin{bmatrix} 3194 & 612 & 11 & 290 & 284 & 606 & 910 & 11 \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "representing the sentence `' written there, and to them say,'`.\n",
    "\n",
    "Given the autoregressive and self-supervised nature, in order to construct the\n",
    "target sequence $\\mathbf{y}$, we simply shift the input sequence by one token to\n",
    "the left. This means that the target sequence $\\mathbf{y}$ is:\n",
    "\n",
    "$$\n",
    "\\mathbf{y} = \\begin{bmatrix} 612 & 11 & 290 & 284 & 606 & 910 & 11 & 198 \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "representing the sentence `' there, and to them say,\\n'`.\n",
    "\n",
    "This behaviour is autoregressive because we are using the context tokens\n",
    "$x_{<t}$ to predict the next token $x_t$, and self-supervised because we are\n",
    "using the input sequence $\\mathbf{x}$ to construct the target sequence\n",
    "$\\mathbf{y}$ without any external labels.\n",
    "\n",
    "To illustrate further, the prediction process during training is cumulative:\n",
    "\n",
    "-   For predicting $x_2$, the model uses $x_1$ as context:\n",
    "    $\\mathbb{P}\\left(x_2 \\mid x_1\\right)$.\n",
    "-   For predicting $x_3$, the model uses both $x_1$ and $x_2$ as context:\n",
    "    $\\mathbb{P}\\left(x_3 \\mid x_1, x_2\\right)$.\n",
    "-   This pattern continues, such that for predicting $x_t$, the model uses\n",
    "    $x_1, x_2, \\ldots, x_{t-1}$ as context:\n",
    "    $\\mathbb{P}\\left(x_t \\mid x_1, x_2, \\ldots, x_{t-1}\\right)$\n",
    "\n",
    "In code, we can achieve this by simply slicing the adding a `1` to the `index`\n",
    "in the `train_data` slicing operation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">tensor</span><span style=\"font-weight: bold\">([[</span>  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">290</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">21120</span>,    <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">30</span>,   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">880</span>,   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">788</span>,    <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">11</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">29448</span>,    <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">13</span><span style=\"font-weight: bold\">]</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"font-weight: bold\">[</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8616</span>,   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">373</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">14855</span>,    <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">13</span>,   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">198</span>,   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">198</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">37286</span>,   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">406</span><span style=\"font-weight: bold\">]])</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m  \u001b[1;36m290\u001b[0m, \u001b[1;36m21120\u001b[0m,    \u001b[1;36m30\u001b[0m,   \u001b[1;36m880\u001b[0m,   \u001b[1;36m788\u001b[0m,    \u001b[1;36m11\u001b[0m, \u001b[1;36m29448\u001b[0m,    \u001b[1;36m13\u001b[0m\u001b[1m]\u001b[0m,\n",
       "\u001b[2;32m│   │   \u001b[0m\u001b[1m[\u001b[0m \u001b[1;36m8616\u001b[0m,   \u001b[1;36m373\u001b[0m, \u001b[1;36m14855\u001b[0m,    \u001b[1;36m13\u001b[0m,   \u001b[1;36m198\u001b[0m,   \u001b[1;36m198\u001b[0m, \u001b[1;36m37286\u001b[0m,   \u001b[1;36m406\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">torch.Size</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8</span><span style=\"font-weight: bold\">])</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m2\u001b[0m, \u001b[1;36m8\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "' and clerk? well then, amen.'"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = torch.stack([torch.from_numpy((train_data[index + 1: index + 1 + composer.block_size]).astype(np.int64)) for index in indices])\n",
    "pprint(y)\n",
    "pprint(y.shape)\n",
    "\n",
    "tokenizer.decode(y[0].numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Asynchronous Data Loading and Prefetching\n",
    "\n",
    "As we approach the last part of the code, Karpathy moves `x` and `y` to the\n",
    "device and returns them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "if composer.device_type == \"cuda\":\n",
    "    # pin arrays x,y, which allows us to move them to GPU asynchronously (non_blocking=True)\n",
    "    x, y = x.pin_memory().to(composer.device, non_blocking=True), y.pin_memory().to(composer.device, non_blocking=True)\n",
    "else:\n",
    "    x, y = x.to(composer.device), y.to(composer.device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a common operation in PyTorch, where we move the data to the underlying\n",
    "device (CPU or GPU or MPS) to leverage the processing capabilities of the\n",
    "device. It goes without saying that modern deep learning models are trained on\n",
    "GPUs - and CUDA is the de facto standard for GPU-accelerated computing.\n",
    "\n",
    "CUDA allows a `pin_memory` and `non_blocking` parameter to be set when transferring\n",
    "tensor data from CPU to GPU. The `pin_memory` parameter is used to allow `.to(\"cuda\")`\n",
    "to be more [performant](https://devblogs.nvidia.com/how-optimize-data-transfers-cuda-cc/)\n",
    "as it avoids some implicit CPU-to-CPU copies. Tensors which are pinned in memory\n",
    "also allow the transfer from CPU to GPU to be done asynchronously via `non_blocking` with respect to\n",
    "the host[^2].\n",
    "\n",
    "It can be useful because we can do some other work in CPU while the data is being\n",
    "transferred to GPU. Consider the below scenario:\n",
    "\n",
    "- `tensor.pin_memory().to(\"cuda\", non_blocking=True)` will transfer the tensor\n",
    "  to the GPU asynchronously, and the CPU can continue doing some other work.\n",
    "- While waiting, CPU can do some other operations without waiting for the\n",
    "  transfer to complete,\n",
    "- Once `tensor` is transferred to the GPU, then we can do some other operations\n",
    "  on the GPU.\n",
    "\n",
    "What is worth noting is that CUDA manages the synchronization such that\n",
    "operations on the GPU will not start until the transfer is complete. However, CUDA\n",
    "programming is complex and is out of the scope of this post. Interested readers\n",
    "can see the reference section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Collating Everything Together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">tensor</span><span style=\"font-weight: bold\">([[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">11503</span>,   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">290</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">21120</span>,    <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">30</span>,   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">880</span>,   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">788</span>,    <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">11</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">29448</span><span style=\"font-weight: bold\">]</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"font-weight: bold\">[</span>  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">326</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8616</span>,   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">373</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">14855</span>,    <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">13</span>,   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">198</span>,   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">198</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">37286</span><span style=\"font-weight: bold\">]])</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m11503\u001b[0m,   \u001b[1;36m290\u001b[0m, \u001b[1;36m21120\u001b[0m,    \u001b[1;36m30\u001b[0m,   \u001b[1;36m880\u001b[0m,   \u001b[1;36m788\u001b[0m,    \u001b[1;36m11\u001b[0m, \u001b[1;36m29448\u001b[0m\u001b[1m]\u001b[0m,\n",
       "\u001b[2;32m│   │   \u001b[0m\u001b[1m[\u001b[0m  \u001b[1;36m326\u001b[0m,  \u001b[1;36m8616\u001b[0m,   \u001b[1;36m373\u001b[0m, \u001b[1;36m14855\u001b[0m,    \u001b[1;36m13\u001b[0m,   \u001b[1;36m198\u001b[0m,   \u001b[1;36m198\u001b[0m, \u001b[1;36m37286\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">tensor</span><span style=\"font-weight: bold\">([[</span>  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">290</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">21120</span>,    <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">30</span>,   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">880</span>,   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">788</span>,    <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">11</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">29448</span>,    <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">13</span><span style=\"font-weight: bold\">]</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"font-weight: bold\">[</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8616</span>,   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">373</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">14855</span>,    <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">13</span>,   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">198</span>,   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">198</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">37286</span>,   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">406</span><span style=\"font-weight: bold\">]])</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m  \u001b[1;36m290\u001b[0m, \u001b[1;36m21120\u001b[0m,    \u001b[1;36m30\u001b[0m,   \u001b[1;36m880\u001b[0m,   \u001b[1;36m788\u001b[0m,    \u001b[1;36m11\u001b[0m, \u001b[1;36m29448\u001b[0m,    \u001b[1;36m13\u001b[0m\u001b[1m]\u001b[0m,\n",
       "\u001b[2;32m│   │   \u001b[0m\u001b[1m[\u001b[0m \u001b[1;36m8616\u001b[0m,   \u001b[1;36m373\u001b[0m, \u001b[1;36m14855\u001b[0m,    \u001b[1;36m13\u001b[0m,   \u001b[1;36m198\u001b[0m,   \u001b[1;36m198\u001b[0m, \u001b[1;36m37286\u001b[0m,   \u001b[1;36m406\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def get_batch(\n",
    "    composer: Composer,\n",
    "    *,\n",
    "    split: Literal[\"train\", \"valid\"],\n",
    "    batch_size: int,\n",
    "    block_size: int,\n",
    "    generator: torch.Generator,\n",
    "    device: torch.device,\n",
    "    device_type: Literal[\"cpu\", \"cuda\"] = \"cpu\",\n",
    ") -> Tuple[torch.Tensor, torch.Tensor]:\n",
    "    # We recreate np.memmap every batch to avoid a memory leak, as per\n",
    "    # https://stackoverflow.com/questions/45132940/numpy-memmap-memory-usage-want-to-iterate-once/61472122#61472122\n",
    "    if split == \"train\":\n",
    "        data = np.memmap(composer.train_path, dtype=np.uint16, mode=\"r\")\n",
    "    else:\n",
    "        data = np.memmap(composer.valid_path, dtype=np.uint16, mode=\"r\")\n",
    "\n",
    "    low, high = 0, len(data) - block_size\n",
    "    size = (batch_size,)\n",
    "\n",
    "    indices = torch.randint(low=low, high=high, size=size, generator=generator)\n",
    "\n",
    "    x = torch.stack([torch.from_numpy((data[index : index + block_size]).astype(np.int64)) for index in indices])\n",
    "    y = torch.stack(\n",
    "        [torch.from_numpy((data[index + 1 : index + 1 + block_size]).astype(np.int64)) for index in indices]\n",
    "    )\n",
    "    if device_type == \"cuda\":\n",
    "        # pin arrays x,y, which allows us to move them to GPU asynchronously (non_blocking=True)\n",
    "        x, y = x.pin_memory().to(device, non_blocking=True), y.pin_memory().to(device, non_blocking=True)\n",
    "    else:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "    return x, y\n",
    "\n",
    "generator = torch.Generator(device=composer.device)\n",
    "generator.manual_seed(25)\n",
    "train_batch = get_batch(composer, split=\"train\", batch_size=composer.batch_size, block_size=composer.block_size, device=composer.device, generator=generator)\n",
    "x, y = train_batch\n",
    "pprint(x)\n",
    "pprint(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using PyTorch's Dataset and Dataloader\n",
    "\n",
    "It is relatively simple to understand - and since there is not a need to\n",
    "[collate](https://pytorch.org/docs/stable/data.html#dataloader-collate-fn) the\n",
    "data, which makes things a bit easier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generative Pre-trained Transformer (GPT)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Token Embeddings\n",
    "\n",
    "First, we will look at the first sequence, given by `' priest and clerk? well then, amen'`,\n",
    "which we have already mapped to its corresponding token IDs.\n",
    "\n",
    "$$\n",
    "\\mathbf{x} = \\begin{bmatrix} 11503 & 290 & 21120 & 30 & 880 & 788 & 11 & 29448 \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "The shape is $1 \\times 8$, which is a single sequence of $8$ tokens. And in this case, \n",
    "we have each word/punctuation mapped to a unique token ID, as seen below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token ID: 11503, Token:  priest\n",
      "Token ID: 290, Token:  and\n",
      "Token ID: 21120, Token:  clerk\n",
      "Token ID: 30, Token: ?\n",
      "Token ID: 880, Token:  well\n",
      "Token ID: 788, Token:  then\n",
      "Token ID: 11, Token: ,\n",
      "Token ID: 29448, Token:  amen\n"
     ]
    }
   ],
   "source": [
    "for token in x[0]:\n",
    "    print(f\"Token ID: {token.item()}, Token: {tokenizer.decode([token.item()])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we need to map each token to a vector (embeddings) in a high-dimensional\n",
    "space.\n",
    "\n",
    "The integer tokens, by themselves, do not carry much information. For example,\n",
    "the word `priest` is tokenized to be `11503`, which is an arbitrary integer. In\n",
    "a one-dimensional Euclidean space, the word `priest` and the next word `and`,\n",
    "indexed by `290`, **_would appear to be very far apart from each other_**.\n",
    "However, if we were to change a tokenizer, and somehow the word `priest` is now\n",
    "tokenized to be `291`, then the words `priest` and `and` **_would appear to be\n",
    "very near to each other_**.\n",
    "\n",
    "This means that the model could potentially learn the relationship of two tokens\n",
    "based solely on their tokenized integers. To address this, we use embedding\n",
    "vectors. While the initial mapping from words to vectors is dependent on the\n",
    "tokenizer and may be arbitrary, during training, the model adjusts these vectors\n",
    "so that words used in similar contexts come to have similar vectors. This allows\n",
    "the model to capture semantic relationships between words - and by extension,\n",
    "allows the model to capture relationships between tokens better."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">' priest and clerk? well then, amen'</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32m' priest and clerk? well then, amen'\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">tensor</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">11503</span>,   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">290</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">21120</span>,    <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">30</span>,   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">880</span>,   <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">788</span>,    <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">11</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">29448</span><span style=\"font-weight: bold\">])</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m11503\u001b[0m,   \u001b[1;36m290\u001b[0m, \u001b[1;36m21120\u001b[0m,    \u001b[1;36m30\u001b[0m,   \u001b[1;36m880\u001b[0m,   \u001b[1;36m788\u001b[0m,    \u001b[1;36m11\u001b[0m, \u001b[1;36m29448\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x0 = x[0]\n",
    "pprint(tokenizer.decode(x0.cpu().numpy()))\n",
    "pprint(x0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">tensor</span><span style=\"font-weight: bold\">([[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-1.0213</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.3146</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.2616</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.3730</span><span style=\"font-weight: bold\">]</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"font-weight: bold\">[</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.5715</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.1229</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.8145</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-1.4164</span><span style=\"font-weight: bold\">]</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"font-weight: bold\">[</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.4973</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-1.1740</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.6713</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.1102</span><span style=\"font-weight: bold\">]</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-2.3167</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.2943</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.9573</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.2935</span><span style=\"font-weight: bold\">]</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"font-weight: bold\">[</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0623</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.1054</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.8182</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-2.4184</span><span style=\"font-weight: bold\">]</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-1.4016</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.3422</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.9704</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.2435</span><span style=\"font-weight: bold\">]</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.0576</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.0596</span>,  <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.2764</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.2403</span><span style=\"font-weight: bold\">]</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   │   </span><span style=\"font-weight: bold\">[</span> <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.2707</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-0.5865</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-1.4099</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">-1.3797</span><span style=\"font-weight: bold\">]]</span>, <span style=\"color: #808000; text-decoration-color: #808000\">grad_fn</span>=<span style=\"font-weight: bold\">&lt;</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff; font-weight: bold\">EmbeddingBackward0</span><span style=\"font-weight: bold\">&gt;)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mtensor\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m-1.0213\u001b[0m,  \u001b[1;36m0.3146\u001b[0m, \u001b[1;36m-0.2616\u001b[0m,  \u001b[1;36m0.3730\u001b[0m\u001b[1m]\u001b[0m,\n",
       "\u001b[2;32m│   │   \u001b[0m\u001b[1m[\u001b[0m \u001b[1;36m0.5715\u001b[0m,  \u001b[1;36m0.1229\u001b[0m, \u001b[1;36m-0.8145\u001b[0m, \u001b[1;36m-1.4164\u001b[0m\u001b[1m]\u001b[0m,\n",
       "\u001b[2;32m│   │   \u001b[0m\u001b[1m[\u001b[0m \u001b[1;36m0.4973\u001b[0m, \u001b[1;36m-1.1740\u001b[0m, \u001b[1;36m-0.6713\u001b[0m, \u001b[1;36m-0.1102\u001b[0m\u001b[1m]\u001b[0m,\n",
       "\u001b[2;32m│   │   \u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m-2.3167\u001b[0m,  \u001b[1;36m0.2943\u001b[0m,  \u001b[1;36m0.9573\u001b[0m,  \u001b[1;36m0.2935\u001b[0m\u001b[1m]\u001b[0m,\n",
       "\u001b[2;32m│   │   \u001b[0m\u001b[1m[\u001b[0m \u001b[1;36m0.0623\u001b[0m, \u001b[1;36m-0.1054\u001b[0m,  \u001b[1;36m0.8182\u001b[0m, \u001b[1;36m-2.4184\u001b[0m\u001b[1m]\u001b[0m,\n",
       "\u001b[2;32m│   │   \u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m-1.4016\u001b[0m,  \u001b[1;36m0.3422\u001b[0m, \u001b[1;36m-0.9704\u001b[0m, \u001b[1;36m-0.2435\u001b[0m\u001b[1m]\u001b[0m,\n",
       "\u001b[2;32m│   │   \u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m-0.0576\u001b[0m, \u001b[1;36m-0.0596\u001b[0m,  \u001b[1;36m0.2764\u001b[0m, \u001b[1;36m-0.2403\u001b[0m\u001b[1m]\u001b[0m,\n",
       "\u001b[2;32m│   │   \u001b[0m\u001b[1m[\u001b[0m \u001b[1;36m1.2707\u001b[0m, \u001b[1;36m-0.5865\u001b[0m, \u001b[1;36m-1.4099\u001b[0m, \u001b[1;36m-1.3797\u001b[0m\u001b[1m]\u001b[0m\u001b[1m]\u001b[0m, \u001b[33mgrad_fn\u001b[0m=\u001b[1m<\u001b[0m\u001b[1;95mEmbeddingBackward0\u001b[0m\u001b[1m>\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">torch.Size</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">8</span>, <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span><span style=\"font-weight: bold\">])</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mtorch.Size\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[1;36m8\u001b[0m, \u001b[1;36m4\u001b[0m\u001b[1m]\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "torch.manual_seed(composer.seed)\n",
    "\n",
    "tok_embed = nn.Embedding(num_embeddings=composer.vocab_size, embedding_dim=composer.d_model)\n",
    "x0_tok_embed = tok_embed(x0)\n",
    "pprint(x0_tok_embed)\n",
    "pprint(x0_tok_embed.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lookup Operation\n",
    "\n",
    "So this operation above is essentially a lookup operation, where we look up the\n",
    "embedding vector for each token in the sequence. This is done by\n",
    "`self.token_embeddings(x)`. We run it against the first sequence for simplicity,\n",
    "and `x0_tok_embed` is the resulting tensor, with a shape of $T \\times D$. In our\n",
    "case, the sequence length (block size) is $T = 8$, and the embedding dimension\n",
    "is $D = 4$. This means that we have essentially mapped each of the $8$ tokens\n",
    "representing `priest and clerk? well then, amen` to a $4$-dimensional vector.\n",
    "\n",
    "-   `priest` is mapped to `[-1.0213, 0.3146, -0.2616, 0.3730]`\n",
    "-   `and` is mapped to `[ 0.5715, 0.1229, -0.8145, -1.4164]`\n",
    "-   ...\n",
    "-   `amen` is mapped to `[ 1.2707, -0.5865, -1.4099, -1.3797]`\n",
    "\n",
    "With each token being a vector, not only does the token carry more information,\n",
    "it is also much easier to do linear algebra operations on the tokens. For\n",
    "example, we can easily calculate the mean/sum of the embeddings for pooling, or\n",
    "we can easily calculate the dot product between two tokens to measure their\n",
    "similarity in a high-dimensional space (as compared to it being an integer with\n",
    "only 1 dimension).\n",
    "\n",
    "Furthermore, the embeddings are learned during training, and the model would try\n",
    "to capture semantic relationships between tokens. For example, the model would\n",
    "try to learn that `priest` and `clerk` are related in some way because they\n",
    "refer to people, and `amen` is related to `priest` because it is often used in\n",
    "religious contexts.\n",
    "\n",
    "### Token Embedding Matrix\n",
    "\n",
    "$\\mathbf{E}$: is the embedding matrix defined as:\n",
    "\n",
    "$$\n",
    "\\mathbf{E} = \\begin{bmatrix} e_{1,1} & e_{1,2} & \\cdots & e_{1,D} \\\\ e_{2,1} & e_{2,2} & \\cdots & e_{2,D} \\\\ \\vdots & \\vdots & \\ddots & \\vdots \\\\ e_{V,1} & e_{V,2} & \\cdots & e_{V,D} \\end{bmatrix} \\in \\mathbb{R}^{V \\times D}\n",
    "$$\n",
    "\n",
    "where\n",
    "\n",
    "-   $V := \\lvert \\mathcal{V} \\rvert$: is the vocabulary size.\n",
    "-   $D$: is the embedding dimension.\n",
    "-   $e_{j, d}$: is the embedding element at position $j, d$. For a word $v_j$ in\n",
    "    the vocabulary $\\mathcal{V}$, the corresponding row in $\\mathbf{E}$ is the\n",
    "    embedding vector for that word.\n",
    "\n",
    "### Representation Mapping\n",
    "\n",
    "Define a function $h_{\\text{tok_embed}}: \\mathcal{V} \\to \\mathbb{R}^{D}$ such\n",
    "that for each token $x_t \\in \\mathcal{V}$, the function\n",
    "$h_{\\text{tok_embed}}(x_t) = \\mathbf{E}_{\\text{index}(x_t)}$ returns the\n",
    "embedding vector from $\\mathbf{E}$, where $\\text{index}(x_t)$ is the index of\n",
    "$x_t$ in the vocabulary $\\mathcal{V}$ (often times $x_t$ is already an integer\n",
    "index).\n",
    "\n",
    "### One-Hot Encoding and Embedding Matrix\n",
    "\n",
    "It is worth noting that the underlying mechanism of calling `tok_embed(x)` is\n",
    "the same as performing a matrix multiplication between a one-hot encoded vector\n",
    "and the embedding matrix. This is because the one-hot encoded vector is a\n",
    "sparse vector with only one non-zero element, and when multiplied with the\n",
    "embedding matrix, it selects the row corresponding to the non-zero element."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "x0_ohe = F.one_hot(x0, num_classes=composer.vocab_size)\n",
    "x0_ohe = x0_ohe.float()\n",
    "assert x0_ohe.shape == (composer.block_size, composer.vocab_size) # [8, 50257]\n",
    "\n",
    "for index, token_id in enumerate(x0):\n",
    "    assert x0_ohe[index, token_id].item() == 1.0 # check if the one-hot encoding is correct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   Recall our tokenized sequence is\n",
    "    `[11503, 290, 21120, 30, 880, 788, 11, 29448]`.\n",
    "-   Converting it to one-hot encoding, we would have a matrix of size\n",
    "    `[8, 50257]` (or more generally `[B, T, V]` in the presence of batch size\n",
    "    `B`).\n",
    "-   Each row is a one-hot vector of the token $x_{t} \\in \\mathbb{R}^{V}$ at\n",
    "    position $t$. For example, the first row would be a one-hot vector of the\n",
    "    token `11503`, so every element in the first row is $0$ except for the\n",
    "    $11503$-th element, which is $1$.\n",
    "-   A minute quirk here is that the token $x_{t}$ exists in the **_continuous\n",
    "    space_** instead of the **_discrete space_**. This is because we have to\n",
    "    perform the dot product between the one-hot vector and the embedding vector,\n",
    "    which is a continuous vector. This is more of a data type coercion.\n",
    "    Therefore, in our code, we also converted the one-hot vector to `.float()`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix = tok_embed.weight.data\n",
    "x0_ohe_tok_embed = x0_ohe @ embedding_matrix\n",
    "assert torch.allclose(x0_tok_embed, x0_ohe_tok_embed, atol=1e-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Indeed, we see that the result of `tok_embed(x)` is the same as the result of\n",
    "`x0_ohe @ embedding_matrix`. In other words, you can one hot encoded the input\n",
    "sequence $\\mathbf{x} = (x_1, x_2, \\ldots, x_T)$ and then matrix multiply it with the\n",
    "embedding matrix $\\mathbf{E}$ (via a linear layer) to get the same result as `tok_embed(x)`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-   $\\mathbf{O}$: one-hot representation of the input sequence\n",
    "    $\\mathbf{x} = (x_1, x_2, \\ldots, x_T)$. This is a $T \\times V$ matrix, where\n",
    "    each row represents a token in the sequence and each column corresponds to a\n",
    "    unique word in the vocabulary $\\mathcal{V}$.\n",
    "\n",
    "    $$\n",
    "    \\begin{aligned}\n",
    "    \\mathbf{O} &= \\begin{bmatrix} o_{1,1} & o_{1,2} & \\cdots & o_{1,V} \\\\ o_{2,1} & o_{2,2} & \\cdots & o_{2,V} \\\\ \\vdots & \\vdots & \\ddots & \\vdots \\\\ o_{T,1} & o_{T,2} & \\cdots & o_{T,V} \\end{bmatrix} \\in \\mathbb{R}^{T \\times V} \\\\\n",
    "    &= \\begin{bmatrix} \\text{---} & \\mathbf{o}_{1, :} & \\text{---} \\\\ \\text{---} & \\mathbf{o}_{2, :} & \\text{---} \\\\ & \\vdots & \\\\ \\text{---} & \\mathbf{o}_{T, :} & \\text{---} \\end{bmatrix} \\in \\mathbb{R}^{T \\times V}\n",
    "    \\end{aligned}\n",
    "    $$\n",
    "\n",
    "    where\n",
    "\n",
    "    -   $T$: is the sequence length.\n",
    "    -   $V$: is the vocabulary size.\n",
    "    -   $o_{t, j}$: is the one-hot encoded element at position $t, j$. For a\n",
    "        given token $x_t$ at the $t$-th position in the sequence $\\mathbf{x}$,\n",
    "        if $f_{\\text{stoi}}(x_t)=j$, then the element at position $j$ in the\n",
    "        one-hot vector for token $x_i$ is 1, and all other elements are 0.\n",
    "    -   $\\mathbf{o}_{t, :}$: is the one-hot encoded vector for the token $x_t$\n",
    "        at the $t$-th position in the sequence $\\mathbf{x}$. This row form is\n",
    "        more important than column form because it serves as the lookup key for\n",
    "        the embedding matrix $\\mathbf{E}$.\n",
    "\n",
    "-   $\\mathbf{Z}$: is the output tensor of the embedding layer, obtained by\n",
    "    matrix multiplying $\\mathbf{O}$ with $\\mathbf{E}$, and it is defined as:\n",
    "\n",
    "    $$\n",
    "    \\mathbf{Z} = \\mathbf{O} \\cdot \\mathbf{E}\n",
    "    $$\n",
    "\n",
    "    $$\n",
    "    \\begin{aligned}\n",
    "    \\mathbf{Z} &= \\mathbf{O} \\cdot \\mathbf{E} \\\\\n",
    "    &= \\begin{bmatrix} z_{1,1} & z_{1,2} & \\cdots & z_{1,D} \\\\ z_{2,1} & z_{2,2} & \\cdots & z_{2,D} \\\\ \\vdots & \\vdots & \\ddots & \\vdots \\\\ z_{T,1} & z_{T,2} & \\cdots & z_{T,D} \\end{bmatrix} \\in \\mathbb{R}^{T \\times D} \\\\\n",
    "    &= \\begin{bmatrix} \\text{---} & \\mathbf{z}_{1,:} & \\text{---} \\\\ \\text{---} & \\mathbf{z}_{2,:} & \\text{---} \\\\ & \\vdots & \\\\ \\text{---} & \\mathbf{z}_{T,:} & \\text{---} \\end{bmatrix} \\in \\mathbb{R}^{T \\times D}\n",
    "    \\end{aligned}\n",
    "    $$\n",
    "\n",
    "    where\n",
    "\n",
    "    -   $T$: is the sequence length.\n",
    "    -   $D$: is the embedding dimension.\n",
    "    -   $z_{t, d}$: is the element at position $t, d$ in the tensor\n",
    "        $\\mathbf{Z}$. For a token $x_t$ at the $t$-th position in the sequence,\n",
    "        $z_{t, :}$ is the $D$ dimensional embedding vector for that token.\n",
    "    -   $\\mathbf{z}_{t, :}$: is the $D$ dimensional embedding vector for the\n",
    "        token $x_t$ at the $t$-th position in the sequence.\n",
    "\n",
    "        In this context, each token in the sequence is represented by a $D$\n",
    "        dimensional vector. So, the output tensor $\\mathbf{Z}$ captures the\n",
    "        dense representation of the sequence. Each token in the sequence is\n",
    "        replaced by its corresponding embedding vector from the embedding matrix\n",
    "        $\\mathbf{E}$.\n",
    "\n",
    "        As before, the output tensor $\\mathbf{Z}$ carries semantic information\n",
    "        about the tokens in the sequence. The closer two vectors are in this\n",
    "        embedding space, the more semantically similar they are."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Positional Embeddings\n",
    "\n",
    "For the lack of a better phrase, we say that self-attention, the core function\n",
    "of GPTs, is permutation invariant. While it is obvious that the input sequence\n",
    "$\\mathbf{x}$ is ordered in the sense that $x_1$ comes before $x_2$, and $x_2$\n",
    "comes before $x_3$, and so on, this information gets lost in the self-attention\n",
    "mechanism. This means that the model does not differentiate \"the cat ate the\n",
    "mouse\" from \"the mouse ate the cat\" as long as the tokens are the same - and\n",
    "this is not desirable.\n",
    "\n",
    "The dominant approach for preserving information about the order of tokens is to\n",
    "represent this to the model as an additional input associated with each token.\n",
    "These inputs are called positional encodings, and they can either be learned or\n",
    "fixed _a priori_ {cite}`zhang2023dive`. What this means is that we can either\n",
    "construct a learnable parameter that is updated during training, or we can\n",
    "construct a fixed parameter that is not updated during training. For the sake of\n",
    "completeness, we will discuss briefly the scheme where the positional encodings\n",
    "are fixed _a priori_ based on sinusoidal functions - which is also the scheme\n",
    "described in the paper \"Attention is All You Need\" {cite}`vaswani2023attention`.\n",
    "\n",
    "```{prf:definition} Positional Encoding\n",
    ":label: decoder-positional-encoding\n",
    "\n",
    "The positional encoding function\n",
    "$\\mathrm{PE}: \\mathbb{N} \\times \\mathbb{N} \\rightarrow \\mathbb{R}$ computes the\n",
    "position encoding for each position $p \\in \\mathbb{N}$ and each dimension\n",
    "$i \\in \\mathbb{N}$ in the input embedding space as follows {cite}`math11112451`:\n",
    "\n",
    "$$\n",
    "\\operatorname{PE}(p, i)= \\begin{cases}\\sin \\left(\\frac{p}{10000^{\\frac{2 i}{d}}}\\right) & \\text { if } i \\text { is even, } \\\\ \\cos \\left(\\frac{p}{10000^{\\frac{2 i-1}{d}}}\\right) & \\text { if } i \\text { is odd. }\\end{cases}\n",
    "$$\n",
    "```\n",
    "\n",
    "The positional encoding function incorporates a 10,000 constant, which serves as\n",
    "a hyperparameter. This value was determined empirically during the original\n",
    "development of the Transformer model. It is designed to create a balance between\n",
    "the higher and lower frequency components of the positional encoding. To\n",
    "facilitate the optimization process, the GPT model employs layer normalization,\n",
    "which is applied to the input of both the multi-head self-attention and\n",
    "position-wise feedforward sublayers. Layer normalization helps alleviate the\n",
    "vanishing and exploding gradient problems and accelerates training.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import ABC, abstractmethod\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "\n",
    "class PositionalEncoding(ABC, nn.Module):\n",
    "    def __init__(self, d_model: int, context_length: int, dropout: float = 0.0) -> None:\n",
    "        super().__init__()\n",
    "        self.d_model = d_model\n",
    "        self.context_length = context_length\n",
    "        self.dropout = nn.Dropout(p=dropout, inplace=False)\n",
    "\n",
    "    @abstractmethod\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        ...\n",
    "\n",
    "\n",
    "class Sinusoid(PositionalEncoding):\n",
    "    P: torch.Tensor\n",
    "\n",
    "    def __init__(self, d_model: int, context_length: int, dropout: float = 0.0) -> None:\n",
    "        super().__init__(d_model, context_length, dropout)\n",
    "\n",
    "        P = self._init_positional_encoding()\n",
    "        self.register_buffer(\"P\", P, persistent=True)  # with this no need requires_grad=False\n",
    "\n",
    "    def _init_positional_encoding(self) -> torch.Tensor:\n",
    "        \"\"\"Initialize the positional encoding tensor.\"\"\"\n",
    "        P = torch.zeros((1, self.context_length, self.d_model))\n",
    "        position = self._get_position_vector()\n",
    "        div_term = self._get_div_term_vector()\n",
    "        P[:, :, 0::2] = torch.sin(position / div_term)\n",
    "        P[:, :, 1::2] = torch.cos(position / div_term)\n",
    "        return P\n",
    "\n",
    "    def _get_position_vector(self) -> torch.Tensor:\n",
    "        \"\"\"Return a vector representing the position of each token in a sequence.\"\"\"\n",
    "        return torch.arange(self.context_length, dtype=torch.float32).reshape(-1, 1)\n",
    "\n",
    "    def _get_div_term_vector(self) -> torch.Tensor:\n",
    "        \"\"\"Return a vector representing the divisor term for positional encoding.\"\"\"\n",
    "        return torch.pow(\n",
    "            10000,\n",
    "            torch.arange(0, self.d_model, 2, dtype=torch.float32) / self.d_model,\n",
    "        )\n",
    "\n",
    "    def forward(self, z: torch.Tensor) -> torch.Tensor:\n",
    "        z = self._add_positional_encoding(z)\n",
    "        z = self.dropout(z)\n",
    "        return z\n",
    "\n",
    "    def _add_positional_encoding(self, z: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Add the positional encoding tensor to the input tensor.\"\"\"\n",
    "        return z + self.P[:, : z.shape[1], :]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "encod_block = Sinusoid(d_model=48, context_length=96)\n",
    "\n",
    "pe = encod_block.P.squeeze().T.cpu().numpy()\n",
    "\n",
    "fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(8,3))\n",
    "pos = ax.imshow(pe, cmap=\"RdGy\", extent=(1,pe.shape[1]+1,pe.shape[0]+1,1))\n",
    "fig.colorbar(pos, ax=ax)\n",
    "ax.set_xlabel(\"Position in sequence\")\n",
    "ax.set_ylabel(\"Hidden dimension\")\n",
    "ax.set_title(\"Positional encoding over hidden dimensions\")\n",
    "ax.set_xticks([1]+[i*10 for i in range(1,1+pe.shape[1]//10)])\n",
    "ax.set_yticks([1]+[i*10 for i in range(1,1+pe.shape[0]//10)])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Self-Attention and Masked Self-Attention"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Insert arch diagram\n",
    "2. change example since i changed seed.\n",
    "3. Add cosine similarity from transformers notebook to show that embeddings in a subspace.\n",
    "4. Add def/theorem/notation prf\n",
    "5. Conditional and Joint probability\n",
    "6. Model definition in page 5/\n",
    "7. Loss see page 5/6\n",
    "8. autoregressive self supervised def page 6\n",
    "9. Insert intuition of using average of preceding tokens for self attention section:\n",
    "    1. version 1: averaging past context with for loops, the weakest form of aggregation\n",
    "    2. min 42 to min 58\n",
    "    3. on intuition of softmax and weight distribution\n",
    "10. Time and Space Complexity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conditional Probability\n",
    "\n",
    "The GPT model, being autoregressive, directly models the **conditional\n",
    "probability** of each token given all previous tokens in a sequence. This is the\n",
    "core operational mechanism of the model, allowing it to predict the next token\n",
    "based on the preceding context. The conditional probability for each token $x_t$\n",
    "given its predecessors $x_{<t}$ is expressed as $P(x_t | x_{<t};\n",
    "\\Theta)$, where\n",
    "$\\Theta$ represents the model's parameters.\n",
    "\n",
    "## Joint Probability\n",
    "\n",
    "The **joint probability** of a sequence $\\mathbf{x} = (x_1, x_2, ..., x_T)$\n",
    "under the model is derived from the product of these conditional probabilities.\n",
    "By assuming that the probability of each token can be modeled based on its\n",
    "predecessors, the model implicitly defines a joint probability distribution over\n",
    "sequences. This joint probability is represented by the product:\n",
    "\n",
    "$$\n",
    "P(\\mathbf{x}; \\Theta) = \\prod_{t=1}^{T} P(x_t | x_{<t}; \\Theta)\n",
    "$$\n",
    "\n",
    "This formulation shows that while the GPT model operates through conditional\n",
    "probabilities, the product of these conditional probabilities across a sequence\n",
    "results in the **joint probability** of the entire sequence. Thus, the GPT model\n",
    "effectively learns the joint probability distribution over sequences in the\n",
    "dataset by learning to predict the next token given its context, leveraging the\n",
    "chain rule of probability.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "{cite}`math11112451`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- https://devblogs.nvidia.com/how-optimize-data-transfers-cuda-cc/\n",
    "- https://developer.nvidia.com/blog/how-overlap-data-transfers-cuda-cc/\n",
    "- https://e2eml.school/transformers.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[^1]: [OpenAI tiktoken](https://github.com/openai/tiktoken)\n",
    "[^2]: [How to Optimize Data Transfers in CUDA C/C++](https://devblogs.nvidia.com/how-optimize-data-transfers-cuda-cc/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "omniverse",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
